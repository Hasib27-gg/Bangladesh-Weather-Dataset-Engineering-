{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe509e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Temp9am",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Temp3pm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MinTemp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MaxTemp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Rainfall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RainToday",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Evaporation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Sunshine",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindGustDir",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "WindGustSpeed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WindDir9am",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "WindDir3pm",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "WindSpeed9am",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WindSpeed3pm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Humidity9am",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Humidity3pm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Pressure9am",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Pressure3pm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cloud9am",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Cloud3pm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5345b6dd-139c-4c5d-a98e-fd3123a8bf2b",
       "rows": [
        [
         "0",
         "01-02-13",
         "20.7",
         "20.9",
         "19.5",
         "22.4",
         "15.6",
         "Yes",
         "6.2",
         "0.0",
         "W",
         "41",
         "S",
         "SSW",
         "17",
         "20",
         "92",
         "84",
         "1017.6",
         "1017.4",
         "8",
         "8",
         "1"
        ],
        [
         "1",
         "02-02-13",
         "22.4",
         "24.8",
         "19.5",
         "25.6",
         "6.0",
         "Yes",
         "3.4",
         "2.7",
         "W",
         "41",
         "W",
         "E",
         "9",
         "13",
         "83",
         "73",
         "1017.9",
         "1016.4",
         "7",
         "7",
         "2"
        ],
        [
         "2",
         "03-02-13",
         "23.5",
         "23.0",
         "21.6",
         "24.5",
         "6.6",
         "Yes",
         "2.4",
         "0.1",
         "W",
         "41",
         "ESE",
         "ESE",
         "17",
         "2",
         "88",
         "86",
         "1016.7",
         "1015.6",
         "7",
         "8",
         "3"
        ],
        [
         "3",
         "04-02-13",
         "21.4",
         "20.9",
         "20.2",
         "22.8",
         "18.8",
         "Yes",
         "2.2",
         "0.0",
         "W",
         "41",
         "NNE",
         "E",
         "22",
         "20",
         "83",
         "90",
         "1014.2",
         "1011.8",
         "8",
         "8",
         "4"
        ],
        [
         "4",
         "05-02-13",
         "22.5",
         "25.5",
         "19.7",
         "25.7",
         "77.4",
         "Yes",
         "4.8",
         "0.0",
         "W",
         "41",
         "NNE",
         "W",
         "11",
         "6",
         "88",
         "74",
         "1008.3",
         "1004.8",
         "8",
         "8",
         "5"
        ]
       ],
       "shape": {
        "columns": 22,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-02-13</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.9</td>\n",
       "      <td>19.5</td>\n",
       "      <td>22.4</td>\n",
       "      <td>15.6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>SSW</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>92</td>\n",
       "      <td>84</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1017.4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-02-13</td>\n",
       "      <td>22.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>19.5</td>\n",
       "      <td>25.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>E</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>73</td>\n",
       "      <td>1017.9</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-02-13</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>24.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>ESE</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>1015.6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-02-13</td>\n",
       "      <td>21.4</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>18.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>E</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "      <td>1014.2</td>\n",
       "      <td>1011.8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-02-13</td>\n",
       "      <td>22.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>19.7</td>\n",
       "      <td>25.7</td>\n",
       "      <td>77.4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>W</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>88</td>\n",
       "      <td>74</td>\n",
       "      <td>1008.3</td>\n",
       "      <td>1004.8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date  Temp9am  Temp3pm  MinTemp  MaxTemp  Rainfall RainToday  \\\n",
       "0  01-02-13     20.7     20.9     19.5     22.4      15.6       Yes   \n",
       "1  02-02-13     22.4     24.8     19.5     25.6       6.0       Yes   \n",
       "2  03-02-13     23.5     23.0     21.6     24.5       6.6       Yes   \n",
       "3  04-02-13     21.4     20.9     20.2     22.8      18.8       Yes   \n",
       "4  05-02-13     22.5     25.5     19.7     25.7      77.4       Yes   \n",
       "\n",
       "   Evaporation  Sunshine WindGustDir  ...  WindDir3pm WindSpeed9am  \\\n",
       "0          6.2       0.0           W  ...         SSW           17   \n",
       "1          3.4       2.7           W  ...           E            9   \n",
       "2          2.4       0.1           W  ...         ESE           17   \n",
       "3          2.2       0.0           W  ...           E           22   \n",
       "4          4.8       0.0           W  ...           W           11   \n",
       "\n",
       "  WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  \\\n",
       "0           20           92           84       1017.6       1017.4         8   \n",
       "1           13           83           73       1017.9       1016.4         7   \n",
       "2            2           88           86       1016.7       1015.6         7   \n",
       "3           20           83           90       1014.2       1011.8         8   \n",
       "4            6           88           74       1008.3       1004.8         8   \n",
       "\n",
       "   Cloud3pm  ID  \n",
       "0         8   1  \n",
       "1         7   2  \n",
       "2         8   3  \n",
       "3         8   4  \n",
       "4         8   5  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections \n",
    "data = pd.read_csv(\"train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33311bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2616, 22)\n",
      "Date\n",
      "Temp9am\n",
      "Temp3pm\n",
      "MinTemp\n",
      "MaxTemp\n",
      "Rainfall\n",
      "RainToday\n",
      "Evaporation\n",
      "Sunshine\n",
      "WindGustDir\n",
      "WindGustSpeed\n",
      "WindDir9am\n",
      "WindDir3pm\n",
      "WindSpeed9am\n",
      "WindSpeed3pm\n",
      "Humidity9am\n",
      "Humidity3pm\n",
      "Pressure9am\n",
      "Pressure3pm\n",
      "Cloud9am\n",
      "Cloud3pm\n",
      "ID\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "for item in data.columns:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68777bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "null_columns = []\n",
    "for item in data.columns:\n",
    "\n",
    "    if data[item].isnull().any():\n",
    "        null_columns.append(item)\n",
    "\n",
    "print(null_columns)\n",
    "#No null columns :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f461ab67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'temp_9am', 'temp_3pm', 'min_temp', 'max_temp', 'rain_fall',\n",
       "       'rain_today', 'evaporation', 'sunshine', 'wind_gust_dir',\n",
       "       'wind_gust_speed', 'wind_dir_9am', 'wind_dir_3pm', 'wind_speed_9am',\n",
       "       'wind_speed_3pm', 'humidity_9am', 'humidity3pm', 'pressure_9am',\n",
       "       'pressure_3pm', 'cloud_9am', 'cloud_3pm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = [\n",
    "    'date',\n",
    "    'temp_9am',\n",
    "    'temp_3pm',\n",
    "    'min_temp',\n",
    "    'max_temp',\n",
    "    'rain_fall',\n",
    "    'rain_today',\n",
    "    'evaporation',\n",
    "    'sunshine',\n",
    "    'wind_gust_dir',\n",
    "    'wind_gust_speed',\n",
    "    'wind_dir_9am',\n",
    "    'wind_dir_3pm',\n",
    "    'wind_speed_9am',\n",
    "    'wind_speed_3pm',\n",
    "    'humidity_9am',\n",
    "    'humidity3pm',\n",
    "    'pressure_9am',\n",
    "    'pressure_3pm',\n",
    "    'cloud_9am',\n",
    "    'cloud_3pm',\n",
    "    'id'\n",
    "]\n",
    "data = data.drop('id' , axis = 1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2935ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('rain_today' , axis = 1).copy()\n",
    "Y = data['rain_today'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad45c93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temp_9am",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temp_3pm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "min_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rain_fall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "evaporation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sunshine",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wind_gust_dir",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "wind_gust_speed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wind_dir_9am",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "wind_dir_3pm",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "wind_speed_9am",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wind_speed_3pm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "humidity_9am",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "humidity3pm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pressure_9am",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pressure_3pm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cloud_9am",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cloud_3pm",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5621bc12-cd9a-4e6d-a9e1-88de0bc161cc",
       "rows": [
        [
         "0",
         "4780",
         "20.7",
         "20.9",
         "19.5",
         "22.4",
         "15.6",
         "6.2",
         "0.0",
         "W",
         "41",
         "S",
         "SSW",
         "17",
         "20",
         "92",
         "84",
         "1017.6",
         "1017.4",
         "8",
         "8"
        ],
        [
         "1",
         "4781",
         "22.4",
         "24.8",
         "19.5",
         "25.6",
         "6.0",
         "3.4",
         "2.7",
         "W",
         "41",
         "W",
         "E",
         "9",
         "13",
         "83",
         "73",
         "1017.9",
         "1016.4",
         "7",
         "7"
        ],
        [
         "2",
         "4782",
         "23.5",
         "23.0",
         "21.6",
         "24.5",
         "6.6",
         "2.4",
         "0.1",
         "W",
         "41",
         "ESE",
         "ESE",
         "17",
         "2",
         "88",
         "86",
         "1016.7",
         "1015.6",
         "7",
         "8"
        ],
        [
         "3",
         "4783",
         "21.4",
         "20.9",
         "20.2",
         "22.8",
         "18.8",
         "2.2",
         "0.0",
         "W",
         "41",
         "NNE",
         "E",
         "22",
         "20",
         "83",
         "90",
         "1014.2",
         "1011.8",
         "8",
         "8"
        ],
        [
         "4",
         "4784",
         "22.5",
         "25.5",
         "19.7",
         "25.7",
         "77.4",
         "4.8",
         "0.0",
         "W",
         "41",
         "NNE",
         "W",
         "11",
         "6",
         "88",
         "74",
         "1008.3",
         "1004.8",
         "8",
         "8"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp_9am</th>\n",
       "      <th>temp_3pm</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>rain_fall</th>\n",
       "      <th>evaporation</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>wind_gust_dir</th>\n",
       "      <th>wind_gust_speed</th>\n",
       "      <th>wind_dir_9am</th>\n",
       "      <th>wind_dir_3pm</th>\n",
       "      <th>wind_speed_9am</th>\n",
       "      <th>wind_speed_3pm</th>\n",
       "      <th>humidity_9am</th>\n",
       "      <th>humidity3pm</th>\n",
       "      <th>pressure_9am</th>\n",
       "      <th>pressure_3pm</th>\n",
       "      <th>cloud_9am</th>\n",
       "      <th>cloud_3pm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4780</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.9</td>\n",
       "      <td>19.5</td>\n",
       "      <td>22.4</td>\n",
       "      <td>15.6</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>S</td>\n",
       "      <td>SSW</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>92</td>\n",
       "      <td>84</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1017.4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4781</td>\n",
       "      <td>22.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>19.5</td>\n",
       "      <td>25.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>W</td>\n",
       "      <td>E</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>73</td>\n",
       "      <td>1017.9</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4782</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>24.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>ESE</td>\n",
       "      <td>ESE</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>1015.6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4783</td>\n",
       "      <td>21.4</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>18.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>NNE</td>\n",
       "      <td>E</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "      <td>1014.2</td>\n",
       "      <td>1011.8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4784</td>\n",
       "      <td>22.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>19.7</td>\n",
       "      <td>25.7</td>\n",
       "      <td>77.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>NNE</td>\n",
       "      <td>W</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>88</td>\n",
       "      <td>74</td>\n",
       "      <td>1008.3</td>\n",
       "      <td>1004.8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date  temp_9am  temp_3pm  min_temp  max_temp  rain_fall  evaporation  \\\n",
       "0  4780      20.7      20.9      19.5      22.4       15.6          6.2   \n",
       "1  4781      22.4      24.8      19.5      25.6        6.0          3.4   \n",
       "2  4782      23.5      23.0      21.6      24.5        6.6          2.4   \n",
       "3  4783      21.4      20.9      20.2      22.8       18.8          2.2   \n",
       "4  4784      22.5      25.5      19.7      25.7       77.4          4.8   \n",
       "\n",
       "   sunshine wind_gust_dir  wind_gust_speed wind_dir_9am wind_dir_3pm  \\\n",
       "0       0.0             W               41            S          SSW   \n",
       "1       2.7             W               41            W            E   \n",
       "2       0.1             W               41          ESE          ESE   \n",
       "3       0.0             W               41          NNE            E   \n",
       "4       0.0             W               41          NNE            W   \n",
       "\n",
       "   wind_speed_9am  wind_speed_3pm  humidity_9am  humidity3pm  pressure_9am  \\\n",
       "0              17              20            92           84        1017.6   \n",
       "1               9              13            83           73        1017.9   \n",
       "2              17               2            88           86        1016.7   \n",
       "3              22              20            83           90        1014.2   \n",
       "4              11               6            88           74        1008.3   \n",
       "\n",
       "   pressure_3pm  cloud_9am  cloud_3pm  \n",
       "0        1017.4          8          8  \n",
       "1        1016.4          7          7  \n",
       "2        1015.6          7          8  \n",
       "3        1011.8          8          8  \n",
       "4        1004.8          8          8  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def date_to_days(date : str) -> int:\n",
    "\n",
    "    time = datetime.strptime(date , \"%d-%m-%y\")\n",
    "    ref_from = datetime(2000 , 1 , 1)\n",
    "    days = (time - ref_from).days\n",
    "\n",
    "    return days\n",
    "\n",
    "X['date'] = X['date'].map(date_to_days)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8627ca9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind_gust_dir\n",
      "wind_dir_9am\n",
      "wind_dir_3pm\n"
     ]
    }
   ],
   "source": [
    "#We will going to store catagorical columns for CatBoost\n",
    "cat_columns = []\n",
    "\n",
    "for item in X.columns:\n",
    "\n",
    "    if X[item].dtype == object:\n",
    "        cat_columns.append(item)\n",
    "\n",
    "for item in cat_columns: print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf9f58a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind_gust_dir : ['W' 'NNW' 'WNW' 'ENE' 'NNE' 'NW' 'SSE' 'NE' 'ESE' 'WSW' 'SE' 'SW' 'N' 'E'\n",
      " 'SSW' 'S']\n",
      "len : 16\n",
      "wind_dir_9am : ['S' 'W' 'ESE' 'NNE' 'SSW' 'WNW' 'N' 'SW' 'SE' 'SSE' 'WSW' 'E' 'ENE' 'NW'\n",
      " 'NNW' 'NE']\n",
      "len : 16\n",
      "wind_dir_3pm : ['SSW' 'E' 'ESE' 'W' 'ENE' 'S' 'SE' 'SSE' 'NE' 'NNE' 'NNW' 'NW' 'WNW' 'N'\n",
      " 'WSW' 'SW']\n",
      "len : 16\n"
     ]
    }
   ],
   "source": [
    "for item in cat_columns:\n",
    "    print(f\"{item} : {X[item].unique()}\")\n",
    "    print(f\"len : {len(X[item].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb850a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#We also store a copy of data for catboost before it is hot encoded.\n",
    "X_cat_copy = X.copy()\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output = False , \n",
    "                        categories = 'auto', \n",
    "                        handle_unknown= 'error',\n",
    "                        max_categories = 32)\n",
    "\n",
    "encoder.fit(X[cat_columns])\n",
    "cat_ohed = pd.DataFrame(encoder.transform(X[cat_columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d653514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temp_9am",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temp_3pm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "min_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rain_fall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "evaporation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sunshine",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wind_gust_speed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wind_speed_9am",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wind_speed_3pm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "humidity_9am",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "humidity3pm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pressure_9am",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pressure_3pm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cloud_9am",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cloud_3pm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "11",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "13",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "14",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "15",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "16",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "17",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "18",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "19",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "21",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "22",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "23",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "25",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "27",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "28",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "29",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "31",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "32",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "33",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "34",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "35",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "36",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "37",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "38",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "39",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "40",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "41",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "42",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "43",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "44",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "45",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "46",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "47",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "313c0c99-5d23-46c2-937a-dd5ed56938d1",
       "rows": [
        [
         "0",
         "4780",
         "20.7",
         "20.9",
         "19.5",
         "22.4",
         "15.6",
         "6.2",
         "0.0",
         "41",
         "17",
         "20",
         "92",
         "84",
         "1017.6",
         "1017.4",
         "8",
         "8",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "4781",
         "22.4",
         "24.8",
         "19.5",
         "25.6",
         "6.0",
         "3.4",
         "2.7",
         "41",
         "9",
         "13",
         "83",
         "73",
         "1017.9",
         "1016.4",
         "7",
         "7",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "4782",
         "23.5",
         "23.0",
         "21.6",
         "24.5",
         "6.6",
         "2.4",
         "0.1",
         "41",
         "17",
         "2",
         "88",
         "86",
         "1016.7",
         "1015.6",
         "7",
         "8",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "3",
         "4783",
         "21.4",
         "20.9",
         "20.2",
         "22.8",
         "18.8",
         "2.2",
         "0.0",
         "41",
         "22",
         "20",
         "83",
         "90",
         "1014.2",
         "1011.8",
         "8",
         "8",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "4784",
         "22.5",
         "25.5",
         "19.7",
         "25.7",
         "77.4",
         "4.8",
         "0.0",
         "41",
         "11",
         "6",
         "88",
         "74",
         "1008.3",
         "1004.8",
         "8",
         "8",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 65,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp_9am</th>\n",
       "      <th>temp_3pm</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>rain_fall</th>\n",
       "      <th>evaporation</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>wind_gust_speed</th>\n",
       "      <th>wind_speed_9am</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4780</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.9</td>\n",
       "      <td>19.5</td>\n",
       "      <td>22.4</td>\n",
       "      <td>15.6</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4781</td>\n",
       "      <td>22.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>19.5</td>\n",
       "      <td>25.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4782</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>24.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>41</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4783</td>\n",
       "      <td>21.4</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>18.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4784</td>\n",
       "      <td>22.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>19.7</td>\n",
       "      <td>25.7</td>\n",
       "      <td>77.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date  temp_9am  temp_3pm  min_temp  max_temp  rain_fall  evaporation  \\\n",
       "0  4780      20.7      20.9      19.5      22.4       15.6          6.2   \n",
       "1  4781      22.4      24.8      19.5      25.6        6.0          3.4   \n",
       "2  4782      23.5      23.0      21.6      24.5        6.6          2.4   \n",
       "3  4783      21.4      20.9      20.2      22.8       18.8          2.2   \n",
       "4  4784      22.5      25.5      19.7      25.7       77.4          4.8   \n",
       "\n",
       "   sunshine  wind_gust_speed  wind_speed_9am  ...   38   39   40   41   42  \\\n",
       "0       0.0               41              17  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "1       2.7               41               9  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "2       0.1               41              17  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "3       0.0               41              22  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "4       0.0               41              11  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    43   44   45   46   47  \n",
       "0  1.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.drop(cat_columns , axis = 1)\n",
    "X_encoded = pd.concat([X , cat_ohed] , axis = 1)\n",
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc3c5132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rain_today",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "35031604-b38b-4948-8ac1-dc66683c853b",
       "rows": [
        [
         "0",
         "1"
        ],
        [
         "1",
         "1"
        ],
        [
         "2",
         "1"
        ],
        [
         "3",
         "1"
        ],
        [
         "4",
         "1"
        ],
        [
         "5",
         "1"
        ],
        [
         "6",
         "1"
        ],
        [
         "7",
         "1"
        ],
        [
         "8",
         "1"
        ],
        [
         "9",
         "0"
        ],
        [
         "10",
         "0"
        ],
        [
         "11",
         "1"
        ],
        [
         "12",
         "1"
        ],
        [
         "13",
         "0"
        ],
        [
         "14",
         "0"
        ],
        [
         "15",
         "0"
        ],
        [
         "16",
         "0"
        ],
        [
         "17",
         "0"
        ],
        [
         "18",
         "0"
        ],
        [
         "19",
         "0"
        ],
        [
         "20",
         "0"
        ],
        [
         "21",
         "0"
        ],
        [
         "22",
         "0"
        ],
        [
         "23",
         "0"
        ],
        [
         "24",
         "0"
        ],
        [
         "25",
         "1"
        ],
        [
         "26",
         "1"
        ],
        [
         "27",
         "1"
        ],
        [
         "28",
         "0"
        ],
        [
         "29",
         "1"
        ],
        [
         "30",
         "0"
        ],
        [
         "31",
         "0"
        ],
        [
         "32",
         "0"
        ],
        [
         "33",
         "0"
        ],
        [
         "34",
         "0"
        ],
        [
         "35",
         "1"
        ],
        [
         "36",
         "0"
        ],
        [
         "37",
         "0"
        ],
        [
         "38",
         "0"
        ],
        [
         "39",
         "0"
        ],
        [
         "40",
         "0"
        ],
        [
         "41",
         "0"
        ],
        [
         "42",
         "0"
        ],
        [
         "43",
         "0"
        ],
        [
         "44",
         "0"
        ],
        [
         "45",
         "0"
        ],
        [
         "46",
         "0"
        ],
        [
         "47",
         "0"
        ],
        [
         "48",
         "0"
        ],
        [
         "49",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2616
       }
      },
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "2611    0\n",
       "2612    0\n",
       "2613    0\n",
       "2614    0\n",
       "2615    0\n",
       "Name: rain_today, Length: 2616, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_MAPED: pd.Series = Y.map({'Yes' : 1 , 'No' : 0})\n",
    "Y_MAPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2705f304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25840978593272174\n"
     ]
    }
   ],
   "source": [
    "print(Y_MAPED.sum(axis = 0)/len(Y_MAPED))\n",
    "#So , obviously we need careful stratification before train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f296e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now before feature engineering ,first I want to reduce the number of\n",
    "# dimensions of X\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "params_pca: dict = {\n",
    "    'n_components' : 0.95,\n",
    "    'whiten'       : False,\n",
    "    'random_state' : 12,\n",
    "    'svd_solver'   : 'full',\n",
    "}\n",
    "\n",
    "pca_model = PCA(**params_pca)\n",
    "pca_model.fit(X)\n",
    "X_reduced_raw_values: np.ndarray = pca_model.transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92b8efb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pca_feature_0']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pca_feature_0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "cbaa221c-f1bc-4115-b8a8-a6285576b773",
       "rows": [
        [
         "0",
         "-1307.5670902636393"
        ],
        [
         "1",
         "-1306.5446475121653"
        ],
        [
         "2",
         "-1305.5728770144588"
        ],
        [
         "3",
         "-1304.5657246957644"
        ],
        [
         "4",
         "-1303.5543204783735"
        ],
        [
         "5",
         "-1302.5187084764093"
        ],
        [
         "6",
         "-1301.554359439123"
        ],
        [
         "7",
         "-1300.5252041288595"
        ],
        [
         "8",
         "-1299.5886920412595"
        ],
        [
         "9",
         "-1298.5097774212509"
        ],
        [
         "10",
         "-1297.5054952208648"
        ],
        [
         "11",
         "-1296.5192830450578"
        ],
        [
         "12",
         "-1295.53894687517"
        ],
        [
         "13",
         "-1294.5056857136406"
        ],
        [
         "14",
         "-1293.5079519675865"
        ],
        [
         "15",
         "-1292.4975869435912"
        ],
        [
         "16",
         "-1291.4948100955535"
        ],
        [
         "17",
         "-1290.5009247388516"
        ],
        [
         "18",
         "-1289.5280861190395"
        ],
        [
         "19",
         "-1288.5199954707987"
        ],
        [
         "20",
         "-1287.5379387048333"
        ],
        [
         "21",
         "-1286.528038737144"
        ],
        [
         "22",
         "-1285.4469630454796"
        ],
        [
         "23",
         "-1284.4532231332541"
        ],
        [
         "24",
         "-1283.4828349334075"
        ],
        [
         "25",
         "-1282.5175682766594"
        ],
        [
         "26",
         "-1281.5157572975813"
        ],
        [
         "27",
         "-1280.5641036385832"
        ],
        [
         "28",
         "-1279.478955465198"
        ],
        [
         "29",
         "-1278.4586256768598"
        ],
        [
         "30",
         "-1277.5202619818365"
        ],
        [
         "31",
         "-1276.5061934656624"
        ],
        [
         "32",
         "-1275.5095803323757"
        ],
        [
         "33",
         "-1274.5059981652448"
        ],
        [
         "34",
         "-1273.5065545584157"
        ],
        [
         "35",
         "-1272.5406154708016"
        ],
        [
         "36",
         "-1271.5391866628615"
        ],
        [
         "37",
         "-1270.5224520595193"
        ],
        [
         "38",
         "-1269.4931375518363"
        ],
        [
         "39",
         "-1268.5050590786304"
        ],
        [
         "40",
         "-1267.5128398772085"
        ],
        [
         "41",
         "-1266.5367477381942"
        ],
        [
         "42",
         "-1265.5221750950686"
        ],
        [
         "43",
         "-1264.5240209039302"
        ],
        [
         "44",
         "-1263.5283388167472"
        ],
        [
         "45",
         "-1262.518898084053"
        ],
        [
         "46",
         "-1261.5035187677822"
        ],
        [
         "47",
         "-1260.5082292923462"
        ],
        [
         "48",
         "-1259.5085352582546"
        ],
        [
         "49",
         "-1258.5534506578124"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2616
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_feature_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1307.567090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1306.544648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1305.572877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1304.565725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1303.554320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>1303.489310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>1304.545363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>1305.540950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>1306.536836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>1307.544561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2616 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pca_feature_0\n",
       "0      -1307.567090\n",
       "1      -1306.544648\n",
       "2      -1305.572877\n",
       "3      -1304.565725\n",
       "4      -1303.554320\n",
       "...             ...\n",
       "2611    1303.489310\n",
       "2612    1304.545363\n",
       "2613    1305.540950\n",
       "2614    1306.536836\n",
       "2615    1307.544561\n",
       "\n",
       "[2616 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_len: int = X_reduced_raw_values.shape[1]\n",
    "new_columns: list = [f\"PCA_FEATURE_{idx}\".lower() for idx in range(col_len)]\n",
    "print(new_columns)\n",
    "X_reduced: pd.DataFrame = pd.DataFrame(data = X_reduced_raw_values , columns = new_columns)\n",
    "X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e186c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uhhh , it seems we have lost too much data . Even though , we captured\n",
    "#95% of the total variance, the 1 single dimension is very worse.\n",
    "#We should ignore that.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_ROOT_TRAIN: pd.DataFrame\n",
    "X_ROOT_TEST: pd.DataFrame\n",
    "Y_ROOT_TRAIN: pd.DataFrame\n",
    "Y_ROOT_TEST: pd.DataFrame\n",
    "\n",
    "tts_params: dict = {\n",
    "    'test_size' : float(0.2),\n",
    "    'train_size' : float(0.8),\n",
    "    'random_state' : int(13),\n",
    "    'shuffle' : bool(True),\n",
    "    'stratify'  : Y_MAPED,\n",
    "}\n",
    "\n",
    "X_ROOT_TRAIN , X_ROOT_TEST, Y_ROOT_TRAIN , Y_ROOT_TEST = train_test_split(\n",
    "    X_encoded,\n",
    "    Y_MAPED,\n",
    "    **tts_params\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1274fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b65d89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class enum_model:\n",
    "    def __init__(self , model_name: str = \"XGBM\") -> any:\n",
    "        if not model_name in [\"XGBM\" , \"CB\" , \"LGBM\"]:\n",
    "            raise ValueError(\n",
    "                \"Error! Model has to be: [XGBM , CB , LGBM]\")\n",
    "        self.model: str = model_name\n",
    "    def getModelType(self) -> str:\n",
    "        return self.model\n",
    "    \n",
    "\n",
    "def _obj_for_xgbm(trial: optuna.Trial) -> float:\n",
    "\n",
    "    xgbm_params: dict = {\n",
    "    #===============#\n",
    "    'objective': 'binary:logistic',\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method': 'hist',\n",
    "    'scale_pos_weight': (Y_ROOT_TRAIN == 0).sum()/(Y_ROOT_TRAIN == 1).sum(),\n",
    "    'random_state': 13,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': 1,\n",
    "    #===============#\n",
    "    \n",
    "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 0.9),\n",
    "    'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.7, 1.0),\n",
    "    'colsample_bynode': trial.suggest_float('colsample_bynode', 0.7, 1.0),\n",
    "    'gamma': trial.suggest_float('gamma', 0.3, 1),\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.01 , 0.05),\n",
    "    'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "    'min_child_weight': trial.suggest_int('min_child_weight', 0.3 , 0.9),\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 1000, 2000),\n",
    "    'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 1.5),\n",
    "    'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 1.5),\n",
    "    'subsample': trial.suggest_float('subsample', 0.8, 1.0),\n",
    "    }\n",
    "\n",
    "\n",
    "    __model: XGBClassifier = XGBClassifier(**xgbm_params)\n",
    "    validator: StratifiedKFold = StratifiedKFold(n_splits = 10 , \n",
    "                                                  shuffle = True , \n",
    "                                                  random_state = 13)\n",
    "    score: float = cross_val_score(__model, \n",
    "                                   X_encoded, \n",
    "                                   Y_MAPED,\n",
    "                                   scoring = \"accuracy\",\n",
    "                                   n_jobs = -1,\n",
    "                                   verbose =  0,\n",
    "                                   cv = validator).mean()\n",
    "    return score\n",
    "\n",
    "def _obj_for_lgbm(trial: optuna.Trial) -> float:\n",
    "     lgbm_params: dict = {\n",
    "         #==================#\n",
    "        'random_state': 13,\n",
    "        'scale_pos_weight' : (Y_ROOT_TRAIN == 0).sum()/(Y_ROOT_TRAIN == 1).sum(),\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_jobs': -1,\n",
    "        'objective' : 'binary',\n",
    "         #==================#\n",
    "\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3 , 0.9),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01 , 0.05),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3 , 8),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 3, 8),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 0.3, 0.8),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1000 , 2000),\n",
    "        'max_bin': trial.suggest_int('max_bin', 32 , 64),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.1 , 1.5),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.1 , 1.5),\n",
    "        'subsample': trial.suggest_float('subsample', 0.8 , 1),\n",
    "     }\n",
    "\n",
    "     __model: LGBMClassifier = LGBMClassifier(**lgbm_params)\n",
    "     validator: StratifiedKFold = StratifiedKFold(n_splits = 10 , \n",
    "                                                  shuffle = True , \n",
    "                                                  random_state = 13)\n",
    "     score: float = cross_val_score(__model, \n",
    "                                    X_encoded, \n",
    "                                    Y_MAPED,\n",
    "                                    scoring = \"accuracy\",\n",
    "                                    n_jobs = -1,\n",
    "                                    verbose =  0,\n",
    "                                    cv = validator).mean()\n",
    "     return score\n",
    "def _obj_for_cb(trial: optuna.Trial) -> float:\n",
    "    \n",
    "    cb_params: dict = {\n",
    "        #=================#\n",
    "        'verbose': 0,\n",
    "        'auto_class_weights' : \"Balanced\",\n",
    "        'random_state': 13,\n",
    "        'boosting_type' : 'Plain',\n",
    "        'task_type': 'CPU',  \n",
    "        #=================#\n",
    "\n",
    "\n",
    "        'iterations': trial.suggest_int('iterations', 1000 , 2000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05),\n",
    "        'depth': trial.suggest_int('depth', 3, 8),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.1, 1.5),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 0.3),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.2, 1),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 2, 4),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "        'max_ctr_complexity': trial.suggest_int('max_ctr_complexity', 0, 3),\n",
    "        \n",
    "    }\n",
    "\n",
    "    __model: CatBoostClassifier = CatBoostClassifier(**cb_params)\n",
    "    validator: StratifiedKFold = StratifiedKFold(\n",
    "        n_splits=10, \n",
    "        shuffle=True, \n",
    "        random_state=13\n",
    "        )\n",
    "    score = cross_val_score(\n",
    "        __model,\n",
    "        X_encoded,\n",
    "        Y_MAPED,\n",
    "        scoring='accuracy',\n",
    "        cv=validator,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    ).mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "class func:\n",
    "    pass\n",
    "def objective(model_name: enum_model) -> func:\n",
    "    match(model_name.getModelType()):\n",
    "        case \"XGBM\": return _obj_for_xgbm\n",
    "        case \"LGBM\": return _obj_for_lgbm\n",
    "        case \"CB\"  : return _obj_for_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "766cefd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:06:54,054] A new study created in RDB with name: xgbm_study\n",
      "[I 2025-12-25 16:06:59,451] Trial 6 finished with value: 0.8329311807200724 and parameters: {'colsample_bytree': 0.700194855958183, 'colsample_bylevel': 0.8366266956813858, 'colsample_bynode': 0.7373573180754142, 'gamma': 0.6917558290608926, 'learning_rate': 0.04672230323354876, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1337, 'reg_alpha': 0.255025034813558, 'reg_lambda': 1.09846781017725, 'subsample': 0.9451319144666979}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:02,100] Trial 5 finished with value: 0.826432394489778 and parameters: {'colsample_bytree': 0.7682327993361835, 'colsample_bylevel': 0.913831309059201, 'colsample_bynode': 0.9837329653765468, 'gamma': 0.45201396910651975, 'learning_rate': 0.028563806194069306, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1376, 'reg_alpha': 1.2747299874222902, 'reg_lambda': 0.4953069750963357, 'subsample': 0.8195302592644873}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:03,491] Trial 4 finished with value: 0.8153388318563366 and parameters: {'colsample_bytree': 0.7892157295166223, 'colsample_bylevel': 0.9955261439535796, 'colsample_bynode': 0.7646171590724395, 'gamma': 0.80319061048684, 'learning_rate': 0.02076225165463363, 'max_depth': 4, 'min_child_weight': 0, 'n_estimators': 1426, 'reg_alpha': 0.15562835726184102, 'reg_lambda': 0.6669969777616418, 'subsample': 0.9499398457720989}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:04,985] Trial 0 finished with value: 0.8283466409288994 and parameters: {'colsample_bytree': 0.8711311540036808, 'colsample_bylevel': 0.7478689148481743, 'colsample_bynode': 0.8357968284070497, 'gamma': 0.674130702136251, 'learning_rate': 0.03717000697299121, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1302, 'reg_alpha': 0.29334235290042987, 'reg_lambda': 0.5165545332943776, 'subsample': 0.8201396712710455}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:06,187] Trial 2 finished with value: 0.8107586791845808 and parameters: {'colsample_bytree': 0.4809252660416893, 'colsample_bylevel': 0.7678264056725465, 'colsample_bynode': 0.9393924459731918, 'gamma': 0.7072877045521766, 'learning_rate': 0.04704120578798736, 'max_depth': 3, 'min_child_weight': 0, 'n_estimators': 1989, 'reg_alpha': 1.2951688781413564, 'reg_lambda': 1.0418129370469484, 'subsample': 0.8320214420422337}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:07,929] Trial 3 finished with value: 0.8187885700915446 and parameters: {'colsample_bytree': 0.6038249438177823, 'colsample_bylevel': 0.8456643953096024, 'colsample_bynode': 0.7815695068898411, 'gamma': 0.577544030454274, 'learning_rate': 0.01809853476805187, 'max_depth': 4, 'min_child_weight': 0, 'n_estimators': 1770, 'reg_alpha': 0.3178919319756942, 'reg_lambda': 0.7806757951525959, 'subsample': 0.9776908408879419}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:08,989] Trial 1 finished with value: 0.8145783978239887 and parameters: {'colsample_bytree': 0.6378519076685247, 'colsample_bylevel': 0.9676956572861206, 'colsample_bynode': 0.9516876377190064, 'gamma': 0.4842521788950267, 'learning_rate': 0.038036900764382056, 'max_depth': 3, 'min_child_weight': 0, 'n_estimators': 1820, 'reg_alpha': 0.15551103803229047, 'reg_lambda': 0.927306087694855, 'subsample': 0.8316857518766775}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:09,650] Trial 8 finished with value: 0.8184112778216491 and parameters: {'colsample_bytree': 0.3158172077054134, 'colsample_bylevel': 0.8737140577213319, 'colsample_bynode': 0.7084125897361686, 'gamma': 0.3729698579069129, 'learning_rate': 0.029882665665105036, 'max_depth': 4, 'min_child_weight': 0, 'n_estimators': 1087, 'reg_alpha': 1.125073916744254, 'reg_lambda': 0.6519821093348898, 'subsample': 0.9606816958023043}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:11,558] Trial 11 finished with value: 0.8260492527273259 and parameters: {'colsample_bytree': 0.8609625323194301, 'colsample_bylevel': 0.8476278079396606, 'colsample_bynode': 0.7627006769018125, 'gamma': 0.6198158399656607, 'learning_rate': 0.04283660218010426, 'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 1688, 'reg_alpha': 0.847132414822266, 'reg_lambda': 0.8220041138196763, 'subsample': 0.8411521241621536}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:12,744] Trial 10 finished with value: 0.8199248340206488 and parameters: {'colsample_bytree': 0.5005790737144918, 'colsample_bylevel': 0.812300138199383, 'colsample_bynode': 0.8764912190007175, 'gamma': 0.848611158884216, 'learning_rate': 0.03136180785063744, 'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 1285, 'reg_alpha': 1.1782224567040678, 'reg_lambda': 0.7451180596799325, 'subsample': 0.8816640347281002}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:14,269] Trial 9 finished with value: 0.8268228481179257 and parameters: {'colsample_bytree': 0.31485602157690057, 'colsample_bylevel': 0.7793115469289691, 'colsample_bynode': 0.9852584154147085, 'gamma': 0.5895502515323534, 'learning_rate': 0.035998065458037624, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1261, 'reg_alpha': 0.4642014629507215, 'reg_lambda': 0.5835000407093109, 'subsample': 0.9163640338109661}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:15,405] Trial 7 finished with value: 0.8294931414699775 and parameters: {'colsample_bytree': 0.5523788935067637, 'colsample_bylevel': 0.9733012220172899, 'colsample_bynode': 0.7756421496803866, 'gamma': 0.7941407207358442, 'learning_rate': 0.04121652587802353, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1347, 'reg_alpha': 0.21215743463522052, 'reg_lambda': 0.9942614511278609, 'subsample': 0.8871678801248966}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:16,235] Trial 12 finished with value: 0.8092304992541898 and parameters: {'colsample_bytree': 0.6070687763204207, 'colsample_bylevel': 0.9442019909663744, 'colsample_bynode': 0.8390945944689845, 'gamma': 0.7494325349477418, 'learning_rate': 0.043594505211994754, 'max_depth': 3, 'min_child_weight': 0, 'n_estimators': 1143, 'reg_alpha': 1.30523345783924, 'reg_lambda': 0.13985026803788764, 'subsample': 0.9430661250385105}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:17,243] Trial 13 finished with value: 0.8145725483314322 and parameters: {'colsample_bytree': 0.3473486187050079, 'colsample_bylevel': 0.8724196071353907, 'colsample_bynode': 0.8916720112369433, 'gamma': 0.7349113441488124, 'learning_rate': 0.03998110473263891, 'max_depth': 4, 'min_child_weight': 0, 'n_estimators': 1782, 'reg_alpha': 1.2790375179125553, 'reg_lambda': 1.2784565765598852, 'subsample': 0.8730778436583442}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:18,512] Trial 14 finished with value: 0.8206940422918312 and parameters: {'colsample_bytree': 0.6916182822802343, 'colsample_bylevel': 0.9491898633648579, 'colsample_bynode': 0.7560115890873058, 'gamma': 0.30275594911790943, 'learning_rate': 0.04706791636390249, 'max_depth': 4, 'min_child_weight': 0, 'n_estimators': 1108, 'reg_alpha': 0.7028955693348695, 'reg_lambda': 1.4060886166530473, 'subsample': 0.8173741984167703}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:19,749] Trial 15 finished with value: 0.8145798601971279 and parameters: {'colsample_bytree': 0.6288085896576663, 'colsample_bylevel': 0.8950818985282754, 'colsample_bynode': 0.781241035523387, 'gamma': 0.9107118339817719, 'learning_rate': 0.01618415183195037, 'max_depth': 4, 'min_child_weight': 0, 'n_estimators': 1330, 'reg_alpha': 1.4455656778215737, 'reg_lambda': 0.7140792918865397, 'subsample': 0.9520242788229719}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:21,263] Trial 16 finished with value: 0.8184039659559532 and parameters: {'colsample_bytree': 0.45120523681583236, 'colsample_bylevel': 0.8123163759923591, 'colsample_bynode': 0.9666721097759373, 'gamma': 0.9192340946890141, 'learning_rate': 0.029123263855812674, 'max_depth': 5, 'min_child_weight': 0, 'n_estimators': 1454, 'reg_alpha': 0.9676360365779858, 'reg_lambda': 1.2345138458835963, 'subsample': 0.8159009559064162}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:22,024] Trial 17 finished with value: 0.8142011055540932 and parameters: {'colsample_bytree': 0.7634517432016076, 'colsample_bylevel': 0.9263967946551909, 'colsample_bynode': 0.8185814391560806, 'gamma': 0.7718810263165468, 'learning_rate': 0.03069673829018406, 'max_depth': 4, 'min_child_weight': 0, 'n_estimators': 1047, 'reg_alpha': 1.1473272525034728, 'reg_lambda': 1.1203305771511978, 'subsample': 0.9768342430511286}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:23,416] Trial 18 finished with value: 0.820322599514492 and parameters: {'colsample_bytree': 0.41470484303522537, 'colsample_bylevel': 0.7404769266486861, 'colsample_bynode': 0.7025175287438363, 'gamma': 0.6109892149145029, 'learning_rate': 0.048419861024632166, 'max_depth': 6, 'min_child_weight': 0, 'n_estimators': 1932, 'reg_alpha': 1.3617504336009607, 'reg_lambda': 1.3671279859404253, 'subsample': 0.8823158690725559}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:24,682] Trial 19 finished with value: 0.8260551022198825 and parameters: {'colsample_bytree': 0.4033636240726898, 'colsample_bylevel': 0.994923673668923, 'colsample_bynode': 0.7638379771707801, 'gamma': 0.9632183588877599, 'learning_rate': 0.029379627419587877, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1160, 'reg_alpha': 1.2628528611029166, 'reg_lambda': 0.7909112362192495, 'subsample': 0.8834223980640002}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:26,264] Trial 20 finished with value: 0.8260477903541869 and parameters: {'colsample_bytree': 0.5712093556526755, 'colsample_bylevel': 0.9834276035293037, 'colsample_bynode': 0.8979017956822902, 'gamma': 0.4336137973172516, 'learning_rate': 0.04514105711320751, 'max_depth': 6, 'min_child_weight': 0, 'n_estimators': 1779, 'reg_alpha': 0.47163139275443877, 'reg_lambda': 0.4936589602312256, 'subsample': 0.9364625612810444}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:26,939] Trial 21 finished with value: 0.8229914304934047 and parameters: {'colsample_bytree': 0.6840313196716259, 'colsample_bylevel': 0.7262739526750673, 'colsample_bynode': 0.7008614918155058, 'gamma': 0.8865765023887848, 'learning_rate': 0.04564963363324265, 'max_depth': 6, 'min_child_weight': 0, 'n_estimators': 1035, 'reg_alpha': 0.5868966300126841, 'reg_lambda': 1.4557575325245968, 'subsample': 0.9225489864323388}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:27,868] Trial 22 finished with value: 0.8241350062882045 and parameters: {'colsample_bytree': 0.8978578034431055, 'colsample_bylevel': 0.704233800151824, 'colsample_bynode': 0.8472075049647962, 'gamma': 0.9695129585603433, 'learning_rate': 0.0492586017268975, 'max_depth': 6, 'min_child_weight': 0, 'n_estimators': 1015, 'reg_alpha': 0.6021977811093617, 'reg_lambda': 1.3762166493632713, 'subsample': 0.9102809827608805}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:29,055] Trial 23 finished with value: 0.8191643999883009 and parameters: {'colsample_bytree': 0.6973516808004324, 'colsample_bylevel': 0.7009805594660301, 'colsample_bynode': 0.706903453776936, 'gamma': 0.9969602912831586, 'learning_rate': 0.04995790497462552, 'max_depth': 6, 'min_child_weight': 0, 'n_estimators': 1552, 'reg_alpha': 0.6309422752351136, 'reg_lambda': 1.3687970001085272, 'subsample': 0.9081043212161531}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:31,613] Trial 24 finished with value: 0.8214603258167354 and parameters: {'colsample_bytree': 0.6983955629011118, 'colsample_bylevel': 0.9059148622770922, 'colsample_bynode': 0.7109460794239955, 'gamma': 0.9997642319008827, 'learning_rate': 0.01006195769920943, 'max_depth': 6, 'min_child_weight': 0, 'n_estimators': 1544, 'reg_alpha': 0.5961117018551134, 'reg_lambda': 1.3899892322185783, 'subsample': 0.8882436278561948}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:32,400] Trial 25 finished with value: 0.8226141382235092 and parameters: {'colsample_bytree': 0.7083207504539345, 'colsample_bylevel': 0.7100175440272206, 'colsample_bynode': 0.7039443721025122, 'gamma': 0.9956043656759732, 'learning_rate': 0.04907353383411486, 'max_depth': 6, 'min_child_weight': 0, 'n_estimators': 1561, 'reg_alpha': 0.6122817548207127, 'reg_lambda': 1.4888164742448848, 'subsample': 0.9166589308139442}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:33,416] Trial 26 finished with value: 0.8222266093416396 and parameters: {'colsample_bytree': 0.487700495605015, 'colsample_bylevel': 0.7082783336995007, 'colsample_bynode': 0.7095013553908535, 'gamma': 0.9860253783812332, 'learning_rate': 0.049294219035861675, 'max_depth': 6, 'min_child_weight': 0, 'n_estimators': 1522, 'reg_alpha': 0.5856114958057641, 'reg_lambda': 1.1499958540415633, 'subsample': 0.9121800383147188}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:34,512] Trial 27 finished with value: 0.8233818841215526 and parameters: {'colsample_bytree': 0.5034179256756348, 'colsample_bylevel': 0.8085693876350873, 'colsample_bynode': 0.7109034082261476, 'gamma': 0.9799287365520578, 'learning_rate': 0.048614309046066825, 'max_depth': 6, 'min_child_weight': 0, 'n_estimators': 1572, 'reg_alpha': 0.5750593431624005, 'reg_lambda': 1.170638846051374, 'subsample': 0.9137524670688533}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:35,466] Trial 28 finished with value: 0.8268184609985084 and parameters: {'colsample_bytree': 0.7297102273671986, 'colsample_bylevel': 0.7024566124795402, 'colsample_bynode': 0.7239883796720993, 'gamma': 0.9910799892317276, 'learning_rate': 0.049699755886706096, 'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 1580, 'reg_alpha': 0.5427463147312794, 'reg_lambda': 1.082236199679721, 'subsample': 0.9192769132363152}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:36,875] Trial 29 finished with value: 0.8275818197771345 and parameters: {'colsample_bytree': 0.5341867581140622, 'colsample_bylevel': 0.720270460057691, 'colsample_bynode': 0.7153745933714899, 'gamma': 0.84879150335807, 'learning_rate': 0.04957700388799545, 'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 1608, 'reg_alpha': 0.5552796363478385, 'reg_lambda': 1.4648912373485834, 'subsample': 0.9183095371692886}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:39,438] Trial 30 finished with value: 0.8233716475095786 and parameters: {'colsample_bytree': 0.5378590224209373, 'colsample_bylevel': 0.712209408073454, 'colsample_bynode': 0.7328115993657233, 'gamma': 0.8525268208902838, 'learning_rate': 0.011327444427478184, 'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 1559, 'reg_alpha': 0.5856722337863862, 'reg_lambda': 1.0500060241802562, 'subsample': 0.9169328825675336}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:41,901] Trial 31 finished with value: 0.8272001403878214 and parameters: {'colsample_bytree': 0.5501536637567358, 'colsample_bylevel': 0.7109420869786411, 'colsample_bynode': 0.7312650277752839, 'gamma': 0.8512900075412305, 'learning_rate': 0.010111433343493563, 'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 1599, 'reg_alpha': 0.5875230824829816, 'reg_lambda': 1.025900333425857, 'subsample': 0.9248460674367248}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:42,951] Trial 32 finished with value: 0.8229914304934047 and parameters: {'colsample_bytree': 0.8822366900869328, 'colsample_bylevel': 0.7080984925818423, 'colsample_bynode': 0.8120993864652722, 'gamma': 0.6989083707851974, 'learning_rate': 0.03661055383256085, 'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 1538, 'reg_alpha': 0.3350727224667507, 'reg_lambda': 0.30517612913480485, 'subsample': 0.9159956490549565}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:45,216] Trial 33 finished with value: 0.829870433739873 and parameters: {'colsample_bytree': 0.8996694698683436, 'colsample_bylevel': 0.7061683659623186, 'colsample_bynode': 0.8101640608030918, 'gamma': 0.6761598655313759, 'learning_rate': 0.035495735201813365, 'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 1581, 'reg_alpha': 0.3334206552948485, 'reg_lambda': 0.3116890569120107, 'subsample': 0.8649705315599195}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:47,767] Trial 34 finished with value: 0.8306381796379165 and parameters: {'colsample_bytree': 0.5514139618148332, 'colsample_bylevel': 0.8122872123953994, 'colsample_bynode': 0.8088448306816818, 'gamma': 0.6835596354415187, 'learning_rate': 0.01004348615945419, 'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 1547, 'reg_alpha': 0.301945828819445, 'reg_lambda': 0.29074637079497323, 'subsample': 0.8582107872180637}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:50,387] Trial 35 finished with value: 0.8291099997075253 and parameters: {'colsample_bytree': 0.542518616148013, 'colsample_bylevel': 0.8137893369097982, 'colsample_bynode': 0.8210795959163313, 'gamma': 0.6997309211439235, 'learning_rate': 0.010282323517130761, 'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 1582, 'reg_alpha': 0.29352068378888446, 'reg_lambda': 0.34021045105114855, 'subsample': 0.9990541886176151}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:50,981] Trial 36 finished with value: 0.8310183966540903 and parameters: {'colsample_bytree': 0.5334081211040854, 'colsample_bylevel': 0.8229945156503575, 'colsample_bynode': 0.8067433829457749, 'gamma': 0.6799281691531395, 'learning_rate': 0.03589901509785319, 'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 1246, 'reg_alpha': 0.2907126553717946, 'reg_lambda': 0.3261193680869673, 'subsample': 0.9911099903939398}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:52,233] Trial 37 finished with value: 0.826433856862917 and parameters: {'colsample_bytree': 0.5557396780566399, 'colsample_bylevel': 0.8176929237033315, 'colsample_bynode': 0.8130513335195518, 'gamma': 0.6717123817208684, 'learning_rate': 0.035512939304668034, 'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 1230, 'reg_alpha': 0.2917994508558029, 'reg_lambda': 0.21965148995429773, 'subsample': 0.8580352252630938}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:53,384] Trial 38 finished with value: 0.8291114620806643 and parameters: {'colsample_bytree': 0.5500449258414258, 'colsample_bylevel': 0.8155725181430041, 'colsample_bynode': 0.8035078531992645, 'gamma': 0.6836362917619552, 'learning_rate': 0.03589857128505134, 'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 1227, 'reg_alpha': 0.258082301201749, 'reg_lambda': 0.18018932825470102, 'subsample': 0.859554802677929}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:54,608] Trial 39 finished with value: 0.829870433739873 and parameters: {'colsample_bytree': 0.8243772839574948, 'colsample_bylevel': 0.7659982323013265, 'colsample_bynode': 0.815239834842198, 'gamma': 0.6828938787415431, 'learning_rate': 0.0351888569407494, 'max_depth': 7, 'min_child_weight': 0, 'n_estimators': 1223, 'reg_alpha': 0.2927193756735868, 'reg_lambda': 0.28121712918995445, 'subsample': 0.9971641601329689}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:56,228] Trial 40 finished with value: 0.8260551022198823 and parameters: {'colsample_bytree': 0.5556744296955165, 'colsample_bylevel': 0.7727721868490268, 'colsample_bynode': 0.8167037891317904, 'gamma': 0.6713287162041286, 'learning_rate': 0.03595167543435677, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1241, 'reg_alpha': 0.10909775845526967, 'reg_lambda': 0.9119164619798564, 'subsample': 0.8469757901882212}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:57,635] Trial 41 finished with value: 0.8310140095346729 and parameters: {'colsample_bytree': 0.8247524413801026, 'colsample_bylevel': 0.7650956672271323, 'colsample_bynode': 0.8146095725091529, 'gamma': 0.6793848530612495, 'learning_rate': 0.036269865586476366, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1218, 'reg_alpha': 0.1296801327568948, 'reg_lambda': 0.9563724345272437, 'subsample': 0.8575291117150723}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:07:59,150] Trial 42 finished with value: 0.8306323301453599 and parameters: {'colsample_bytree': 0.553516737385521, 'colsample_bylevel': 0.7493735638066181, 'colsample_bynode': 0.7992193826933327, 'gamma': 0.6740864313769138, 'learning_rate': 0.03924678495821443, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1242, 'reg_alpha': 0.2316871310344681, 'reg_lambda': 0.8990292336104664, 'subsample': 0.8563871253932106}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:08:00,833] Trial 43 finished with value: 0.8256778099499869 and parameters: {'colsample_bytree': 0.8186254193960484, 'colsample_bylevel': 0.7551181337069284, 'colsample_bynode': 0.8122803114698017, 'gamma': 0.6788522589061065, 'learning_rate': 0.03887090730975119, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1229, 'reg_alpha': 0.10252969096976633, 'reg_lambda': 0.9257456606276482, 'subsample': 0.8558297479072003}. Best is trial 6 with value: 0.8329311807200724.\n",
      "[I 2025-12-25 16:08:01,860] Trial 44 finished with value: 0.8348483519054721 and parameters: {'colsample_bytree': 0.6629506354849434, 'colsample_bylevel': 0.7608426444691376, 'colsample_bynode': 0.7964685684175228, 'gamma': 0.6779205303297494, 'learning_rate': 0.040803984002659034, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1225, 'reg_alpha': 0.10190980346908472, 'reg_lambda': 0.9427251689165057, 'subsample': 0.8573575194549008}. Best is trial 44 with value: 0.8348483519054721.\n",
      "[I 2025-12-25 16:08:03,219] Trial 45 finished with value: 0.82948875435056 and parameters: {'colsample_bytree': 0.8312459230146838, 'colsample_bylevel': 0.7527302225592888, 'colsample_bynode': 0.8077857089575591, 'gamma': 0.669767292379227, 'learning_rate': 0.039019208212129994, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1208, 'reg_alpha': 0.10237000400068258, 'reg_lambda': 0.9182342051538858, 'subsample': 0.8536579157310653}. Best is trial 44 with value: 0.8348483519054721.\n",
      "[I 2025-12-25 16:08:05,238] Trial 46 finished with value: 0.8337003889912549 and parameters: {'colsample_bytree': 0.8237315250083933, 'colsample_bylevel': 0.7815311604175978, 'colsample_bynode': 0.8076538357223219, 'gamma': 0.5385689275391209, 'learning_rate': 0.03371447048253319, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1660, 'reg_alpha': 0.10825489696142968, 'reg_lambda': 0.3305102533647584, 'subsample': 0.855787933933887}. Best is trial 44 with value: 0.8348483519054721.\n",
      "[I 2025-12-25 16:08:06,919] Trial 47 finished with value: 0.827962036793308 and parameters: {'colsample_bytree': 0.8240347619097148, 'colsample_bylevel': 0.7899455734259988, 'colsample_bynode': 0.7911670617163274, 'gamma': 0.550451481499048, 'learning_rate': 0.04006685827778092, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1670, 'reg_alpha': 0.10765858045978918, 'reg_lambda': 0.920795150528013, 'subsample': 0.8545914430343257}. Best is trial 44 with value: 0.8348483519054721.\n",
      "[I 2025-12-25 16:08:08,792] Trial 48 finished with value: 0.826814073879091 and parameters: {'colsample_bytree': 0.8416266500167338, 'colsample_bylevel': 0.7777912230127506, 'colsample_bynode': 0.7987996287096097, 'gamma': 0.5288848640215751, 'learning_rate': 0.025709913225191713, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1223, 'reg_alpha': 0.3980099916860541, 'reg_lambda': 0.11643738094140521, 'subsample': 0.8586086665856771}. Best is trial 44 with value: 0.8348483519054721.\n",
      "[I 2025-12-25 16:08:10,295] Trial 49 finished with value: 0.8298777456055688 and parameters: {'colsample_bytree': 0.8271071413178253, 'colsample_bylevel': 0.8344744604650215, 'colsample_bynode': 0.7987494964643677, 'gamma': 0.530640385440084, 'learning_rate': 0.02572950769772446, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 1434, 'reg_alpha': 0.11340538036427311, 'reg_lambda': 0.3960578587968031, 'subsample': 0.800012604986873}. Best is trial 44 with value: 0.8348483519054721.\n"
     ]
    }
   ],
   "source": [
    "xgbm_obj: func = objective(enum_model(\"XGBM\"))\n",
    "\n",
    "storage_path_xgbm: str = \"sqlite:///xgbm_study.db\"\n",
    "study_xgbm: optuna.Study = optuna.study.create_study(\n",
    "    study_name = \"xgbm_study\",\n",
    "    storage  = storage_path_xgbm,\n",
    "    direction= 'maximize',\n",
    "    )\n",
    "study_xgbm.optimize(\n",
    "    func = xgbm_obj,\n",
    "    n_trials = 50,\n",
    "    n_jobs = -1,\n",
    "    show_progress_bar = False,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fad5629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:08:10,462] A new study created in RDB with name: lgbm_study\n",
      "[I 2025-12-25 16:08:19,086] Trial 4 finished with value: 0.8199394577520399 and parameters: {'colsample_bytree': 0.3431038552676605, 'learning_rate': 0.041001702092872405, 'max_depth': 7, 'min_child_samples': 3, 'min_child_weight': 0.601487006456602, 'n_estimators': 1652, 'max_bin': 49, 'reg_alpha': 1.4466506183344159, 'reg_lambda': 1.1796907232023568, 'subsample': 0.8557853869328909}. Best is trial 4 with value: 0.8199394577520399.\n",
      "[I 2025-12-25 16:08:22,643] Trial 1 finished with value: 0.8260551022198825 and parameters: {'colsample_bytree': 0.6757372688837648, 'learning_rate': 0.04202498938988612, 'max_depth': 6, 'min_child_samples': 3, 'min_child_weight': 0.5740428417970086, 'n_estimators': 1976, 'max_bin': 45, 'reg_alpha': 1.0573220460459873, 'reg_lambda': 0.8451738091060396, 'subsample': 0.8083425413144347}. Best is trial 1 with value: 0.8260551022198825.\n",
      "[I 2025-12-25 16:08:25,570] Trial 0 finished with value: 0.8176420695504666 and parameters: {'colsample_bytree': 0.7468986229083161, 'learning_rate': 0.03848918895820953, 'max_depth': 4, 'min_child_samples': 4, 'min_child_weight': 0.39582894809079494, 'n_estimators': 1288, 'max_bin': 54, 'reg_alpha': 1.468831187448422, 'reg_lambda': 0.5551834618283743, 'subsample': 0.8891483957698223}. Best is trial 1 with value: 0.8260551022198825.\n",
      "[I 2025-12-25 16:08:30,024] Trial 2 finished with value: 0.820702816530666 and parameters: {'colsample_bytree': 0.8001116792179352, 'learning_rate': 0.032550178353475165, 'max_depth': 5, 'min_child_samples': 8, 'min_child_weight': 0.3891295841120097, 'n_estimators': 1290, 'max_bin': 52, 'reg_alpha': 0.14895770664378105, 'reg_lambda': 0.8642612367678212, 'subsample': 0.9982178712557253}. Best is trial 1 with value: 0.8260551022198825.\n",
      "[I 2025-12-25 16:08:37,084] Trial 5 finished with value: 0.813445058641163 and parameters: {'colsample_bytree': 0.6900766672489391, 'learning_rate': 0.04828984930514249, 'max_depth': 3, 'min_child_samples': 4, 'min_child_weight': 0.7581663652880761, 'n_estimators': 1188, 'max_bin': 56, 'reg_alpha': 0.3501111529226172, 'reg_lambda': 1.1249668028413324, 'subsample': 0.8918749439020317}. Best is trial 1 with value: 0.8260551022198825.\n",
      "[I 2025-12-25 16:08:38,943] Trial 3 finished with value: 0.8256734228305694 and parameters: {'colsample_bytree': 0.6261047314383009, 'learning_rate': 0.02451074551238723, 'max_depth': 8, 'min_child_samples': 8, 'min_child_weight': 0.6070606422705083, 'n_estimators': 1556, 'max_bin': 63, 'reg_alpha': 0.28062756516089427, 'reg_lambda': 1.4121899848885429, 'subsample': 0.9998796602576903}. Best is trial 1 with value: 0.8260551022198825.\n",
      "[I 2025-12-25 16:08:44,476] Trial 9 finished with value: 0.8206969670381093 and parameters: {'colsample_bytree': 0.8019276058672378, 'learning_rate': 0.03412441221717941, 'max_depth': 8, 'min_child_samples': 4, 'min_child_weight': 0.7115409457803733, 'n_estimators': 1280, 'max_bin': 35, 'reg_alpha': 0.8620232098730368, 'reg_lambda': 0.35672334722945964, 'subsample': 0.8164833913107937}. Best is trial 1 with value: 0.8260551022198825.\n",
      "[I 2025-12-25 16:08:46,579] Trial 7 finished with value: 0.8161212014857713 and parameters: {'colsample_bytree': 0.6882424996515177, 'learning_rate': 0.03594426127540767, 'max_depth': 4, 'min_child_samples': 8, 'min_child_weight': 0.6835352194119848, 'n_estimators': 1305, 'max_bin': 42, 'reg_alpha': 0.2255543154517336, 'reg_lambda': 0.7597763826532816, 'subsample': 0.8509113519801978}. Best is trial 1 with value: 0.8260551022198825.\n",
      "[I 2025-12-25 16:08:48,221] Trial 6 finished with value: 0.7996607294317217 and parameters: {'colsample_bytree': 0.7238197395483161, 'learning_rate': 0.01542029730038864, 'max_depth': 3, 'min_child_samples': 5, 'min_child_weight': 0.6698329464976158, 'n_estimators': 1276, 'max_bin': 56, 'reg_alpha': 1.4087558420378588, 'reg_lambda': 0.4684206317730042, 'subsample': 0.8028111300807025}. Best is trial 1 with value: 0.8260551022198825.\n",
      "[I 2025-12-25 16:08:56,591] Trial 8 finished with value: 0.8230016671053786 and parameters: {'colsample_bytree': 0.8177599391957411, 'learning_rate': 0.01931425498277034, 'max_depth': 7, 'min_child_samples': 5, 'min_child_weight': 0.3661395343087541, 'n_estimators': 1982, 'max_bin': 40, 'reg_alpha': 1.4886646740280123, 'reg_lambda': 1.1516773103791138, 'subsample': 0.9078082674570842}. Best is trial 1 with value: 0.8260551022198825.\n",
      "[I 2025-12-25 16:09:01,582] Trial 10 finished with value: 0.8210771840542833 and parameters: {'colsample_bytree': 0.5321541667591778, 'learning_rate': 0.020445420392878392, 'max_depth': 5, 'min_child_samples': 4, 'min_child_weight': 0.31184962567611785, 'n_estimators': 1471, 'max_bin': 37, 'reg_alpha': 1.295141428806352, 'reg_lambda': 0.860762335548428, 'subsample': 0.8905840217615845}. Best is trial 1 with value: 0.8260551022198825.\n",
      "[I 2025-12-25 16:09:08,473] Trial 11 finished with value: 0.8214676376824311 and parameters: {'colsample_bytree': 0.8787924943473966, 'learning_rate': 0.02369699391717793, 'max_depth': 8, 'min_child_samples': 4, 'min_child_weight': 0.53279511835605, 'n_estimators': 1125, 'max_bin': 42, 'reg_alpha': 1.4264637867245573, 'reg_lambda': 1.3527304546848866, 'subsample': 0.8347579574809119}. Best is trial 1 with value: 0.8260551022198825.\n",
      "[I 2025-12-25 16:09:11,956] Trial 13 finished with value: 0.8123000204732239 and parameters: {'colsample_bytree': 0.761028050442383, 'learning_rate': 0.04706795122667803, 'max_depth': 3, 'min_child_samples': 7, 'min_child_weight': 0.41298497018057495, 'n_estimators': 1294, 'max_bin': 45, 'reg_alpha': 0.6346378071208096, 'reg_lambda': 1.3403280335652648, 'subsample': 0.8291636839208797}. Best is trial 1 with value: 0.8260551022198825.\n",
      "[I 2025-12-25 16:09:12,551] Trial 12 finished with value: 0.8142069550466499 and parameters: {'colsample_bytree': 0.34150093015158545, 'learning_rate': 0.048386190126750925, 'max_depth': 4, 'min_child_samples': 3, 'min_child_weight': 0.38960973343299815, 'n_estimators': 1784, 'max_bin': 37, 'reg_alpha': 0.840508703975652, 'reg_lambda': 0.4602853773570359, 'subsample': 0.9129797531793207}. Best is trial 1 with value: 0.8260551022198825.\n",
      "[I 2025-12-25 16:09:20,601] Trial 14 finished with value: 0.826441168728613 and parameters: {'colsample_bytree': 0.4274891919994228, 'learning_rate': 0.030565455929705505, 'max_depth': 7, 'min_child_samples': 5, 'min_child_weight': 0.3419404783931704, 'n_estimators': 1956, 'max_bin': 40, 'reg_alpha': 0.9453301877328952, 'reg_lambda': 0.12244754256495327, 'subsample': 0.9729475185277829}. Best is trial 14 with value: 0.826441168728613.\n",
      "[I 2025-12-25 16:09:22,414] Trial 15 finished with value: 0.8168801731449797 and parameters: {'colsample_bytree': 0.5385298071822365, 'learning_rate': 0.038190323379277046, 'max_depth': 3, 'min_child_samples': 8, 'min_child_weight': 0.5486190450429786, 'n_estimators': 1872, 'max_bin': 60, 'reg_alpha': 0.2310523356808079, 'reg_lambda': 0.9512999872209517, 'subsample': 0.9449741312389053}. Best is trial 14 with value: 0.826441168728613.\n",
      "[I 2025-12-25 16:09:24,663] Trial 16 finished with value: 0.8103755374221286 and parameters: {'colsample_bytree': 0.6385685651660168, 'learning_rate': 0.020780226203881248, 'max_depth': 3, 'min_child_samples': 6, 'min_child_weight': 0.6267450759544042, 'n_estimators': 1579, 'max_bin': 58, 'reg_alpha': 1.0830684536612343, 'reg_lambda': 1.3821278226257852, 'subsample': 0.8671094903847155}. Best is trial 14 with value: 0.826441168728613.\n",
      "[I 2025-12-25 16:09:32,830] Trial 18 finished with value: 0.8100011698985113 and parameters: {'colsample_bytree': 0.8803747643088939, 'learning_rate': 0.024398177987252273, 'max_depth': 3, 'min_child_samples': 8, 'min_child_weight': 0.672896944456133, 'n_estimators': 1339, 'max_bin': 64, 'reg_alpha': 1.4308843639954663, 'reg_lambda': 0.6402259741597828, 'subsample': 0.9763693761893668}. Best is trial 14 with value: 0.826441168728613.\n",
      "[I 2025-12-25 16:09:33,395] Trial 17 finished with value: 0.8229943552396829 and parameters: {'colsample_bytree': 0.5344667515430097, 'learning_rate': 0.014844114814180479, 'max_depth': 6, 'min_child_samples': 6, 'min_child_weight': 0.461516069388641, 'n_estimators': 1508, 'max_bin': 44, 'reg_alpha': 0.6389227772414952, 'reg_lambda': 0.2433934673636164, 'subsample': 0.9205345507348306}. Best is trial 14 with value: 0.826441168728613.\n",
      "[I 2025-12-25 16:09:37,636] Trial 19 finished with value: 0.8233716475095785 and parameters: {'colsample_bytree': 0.4111264367710877, 'learning_rate': 0.04909492701458343, 'max_depth': 8, 'min_child_samples': 4, 'min_child_weight': 0.5073239425704416, 'n_estimators': 1840, 'max_bin': 37, 'reg_alpha': 1.3512500975782613, 'reg_lambda': 0.4190307171064399, 'subsample': 0.8164630543083685}. Best is trial 14 with value: 0.826441168728613.\n",
      "[I 2025-12-25 16:09:46,332] Trial 20 finished with value: 0.8268184609985084 and parameters: {'colsample_bytree': 0.6860652418493454, 'learning_rate': 0.020613423460638713, 'max_depth': 7, 'min_child_samples': 6, 'min_child_weight': 0.4687844822672785, 'n_estimators': 1993, 'max_bin': 51, 'reg_alpha': 1.220961564633308, 'reg_lambda': 0.1299384308737666, 'subsample': 0.9910354425413771}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:09:49,022] Trial 21 finished with value: 0.8252858939487 and parameters: {'colsample_bytree': 0.5153348213734162, 'learning_rate': 0.049998710366917075, 'max_depth': 6, 'min_child_samples': 6, 'min_child_weight': 0.47942221920321704, 'n_estimators': 1965, 'max_bin': 43, 'reg_alpha': 1.0099245377953845, 'reg_lambda': 0.13471301934805457, 'subsample': 0.9381663697461746}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:09:57,404] Trial 22 finished with value: 0.8256763475768478 and parameters: {'colsample_bytree': 0.5385558110906397, 'learning_rate': 0.025003987267685747, 'max_depth': 8, 'min_child_samples': 7, 'min_child_weight': 0.5087799971653846, 'n_estimators': 2000, 'max_bin': 64, 'reg_alpha': 0.9158855886207442, 'reg_lambda': 1.4824344218449945, 'subsample': 0.9973080165008918}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:10:04,016] Trial 23 finished with value: 0.8252975929338129 and parameters: {'colsample_bytree': 0.5547602020576151, 'learning_rate': 0.02804488711169533, 'max_depth': 6, 'min_child_samples': 7, 'min_child_weight': 0.5157307900813022, 'n_estimators': 1937, 'max_bin': 60, 'reg_alpha': 0.9002702976720312, 'reg_lambda': 1.4883473360549888, 'subsample': 0.9974564607342384}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:10:10,195] Trial 24 finished with value: 0.8233833464946917 and parameters: {'colsample_bytree': 0.5541503317771167, 'learning_rate': 0.026723304920320604, 'max_depth': 6, 'min_child_samples': 6, 'min_child_weight': 0.5295696811670703, 'n_estimators': 1906, 'max_bin': 64, 'reg_alpha': 1.0998774254150836, 'reg_lambda': 0.10559720095896463, 'subsample': 0.9962736575819758}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:10:16,104] Trial 25 finished with value: 0.8222353835804744 and parameters: {'colsample_bytree': 0.5767392533974645, 'learning_rate': 0.028651169658536778, 'max_depth': 6, 'min_child_samples': 6, 'min_child_weight': 0.5207676013072382, 'n_estimators': 1955, 'max_bin': 64, 'reg_alpha': 1.0646513606455419, 'reg_lambda': 0.11772878800938302, 'subsample': 0.9840801773265428}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:10:22,869] Trial 26 finished with value: 0.8199350706326227 and parameters: {'colsample_bytree': 0.4785961972422047, 'learning_rate': 0.027561248160966063, 'max_depth': 6, 'min_child_samples': 6, 'min_child_weight': 0.4989337650818009, 'n_estimators': 1993, 'max_bin': 33, 'reg_alpha': 1.0427173879843668, 'reg_lambda': 0.20674479663168321, 'subsample': 0.9515439662594147}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:10:25,138] Trial 27 finished with value: 0.8233921207335264 and parameters: {'colsample_bytree': 0.45198572178198515, 'learning_rate': 0.028303857591116064, 'max_depth': 6, 'min_child_samples': 6, 'min_child_weight': 0.4769724614808364, 'n_estimators': 1966, 'max_bin': 46, 'reg_alpha': 1.0657449762092974, 'reg_lambda': 0.192016149274561, 'subsample': 0.9586036187254573}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:10:32,999] Trial 28 finished with value: 0.8214647129361528 and parameters: {'colsample_bytree': 0.4391146944276031, 'learning_rate': 0.028653777861682442, 'max_depth': 6, 'min_child_samples': 6, 'min_child_weight': 0.48727729835222977, 'n_estimators': 1957, 'max_bin': 32, 'reg_alpha': 1.0628326499640885, 'reg_lambda': 0.24119256813927714, 'subsample': 0.9593343172082336}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:10:37,063] Trial 29 finished with value: 0.8229972799859612 and parameters: {'colsample_bytree': 0.4755848229830889, 'learning_rate': 0.02909128088795568, 'max_depth': 6, 'min_child_samples': 6, 'min_child_weight': 0.475909187807836, 'n_estimators': 1992, 'max_bin': 47, 'reg_alpha': 1.0830841296274536, 'reg_lambda': 0.2561498435411169, 'subsample': 0.9391467416884005}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:10:43,070] Trial 30 finished with value: 0.819949694364014 and parameters: {'colsample_bytree': 0.4306094316277668, 'learning_rate': 0.029450622422425753, 'max_depth': 6, 'min_child_samples': 3, 'min_child_weight': 0.46821100505527447, 'n_estimators': 1972, 'max_bin': 49, 'reg_alpha': 1.073608708245819, 'reg_lambda': 0.10827440271986544, 'subsample': 0.9411090514851463}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:10:48,970] Trial 31 finished with value: 0.8214691000555702 and parameters: {'colsample_bytree': 0.44128445303729547, 'learning_rate': 0.029339517358203854, 'max_depth': 6, 'min_child_samples': 3, 'min_child_weight': 0.4685240005694582, 'n_estimators': 1995, 'max_bin': 32, 'reg_alpha': 1.0498474987587498, 'reg_lambda': 0.17229302418547365, 'subsample': 0.9469181058446281}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:10:58,975] Trial 32 finished with value: 0.824140855780761 and parameters: {'colsample_bytree': 0.41220658309391145, 'learning_rate': 0.0104888146471181, 'max_depth': 7, 'min_child_samples': 6, 'min_child_weight': 0.47701543692943027, 'n_estimators': 1991, 'max_bin': 48, 'reg_alpha': 1.1133907973346937, 'reg_lambda': 0.1010152757385326, 'subsample': 0.9605541451784053}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:11:05,678] Trial 33 finished with value: 0.822611213477231 and parameters: {'colsample_bytree': 0.4565134705741746, 'learning_rate': 0.010226793014691931, 'max_depth': 7, 'min_child_samples': 7, 'min_child_weight': 0.3061143488674458, 'n_estimators': 1734, 'max_bin': 48, 'reg_alpha': 1.2099029742917164, 'reg_lambda': 0.1543197023181641, 'subsample': 0.9717164106700514}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:11:08,960] Trial 34 finished with value: 0.8252961305606739 and parameters: {'colsample_bytree': 0.5889058768868161, 'learning_rate': 0.029972076485997267, 'max_depth': 7, 'min_child_samples': 5, 'min_child_weight': 0.3170467310526716, 'n_estimators': 1693, 'max_bin': 49, 'reg_alpha': 1.1887954391397637, 'reg_lambda': 0.1224377667878841, 'subsample': 0.9614542012047784}. Best is trial 20 with value: 0.8268184609985084.\n",
      "[I 2025-12-25 16:11:12,910] Trial 35 finished with value: 0.8268228481179257 and parameters: {'colsample_bytree': 0.4550136414377964, 'learning_rate': 0.04347414519375591, 'max_depth': 7, 'min_child_samples': 5, 'min_child_weight': 0.3023021334034122, 'n_estimators': 1729, 'max_bin': 46, 'reg_alpha': 1.1965259005415732, 'reg_lambda': 0.11421626702180687, 'subsample': 0.9704153174039498}. Best is trial 35 with value: 0.8268228481179257.\n",
      "[I 2025-12-25 16:11:16,591] Trial 36 finished with value: 0.8252932058143957 and parameters: {'colsample_bytree': 0.4597977904192575, 'learning_rate': 0.04426304160955334, 'max_depth': 7, 'min_child_samples': 5, 'min_child_weight': 0.3145156669486928, 'n_estimators': 1741, 'max_bin': 47, 'reg_alpha': 1.171508274930832, 'reg_lambda': 0.2791164264450402, 'subsample': 0.9624894401994094}. Best is trial 35 with value: 0.8268228481179257.\n",
      "[I 2025-12-25 16:11:23,676] Trial 37 finished with value: 0.8245269222894915 and parameters: {'colsample_bytree': 0.4415591735841228, 'learning_rate': 0.01109360180467125, 'max_depth': 7, 'min_child_samples': 5, 'min_child_weight': 0.30552890482259915, 'n_estimators': 1718, 'max_bin': 48, 'reg_alpha': 1.206434976123355, 'reg_lambda': 0.26440459959932605, 'subsample': 0.966582287469535}. Best is trial 35 with value: 0.8268228481179257.\n",
      "[I 2025-12-25 16:11:27,016] Trial 38 finished with value: 0.8245327717820479 and parameters: {'colsample_bytree': 0.43891491216216055, 'learning_rate': 0.0416416977561048, 'max_depth': 7, 'min_child_samples': 5, 'min_child_weight': 0.43948294669540655, 'n_estimators': 1742, 'max_bin': 48, 'reg_alpha': 1.2178878511893096, 'reg_lambda': 0.3058176337220458, 'subsample': 0.9646323914758045}. Best is trial 35 with value: 0.8268228481179257.\n",
      "[I 2025-12-25 16:11:31,202] Trial 39 finished with value: 0.8229899681202655 and parameters: {'colsample_bytree': 0.637458281906713, 'learning_rate': 0.0426325502866374, 'max_depth': 7, 'min_child_samples': 5, 'min_child_weight': 0.30964757422321054, 'n_estimators': 1739, 'max_bin': 48, 'reg_alpha': 1.1825062317087724, 'reg_lambda': 0.3072998125206773, 'subsample': 0.9688673085822225}. Best is trial 35 with value: 0.8268228481179257.\n",
      "[I 2025-12-25 16:11:40,283] Trial 40 finished with value: 0.8226097511040917 and parameters: {'colsample_bytree': 0.6161687127518728, 'learning_rate': 0.010195672537560114, 'max_depth': 7, 'min_child_samples': 5, 'min_child_weight': 0.3046796774738958, 'n_estimators': 1744, 'max_bin': 50, 'reg_alpha': 1.2382764065485836, 'reg_lambda': 0.6554756743716372, 'subsample': 0.9280576704433748}. Best is trial 35 with value: 0.8268228481179257.\n",
      "[I 2025-12-25 16:11:41,973] Trial 41 finished with value: 0.8260536398467433 and parameters: {'colsample_bytree': 0.6438819355305879, 'learning_rate': 0.04318817177187285, 'max_depth': 7, 'min_child_samples': 5, 'min_child_weight': 0.3083977663715072, 'n_estimators': 1741, 'max_bin': 51, 'reg_alpha': 1.1802293757867761, 'reg_lambda': 0.6107896181151367, 'subsample': 0.8758643359638555}. Best is trial 35 with value: 0.8268228481179257.\n",
      "[I 2025-12-25 16:11:50,487] Trial 42 finished with value: 0.8233745722558569 and parameters: {'colsample_bytree': 0.623764254904612, 'learning_rate': 0.011087060908383, 'max_depth': 7, 'min_child_samples': 7, 'min_child_weight': 0.5784841850634477, 'n_estimators': 1785, 'max_bin': 50, 'reg_alpha': 1.216794575379143, 'reg_lambda': 0.5806488689172693, 'subsample': 0.9726656644936829}. Best is trial 35 with value: 0.8268228481179257.\n",
      "[I 2025-12-25 16:11:55,558] Trial 43 finished with value: 0.8241452429001785 and parameters: {'colsample_bytree': 0.6295498657794796, 'learning_rate': 0.04350086900690317, 'max_depth': 7, 'min_child_samples': 7, 'min_child_weight': 0.5716382644556482, 'n_estimators': 1748, 'max_bin': 52, 'reg_alpha': 0.7248705900354632, 'reg_lambda': 0.652553993142746, 'subsample': 0.9792792653429849}. Best is trial 35 with value: 0.8268228481179257.\n",
      "[I 2025-12-25 16:11:59,109] Trial 44 finished with value: 0.823377497002135 and parameters: {'colsample_bytree': 0.6238171536944475, 'learning_rate': 0.0413993627790598, 'max_depth': 7, 'min_child_samples': 7, 'min_child_weight': 0.578183357065787, 'n_estimators': 1774, 'max_bin': 53, 'reg_alpha': 1.2253446458147055, 'reg_lambda': 0.6340521166565909, 'subsample': 0.977967007055149}. Best is trial 35 with value: 0.8268228481179257.\n",
      "[I 2025-12-25 16:12:04,160] Trial 45 finished with value: 0.8260594893392998 and parameters: {'colsample_bytree': 0.6291272728362494, 'learning_rate': 0.04269829786046957, 'max_depth': 7, 'min_child_samples': 5, 'min_child_weight': 0.5846040617951791, 'n_estimators': 1807, 'max_bin': 51, 'reg_alpha': 0.7361791109771678, 'reg_lambda': 0.591634499293896, 'subsample': 0.9816121100761933}. Best is trial 35 with value: 0.8268228481179257.\n",
      "[I 2025-12-25 16:12:06,286] Trial 46 finished with value: 0.8230031294785178 and parameters: {'colsample_bytree': 0.6517493917610856, 'learning_rate': 0.0430990320946855, 'max_depth': 8, 'min_child_samples': 7, 'min_child_weight': 0.4159333463256926, 'n_estimators': 1824, 'max_bin': 53, 'reg_alpha': 0.9434281683768125, 'reg_lambda': 0.6231318405315565, 'subsample': 0.9833958189220074}. Best is trial 35 with value: 0.8268228481179257.\n",
      "[I 2025-12-25 16:12:11,709] Trial 47 finished with value: 0.822230996461057 and parameters: {'colsample_bytree': 0.30831861479116546, 'learning_rate': 0.0436693233036701, 'max_depth': 5, 'min_child_samples': 5, 'min_child_weight': 0.35403421323906115, 'n_estimators': 1817, 'max_bin': 52, 'reg_alpha': 0.7180545714225186, 'reg_lambda': 0.334357654720291, 'subsample': 0.9830158726564414}. Best is trial 35 with value: 0.8268228481179257.\n",
      "[I 2025-12-25 16:12:16,402] Trial 48 finished with value: 0.8195504664970314 and parameters: {'colsample_bytree': 0.30320429701921414, 'learning_rate': 0.0422017138723054, 'max_depth': 5, 'min_child_samples': 5, 'min_child_weight': 0.3525493900898597, 'n_estimators': 1829, 'max_bin': 53, 'reg_alpha': 1.268015200534558, 'reg_lambda': 0.6206764363895911, 'subsample': 0.9833531141788474}. Best is trial 35 with value: 0.8268228481179257.\n",
      "[I 2025-12-25 16:12:18,985] Trial 49 finished with value: 0.8222280717147787 and parameters: {'colsample_bytree': 0.6422245953276897, 'learning_rate': 0.041579893447235866, 'max_depth': 5, 'min_child_samples': 5, 'min_child_weight': 0.3575971079131239, 'n_estimators': 1832, 'max_bin': 52, 'reg_alpha': 0.7377419451941616, 'reg_lambda': 0.569129232974966, 'subsample': 0.9829166511693056}. Best is trial 35 with value: 0.8268228481179257.\n"
     ]
    }
   ],
   "source": [
    "lgbm_obj: func = objective(enum_model(\"LGBM\"))\n",
    "\n",
    "storage_path_lgbm: str = \"sqlite:///lgbm_study.db\"\n",
    "study_lgbm = optuna.create_study(\n",
    "    study_name = \"lgbm_study\",\n",
    "    storage  = storage_path_lgbm,\n",
    "    direction= 'maximize',\n",
    ")\n",
    "study_lgbm.optimize(\n",
    "    func = lgbm_obj,\n",
    "    n_trials = 50,\n",
    "    n_jobs = -1,\n",
    "    show_progress_bar = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9d2fe09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:12:19,226] A new study created in RDB with name: cb_study\n",
      "[I 2025-12-25 16:12:31,773] Trial 4 finished with value: 0.8302448012634904 and parameters: {'iterations': 1055, 'learning_rate': 0.043010373356293694, 'depth': 5, 'l2_leaf_reg': 1.3754822347590832, 'bagging_temperature': 0.03255420478150632, 'random_strength': 0.5582574944524468, 'min_data_in_leaf': 2, 'subsample': 0.7976576865964419, 'max_ctr_complexity': 3}. Best is trial 4 with value: 0.8302448012634904.\n",
      "[I 2025-12-25 16:13:18,390] Trial 5 finished with value: 0.8279620367933083 and parameters: {'iterations': 1933, 'learning_rate': 0.04764776348346921, 'depth': 8, 'l2_leaf_reg': 0.7250641995105248, 'bagging_temperature': 0.047922409886452445, 'random_strength': 0.337638564769554, 'min_data_in_leaf': 2, 'subsample': 0.9517782806834247, 'max_ctr_complexity': 2}. Best is trial 4 with value: 0.8302448012634904.\n",
      "[I 2025-12-25 16:13:31,835] Trial 3 finished with value: 0.824130619168787 and parameters: {'iterations': 1509, 'learning_rate': 0.025757018349165564, 'depth': 5, 'l2_leaf_reg': 1.3468630162474398, 'bagging_temperature': 0.0799312893260997, 'random_strength': 0.6362703572981445, 'min_data_in_leaf': 3, 'subsample': 0.9398711836156041, 'max_ctr_complexity': 0}. Best is trial 4 with value: 0.8302448012634904.\n",
      "[I 2025-12-25 16:13:47,875] Trial 1 finished with value: 0.8291070749612472 and parameters: {'iterations': 1592, 'learning_rate': 0.01670122623823802, 'depth': 7, 'l2_leaf_reg': 0.5141680931689278, 'bagging_temperature': 0.021340256746542007, 'random_strength': 0.8963000036375004, 'min_data_in_leaf': 4, 'subsample': 0.8807643104114459, 'max_ctr_complexity': 3}. Best is trial 4 with value: 0.8302448012634904.\n",
      "[I 2025-12-25 16:14:08,263] Trial 0 finished with value: 0.8145783978239887 and parameters: {'iterations': 1392, 'learning_rate': 0.03717780696063884, 'depth': 3, 'l2_leaf_reg': 0.7977141188566957, 'bagging_temperature': 0.08226023786519271, 'random_strength': 0.771930697592581, 'min_data_in_leaf': 3, 'subsample': 0.802030221479947, 'max_ctr_complexity': 3}. Best is trial 4 with value: 0.8302448012634904.\n",
      "[I 2025-12-25 16:14:11,244] Trial 2 finished with value: 0.8283378666900646 and parameters: {'iterations': 1884, 'learning_rate': 0.03434169600574876, 'depth': 6, 'l2_leaf_reg': 1.4319776129538855, 'bagging_temperature': 0.10115980958187211, 'random_strength': 0.7598590510040761, 'min_data_in_leaf': 2, 'subsample': 0.8062762892737763, 'max_ctr_complexity': 1}. Best is trial 4 with value: 0.8302448012634904.\n",
      "[I 2025-12-25 16:14:38,475] Trial 7 finished with value: 0.8344622853967417 and parameters: {'iterations': 1128, 'learning_rate': 0.010610958056680336, 'depth': 8, 'l2_leaf_reg': 0.7073279103956898, 'bagging_temperature': 0.25888018911640204, 'random_strength': 0.2219792976421985, 'min_data_in_leaf': 2, 'subsample': 0.9925019775175676, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:15:19,856] Trial 8 finished with value: 0.8306396420110556 and parameters: {'iterations': 1625, 'learning_rate': 0.019023331406577387, 'depth': 8, 'l2_leaf_reg': 1.3736767555071718, 'bagging_temperature': 0.11826936849964681, 'random_strength': 0.9847246962861178, 'min_data_in_leaf': 3, 'subsample': 0.7841067012287968, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:15:49,681] Trial 11 finished with value: 0.8233716475095786 and parameters: {'iterations': 1297, 'learning_rate': 0.01483062570660796, 'depth': 5, 'l2_leaf_reg': 0.22566590221478305, 'bagging_temperature': 0.25700187034409044, 'random_strength': 0.5815409284760693, 'min_data_in_leaf': 4, 'subsample': 0.9476489724650997, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:15:55,251] Trial 6 finished with value: 0.8314015384165424 and parameters: {'iterations': 1641, 'learning_rate': 0.04844654203969178, 'depth': 8, 'l2_leaf_reg': 0.827432198024078, 'bagging_temperature': 0.05546677914127109, 'random_strength': 0.34893379596630536, 'min_data_in_leaf': 3, 'subsample': 0.9175387987058109, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:16:01,852] Trial 9 finished with value: 0.8214588634435962 and parameters: {'iterations': 1071, 'learning_rate': 0.049926858746636965, 'depth': 4, 'l2_leaf_reg': 0.8167125471451635, 'bagging_temperature': 0.10145240680295838, 'random_strength': 0.49053451653394203, 'min_data_in_leaf': 3, 'subsample': 0.9337508213053208, 'max_ctr_complexity': 1}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:16:17,954] Trial 10 finished with value: 0.8268082243865346 and parameters: {'iterations': 1773, 'learning_rate': 0.020546214318084427, 'depth': 5, 'l2_leaf_reg': 0.8693805428330096, 'bagging_temperature': 0.023360428123574115, 'random_strength': 0.3847454360994726, 'min_data_in_leaf': 3, 'subsample': 0.9400109897578482, 'max_ctr_complexity': 0}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:16:27,198] Trial 12 finished with value: 0.8172516159223188 and parameters: {'iterations': 1831, 'learning_rate': 0.014562453892599879, 'depth': 4, 'l2_leaf_reg': 0.39014464758755396, 'bagging_temperature': 0.09701416906672584, 'random_strength': 0.9589586801805956, 'min_data_in_leaf': 3, 'subsample': 0.8777510081476338, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:16:40,907] Trial 13 finished with value: 0.8218332309672137 and parameters: {'iterations': 1210, 'learning_rate': 0.013691075512788201, 'depth': 5, 'l2_leaf_reg': 0.9340268964870878, 'bagging_temperature': 0.09965328160162072, 'random_strength': 0.27980475449210696, 'min_data_in_leaf': 2, 'subsample': 0.8991104685573462, 'max_ctr_complexity': 0}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:17:07,689] Trial 14 finished with value: 0.8333113977362464 and parameters: {'iterations': 1114, 'learning_rate': 0.03616028757316939, 'depth': 8, 'l2_leaf_reg': 0.689172675918279, 'bagging_temperature': 0.06242658560644586, 'random_strength': 0.5766217149162125, 'min_data_in_leaf': 4, 'subsample': 0.7002017674250338, 'max_ctr_complexity': 0}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:17:26,235] Trial 15 finished with value: 0.830250650756047 and parameters: {'iterations': 1259, 'learning_rate': 0.018176932926618178, 'depth': 7, 'l2_leaf_reg': 0.31552069082573586, 'bagging_temperature': 0.19732834512605182, 'random_strength': 0.3654877769181842, 'min_data_in_leaf': 3, 'subsample': 0.9307470524934153, 'max_ctr_complexity': 1}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:17:32,339] Trial 16 finished with value: 0.8195504664970314 and parameters: {'iterations': 1687, 'learning_rate': 0.028337997527045126, 'depth': 4, 'l2_leaf_reg': 0.1474280096676391, 'bagging_temperature': 0.17100097858924337, 'random_strength': 0.20102331516349406, 'min_data_in_leaf': 4, 'subsample': 0.7838753538433507, 'max_ctr_complexity': 1}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:17:49,327] Trial 17 finished with value: 0.8271767424175952 and parameters: {'iterations': 1944, 'learning_rate': 0.028297917357884714, 'depth': 5, 'l2_leaf_reg': 0.14425705632083055, 'bagging_temperature': 0.09276914308826824, 'random_strength': 0.4825042534946795, 'min_data_in_leaf': 3, 'subsample': 0.7264899982247071, 'max_ctr_complexity': 1}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:17:57,566] Trial 18 finished with value: 0.8168670117867276 and parameters: {'iterations': 1452, 'learning_rate': 0.0425881217435535, 'depth': 4, 'l2_leaf_reg': 0.7534440270114422, 'bagging_temperature': 0.06035919320910915, 'random_strength': 0.22350061042378302, 'min_data_in_leaf': 3, 'subsample': 0.7662809862431035, 'max_ctr_complexity': 3}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:18:23,843] Trial 19 finished with value: 0.8283378666900646 and parameters: {'iterations': 1051, 'learning_rate': 0.048346251101258834, 'depth': 8, 'l2_leaf_reg': 1.14579945416072, 'bagging_temperature': 0.23225662799797075, 'random_strength': 0.5071922446595754, 'min_data_in_leaf': 4, 'subsample': 0.9980885545482119, 'max_ctr_complexity': 3}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:18:46,038] Trial 20 finished with value: 0.8302608873680208 and parameters: {'iterations': 1101, 'learning_rate': 0.014715352150870928, 'depth': 8, 'l2_leaf_reg': 0.7039685887521576, 'bagging_temperature': 0.23350355670228765, 'random_strength': 0.558197667628288, 'min_data_in_leaf': 3, 'subsample': 0.7980801830794213, 'max_ctr_complexity': 1}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:18:47,684] Trial 21 finished with value: 0.8011859846158345 and parameters: {'iterations': 1087, 'learning_rate': 0.010156306673336106, 'depth': 3, 'l2_leaf_reg': 1.0257040386967144, 'bagging_temperature': 0.2917165627922253, 'random_strength': 0.22419959924297267, 'min_data_in_leaf': 2, 'subsample': 0.9862372432673087, 'max_ctr_complexity': 0}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:19:16,080] Trial 22 finished with value: 0.8306323301453599 and parameters: {'iterations': 1706, 'learning_rate': 0.02512972435786421, 'depth': 7, 'l2_leaf_reg': 1.0501021934859496, 'bagging_temperature': 0.20558642839807928, 'random_strength': 0.20887269775805214, 'min_data_in_leaf': 2, 'subsample': 0.9949829791400215, 'max_ctr_complexity': 1}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:19:36,772] Trial 23 finished with value: 0.8294946038431167 and parameters: {'iterations': 1232, 'learning_rate': 0.01100561103507224, 'depth': 7, 'l2_leaf_reg': 1.086628254709832, 'bagging_temperature': 0.21000977757171754, 'random_strength': 0.22148829443359638, 'min_data_in_leaf': 2, 'subsample': 0.9965526534818316, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:19:56,738] Trial 24 finished with value: 0.8275788950308561 and parameters: {'iterations': 1244, 'learning_rate': 0.027545143957026338, 'depth': 7, 'l2_leaf_reg': 1.0683330827791262, 'bagging_temperature': 0.23023089416724696, 'random_strength': 0.2142279576938334, 'min_data_in_leaf': 2, 'subsample': 0.718182163053585, 'max_ctr_complexity': 1}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:20:26,301] Trial 25 finished with value: 0.827960574420169 and parameters: {'iterations': 1692, 'learning_rate': 0.02713330733355601, 'depth': 7, 'l2_leaf_reg': 1.1033895674382839, 'bagging_temperature': 0.20720595522278265, 'random_strength': 0.2137210778174713, 'min_data_in_leaf': 4, 'subsample': 0.9802554437274009, 'max_ctr_complexity': 1}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:20:37,792] Trial 26 finished with value: 0.8306396420110556 and parameters: {'iterations': 1183, 'learning_rate': 0.027819646897068555, 'depth': 7, 'l2_leaf_reg': 1.0733067698081245, 'bagging_temperature': 0.2050256753020582, 'random_strength': 0.4520784433902746, 'min_data_in_leaf': 4, 'subsample': 0.7001786886239065, 'max_ctr_complexity': 1}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:20:45,863] Trial 27 finished with value: 0.830250650756047 and parameters: {'iterations': 1009, 'learning_rate': 0.028161582118442944, 'depth': 7, 'l2_leaf_reg': 1.0607827028681174, 'bagging_temperature': 0.1743983669732716, 'random_strength': 0.2062245678718501, 'min_data_in_leaf': 4, 'subsample': 0.731736952289256, 'max_ctr_complexity': 1}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:21:03,010] Trial 28 finished with value: 0.8294902167236993 and parameters: {'iterations': 1011, 'learning_rate': 0.03663312500324094, 'depth': 7, 'l2_leaf_reg': 1.1490118920842685, 'bagging_temperature': 0.296111487380144, 'random_strength': 0.47141772485581107, 'min_data_in_leaf': 4, 'subsample': 0.7379589690658279, 'max_ctr_complexity': 0}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:21:22,189] Trial 29 finished with value: 0.8306352548916381 and parameters: {'iterations': 1156, 'learning_rate': 0.03478468326070377, 'depth': 7, 'l2_leaf_reg': 1.0878962053883163, 'bagging_temperature': 0.27595118830252374, 'random_strength': 0.6844993075396211, 'min_data_in_leaf': 4, 'subsample': 0.9918104711185937, 'max_ctr_complexity': 0}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:21:40,923] Trial 30 finished with value: 0.828722470825656 and parameters: {'iterations': 1155, 'learning_rate': 0.03526438763516085, 'depth': 7, 'l2_leaf_reg': 1.0635334304411679, 'bagging_temperature': 0.2951380571232696, 'random_strength': 0.6952002870919812, 'min_data_in_leaf': 4, 'subsample': 0.9860143281635361, 'max_ctr_complexity': 0}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:21:55,575] Trial 31 finished with value: 0.8306352548916381 and parameters: {'iterations': 1150, 'learning_rate': 0.010499682789791114, 'depth': 7, 'l2_leaf_reg': 0.5840016408596255, 'bagging_temperature': 0.2965040652598203, 'random_strength': 0.6964674504074359, 'min_data_in_leaf': 2, 'subsample': 0.7043369909219593, 'max_ctr_complexity': 0}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:22:15,507] Trial 32 finished with value: 0.8306337925184991 and parameters: {'iterations': 1162, 'learning_rate': 0.034740415482766095, 'depth': 7, 'l2_leaf_reg': 0.5567504927291587, 'bagging_temperature': 0.13785478171933546, 'random_strength': 0.3975831382535837, 'min_data_in_leaf': 4, 'subsample': 0.9976534879435548, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:22:27,786] Trial 33 finished with value: 0.826432394489778 and parameters: {'iterations': 1347, 'learning_rate': 0.03493721696270019, 'depth': 7, 'l2_leaf_reg': 0.5563409869251933, 'bagging_temperature': 0.13714072967574537, 'random_strength': 0.41845077821185955, 'min_data_in_leaf': 4, 'subsample': 0.701186429058964, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:22:44,687] Trial 34 finished with value: 0.8283466409288994 and parameters: {'iterations': 1183, 'learning_rate': 0.0353331993292862, 'depth': 7, 'l2_leaf_reg': 0.5420023667683809, 'bagging_temperature': 0.13036949637224, 'random_strength': 0.42846440396158214, 'min_data_in_leaf': 4, 'subsample': 0.8365765708969999, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:22:59,402] Trial 35 finished with value: 0.821850779444883 and parameters: {'iterations': 1333, 'learning_rate': 0.03514846026902246, 'depth': 6, 'l2_leaf_reg': 0.5646850809042454, 'bagging_temperature': 0.14239681538682455, 'random_strength': 0.31362853718473893, 'min_data_in_leaf': 4, 'subsample': 0.8468370500751706, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:23:14,850] Trial 36 finished with value: 0.827197215641543 and parameters: {'iterations': 1349, 'learning_rate': 0.033036081193736896, 'depth': 6, 'l2_leaf_reg': 0.5811641925137612, 'bagging_temperature': 0.00028012166288750306, 'random_strength': 0.4376472064276573, 'min_data_in_leaf': 4, 'subsample': 0.8537787572017872, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:23:26,539] Trial 37 finished with value: 0.8252800444561433 and parameters: {'iterations': 1346, 'learning_rate': 0.03348739407602015, 'depth': 6, 'l2_leaf_reg': 0.5827903559787773, 'bagging_temperature': 0.14179403532125814, 'random_strength': 0.4252122498016553, 'min_data_in_leaf': 4, 'subsample': 0.8427977349269938, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:23:41,284] Trial 38 finished with value: 0.8260463279810477 and parameters: {'iterations': 1426, 'learning_rate': 0.03279183774769606, 'depth': 6, 'l2_leaf_reg': 0.5546761253451509, 'bagging_temperature': 0.13822857065601038, 'random_strength': 0.30529039673638225, 'min_data_in_leaf': 4, 'subsample': 0.844510705803576, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:23:49,652] Trial 39 finished with value: 0.8294916790968383 and parameters: {'iterations': 1359, 'learning_rate': 0.037078062893576964, 'depth': 6, 'l2_leaf_reg': 0.6161355362157552, 'bagging_temperature': 0.0015533002958226724, 'random_strength': 0.6462619832544664, 'min_data_in_leaf': 4, 'subsample': 0.8455794828805325, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:24:05,105] Trial 40 finished with value: 0.8298733584861513 and parameters: {'iterations': 1356, 'learning_rate': 0.03318422124694255, 'depth': 6, 'l2_leaf_reg': 0.5945575095338342, 'bagging_temperature': 0.1356597802962621, 'random_strength': 0.6702906117536697, 'min_data_in_leaf': 3, 'subsample': 0.8337589891474085, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:24:25,581] Trial 41 finished with value: 0.8256617238454564 and parameters: {'iterations': 1388, 'learning_rate': 0.0417203115256617, 'depth': 6, 'l2_leaf_reg': 0.5990608363677842, 'bagging_temperature': 0.1420186911776778, 'random_strength': 0.32069217510380216, 'min_data_in_leaf': 3, 'subsample': 0.8331502205032351, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:25:00,573] Trial 42 finished with value: 0.8302565002486034 and parameters: {'iterations': 1339, 'learning_rate': 0.02192966456112849, 'depth': 8, 'l2_leaf_reg': 0.5897037297742775, 'bagging_temperature': 0.1324903742363852, 'random_strength': 0.8614191989122094, 'min_data_in_leaf': 3, 'subsample': 0.762824328944916, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:25:30,283] Trial 43 finished with value: 0.8329282559737944 and parameters: {'iterations': 1356, 'learning_rate': 0.021757413905917997, 'depth': 8, 'l2_leaf_reg': 0.6098126228463017, 'bagging_temperature': 0.00391336234149578, 'random_strength': 0.8082067554707659, 'min_data_in_leaf': 3, 'subsample': 0.8372364157205747, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:26:13,254] Trial 44 finished with value: 0.8317846801789944 and parameters: {'iterations': 1577, 'learning_rate': 0.022192196078145328, 'depth': 8, 'l2_leaf_reg': 0.6500169208909268, 'bagging_temperature': 0.12345418959894502, 'random_strength': 0.8258379587806433, 'min_data_in_leaf': 3, 'subsample': 0.8351603375632393, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:26:44,272] Trial 45 finished with value: 0.8306323301453599 and parameters: {'iterations': 1568, 'learning_rate': 0.02219987851655425, 'depth': 8, 'l2_leaf_reg': 1.249506727223189, 'bagging_temperature': 0.00031140921077898315, 'random_strength': 0.8272212702651572, 'min_data_in_leaf': 3, 'subsample': 0.8390246338139715, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:27:26,383] Trial 46 finished with value: 0.8291129244538038 and parameters: {'iterations': 1586, 'learning_rate': 0.022068117525218, 'depth': 8, 'l2_leaf_reg': 1.2700248593107908, 'bagging_temperature': 0.07000097001296117, 'random_strength': 0.8045854572315447, 'min_data_in_leaf': 3, 'subsample': 0.8442204006753787, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:27:55,796] Trial 47 finished with value: 0.8317861425521336 and parameters: {'iterations': 1570, 'learning_rate': 0.04023394340119283, 'depth': 8, 'l2_leaf_reg': 1.2882082340561802, 'bagging_temperature': 0.007923945098716273, 'random_strength': 0.8035666752084681, 'min_data_in_leaf': 3, 'subsample': 0.8273881198122262, 'max_ctr_complexity': 2}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:28:36,526] Trial 48 finished with value: 0.8325465765844813 and parameters: {'iterations': 1559, 'learning_rate': 0.04084555589805497, 'depth': 8, 'l2_leaf_reg': 1.4948770430116682, 'bagging_temperature': 0.07299719762520404, 'random_strength': 0.8293411128555773, 'min_data_in_leaf': 3, 'subsample': 0.7547057095696981, 'max_ctr_complexity': 3}. Best is trial 7 with value: 0.8344622853967417.\n",
      "[I 2025-12-25 16:28:49,911] Trial 49 finished with value: 0.8329297183469334 and parameters: {'iterations': 1557, 'learning_rate': 0.04172000395271415, 'depth': 8, 'l2_leaf_reg': 1.2636158943938887, 'bagging_temperature': 0.06946278304633821, 'random_strength': 0.8283983253340335, 'min_data_in_leaf': 3, 'subsample': 0.7530085922511652, 'max_ctr_complexity': 3}. Best is trial 7 with value: 0.8344622853967417.\n"
     ]
    }
   ],
   "source": [
    "cb_obj: func = objective(enum_model(\"CB\"))\n",
    "storage_path_cb: str = \"sqlite:///cb_study.db\"\n",
    "study_cb = optuna.create_study(\n",
    "    study_name = \"cb_study\",\n",
    "    storage  = storage_path_cb,\n",
    "    direction= 'maximize',\n",
    "    load_if_exists = True\n",
    ")\n",
    "study_cb.optimize(\n",
    "    func = cb_obj,\n",
    "    n_trials = 50,\n",
    "    n_jobs = -1,\n",
    "    show_progress_bar = False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "634c0d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.67670\n",
      "[1]\tvalidation_0-logloss:0.66337\n",
      "[2]\tvalidation_0-logloss:0.64832\n",
      "[3]\tvalidation_0-logloss:0.63644\n",
      "[4]\tvalidation_0-logloss:0.62499\n",
      "[5]\tvalidation_0-logloss:0.61247\n",
      "[6]\tvalidation_0-logloss:0.60318\n",
      "[7]\tvalidation_0-logloss:0.59493\n",
      "[8]\tvalidation_0-logloss:0.58570\n",
      "[9]\tvalidation_0-logloss:0.57534\n",
      "[10]\tvalidation_0-logloss:0.56652\n",
      "[11]\tvalidation_0-logloss:0.55957\n",
      "[12]\tvalidation_0-logloss:0.55284\n",
      "[13]\tvalidation_0-logloss:0.54472\n",
      "[14]\tvalidation_0-logloss:0.53711\n",
      "[15]\tvalidation_0-logloss:0.53105\n",
      "[16]\tvalidation_0-logloss:0.52523\n",
      "[17]\tvalidation_0-logloss:0.52067\n",
      "[18]\tvalidation_0-logloss:0.51475\n",
      "[19]\tvalidation_0-logloss:0.50971\n",
      "[20]\tvalidation_0-logloss:0.50519\n",
      "[21]\tvalidation_0-logloss:0.50114\n",
      "[22]\tvalidation_0-logloss:0.49633\n",
      "[23]\tvalidation_0-logloss:0.49123\n",
      "[24]\tvalidation_0-logloss:0.48692\n",
      "[25]\tvalidation_0-logloss:0.48341\n",
      "[26]\tvalidation_0-logloss:0.47986\n",
      "[27]\tvalidation_0-logloss:0.47670\n",
      "[28]\tvalidation_0-logloss:0.47302\n",
      "[29]\tvalidation_0-logloss:0.46918\n",
      "[30]\tvalidation_0-logloss:0.46610\n",
      "[31]\tvalidation_0-logloss:0.46304\n",
      "[32]\tvalidation_0-logloss:0.46067\n",
      "[33]\tvalidation_0-logloss:0.45764\n",
      "[34]\tvalidation_0-logloss:0.45610\n",
      "[35]\tvalidation_0-logloss:0.45326\n",
      "[36]\tvalidation_0-logloss:0.45178\n",
      "[37]\tvalidation_0-logloss:0.44941\n",
      "[38]\tvalidation_0-logloss:0.44711\n",
      "[39]\tvalidation_0-logloss:0.44525\n",
      "[40]\tvalidation_0-logloss:0.44321\n",
      "[41]\tvalidation_0-logloss:0.44269\n",
      "[42]\tvalidation_0-logloss:0.44038\n",
      "[43]\tvalidation_0-logloss:0.43934\n",
      "[44]\tvalidation_0-logloss:0.43792\n",
      "[45]\tvalidation_0-logloss:0.43660\n",
      "[46]\tvalidation_0-logloss:0.43502\n",
      "[47]\tvalidation_0-logloss:0.43356\n",
      "[48]\tvalidation_0-logloss:0.43216\n",
      "[49]\tvalidation_0-logloss:0.43000\n",
      "[50]\tvalidation_0-logloss:0.42835\n",
      "[51]\tvalidation_0-logloss:0.42736\n",
      "[52]\tvalidation_0-logloss:0.42603\n",
      "[53]\tvalidation_0-logloss:0.42628\n",
      "[54]\tvalidation_0-logloss:0.42501\n",
      "[55]\tvalidation_0-logloss:0.42444\n",
      "[56]\tvalidation_0-logloss:0.42353\n",
      "[57]\tvalidation_0-logloss:0.42236\n",
      "[58]\tvalidation_0-logloss:0.42096\n",
      "[59]\tvalidation_0-logloss:0.41987\n",
      "[60]\tvalidation_0-logloss:0.41844\n",
      "[61]\tvalidation_0-logloss:0.41846\n",
      "[62]\tvalidation_0-logloss:0.41794\n",
      "[63]\tvalidation_0-logloss:0.41750\n",
      "[64]\tvalidation_0-logloss:0.41649\n",
      "[65]\tvalidation_0-logloss:0.41574\n",
      "[66]\tvalidation_0-logloss:0.41520\n",
      "[67]\tvalidation_0-logloss:0.41490\n",
      "[68]\tvalidation_0-logloss:0.41463\n",
      "[69]\tvalidation_0-logloss:0.41480\n",
      "[70]\tvalidation_0-logloss:0.41481\n",
      "[71]\tvalidation_0-logloss:0.41401\n",
      "[72]\tvalidation_0-logloss:0.41350\n",
      "[73]\tvalidation_0-logloss:0.41383\n",
      "[74]\tvalidation_0-logloss:0.41342\n",
      "[75]\tvalidation_0-logloss:0.41251\n",
      "[76]\tvalidation_0-logloss:0.41223\n",
      "[77]\tvalidation_0-logloss:0.41174\n",
      "[78]\tvalidation_0-logloss:0.41160\n",
      "[79]\tvalidation_0-logloss:0.41204\n",
      "[80]\tvalidation_0-logloss:0.41213\n",
      "[81]\tvalidation_0-logloss:0.41194\n",
      "[82]\tvalidation_0-logloss:0.41210\n",
      "[83]\tvalidation_0-logloss:0.41215\n",
      "[84]\tvalidation_0-logloss:0.41175\n",
      "[85]\tvalidation_0-logloss:0.41153\n",
      "[86]\tvalidation_0-logloss:0.41132\n",
      "[87]\tvalidation_0-logloss:0.41089\n",
      "[88]\tvalidation_0-logloss:0.41012\n",
      "[89]\tvalidation_0-logloss:0.41042\n",
      "[90]\tvalidation_0-logloss:0.41012\n",
      "[91]\tvalidation_0-logloss:0.40973\n",
      "[92]\tvalidation_0-logloss:0.40933\n",
      "[93]\tvalidation_0-logloss:0.40964\n",
      "[94]\tvalidation_0-logloss:0.40921\n",
      "[95]\tvalidation_0-logloss:0.41000\n",
      "[96]\tvalidation_0-logloss:0.40983\n",
      "[97]\tvalidation_0-logloss:0.40993\n",
      "[98]\tvalidation_0-logloss:0.40955\n",
      "[99]\tvalidation_0-logloss:0.40942\n",
      "[100]\tvalidation_0-logloss:0.40930\n",
      "[101]\tvalidation_0-logloss:0.40967\n",
      "[102]\tvalidation_0-logloss:0.40908\n",
      "[103]\tvalidation_0-logloss:0.40909\n",
      "[104]\tvalidation_0-logloss:0.40860\n",
      "[105]\tvalidation_0-logloss:0.40821\n",
      "[106]\tvalidation_0-logloss:0.40807\n",
      "[107]\tvalidation_0-logloss:0.40776\n",
      "[108]\tvalidation_0-logloss:0.40781\n",
      "[109]\tvalidation_0-logloss:0.40827\n",
      "[110]\tvalidation_0-logloss:0.40835\n",
      "[111]\tvalidation_0-logloss:0.40849\n",
      "[112]\tvalidation_0-logloss:0.40860\n",
      "[113]\tvalidation_0-logloss:0.40869\n",
      "[114]\tvalidation_0-logloss:0.40831\n",
      "[115]\tvalidation_0-logloss:0.40863\n",
      "[116]\tvalidation_0-logloss:0.40864\n",
      "[117]\tvalidation_0-logloss:0.40864\n",
      "[118]\tvalidation_0-logloss:0.40807\n",
      "[119]\tvalidation_0-logloss:0.40843\n",
      "[120]\tvalidation_0-logloss:0.40879\n",
      "[121]\tvalidation_0-logloss:0.40852\n",
      "[122]\tvalidation_0-logloss:0.40865\n",
      "[123]\tvalidation_0-logloss:0.40848\n",
      "[124]\tvalidation_0-logloss:0.40817\n",
      "[125]\tvalidation_0-logloss:0.40807\n",
      "[126]\tvalidation_0-logloss:0.40823\n",
      "[127]\tvalidation_0-logloss:0.40790\n",
      "[128]\tvalidation_0-logloss:0.40752\n",
      "[129]\tvalidation_0-logloss:0.40791\n",
      "[130]\tvalidation_0-logloss:0.40838\n",
      "[131]\tvalidation_0-logloss:0.40837\n",
      "[132]\tvalidation_0-logloss:0.40849\n",
      "[133]\tvalidation_0-logloss:0.40844\n",
      "[134]\tvalidation_0-logloss:0.40872\n",
      "[135]\tvalidation_0-logloss:0.40793\n",
      "[136]\tvalidation_0-logloss:0.40773\n",
      "[137]\tvalidation_0-logloss:0.40788\n",
      "[138]\tvalidation_0-logloss:0.40767\n",
      "[139]\tvalidation_0-logloss:0.40761\n",
      "[140]\tvalidation_0-logloss:0.40753\n",
      "[141]\tvalidation_0-logloss:0.40739\n",
      "[142]\tvalidation_0-logloss:0.40743\n",
      "[143]\tvalidation_0-logloss:0.40776\n",
      "[144]\tvalidation_0-logloss:0.40770\n",
      "[145]\tvalidation_0-logloss:0.40806\n",
      "[146]\tvalidation_0-logloss:0.40823\n",
      "[147]\tvalidation_0-logloss:0.40822\n",
      "[148]\tvalidation_0-logloss:0.40723\n",
      "[149]\tvalidation_0-logloss:0.40706\n",
      "[150]\tvalidation_0-logloss:0.40708\n",
      "[151]\tvalidation_0-logloss:0.40747\n",
      "[152]\tvalidation_0-logloss:0.40757\n",
      "[153]\tvalidation_0-logloss:0.40769\n",
      "[154]\tvalidation_0-logloss:0.40747\n",
      "[155]\tvalidation_0-logloss:0.40663\n",
      "[156]\tvalidation_0-logloss:0.40683\n",
      "[157]\tvalidation_0-logloss:0.40644\n",
      "[158]\tvalidation_0-logloss:0.40676\n",
      "[159]\tvalidation_0-logloss:0.40653\n",
      "[160]\tvalidation_0-logloss:0.40655\n",
      "[161]\tvalidation_0-logloss:0.40666\n",
      "[162]\tvalidation_0-logloss:0.40680\n",
      "[163]\tvalidation_0-logloss:0.40725\n",
      "[164]\tvalidation_0-logloss:0.40730\n",
      "[165]\tvalidation_0-logloss:0.40732\n",
      "[166]\tvalidation_0-logloss:0.40732\n",
      "[167]\tvalidation_0-logloss:0.40729\n",
      "[168]\tvalidation_0-logloss:0.40704\n",
      "[169]\tvalidation_0-logloss:0.40689\n",
      "[170]\tvalidation_0-logloss:0.40713\n",
      "[171]\tvalidation_0-logloss:0.40752\n",
      "[172]\tvalidation_0-logloss:0.40775\n",
      "[173]\tvalidation_0-logloss:0.40788\n",
      "[174]\tvalidation_0-logloss:0.40823\n",
      "[175]\tvalidation_0-logloss:0.40847\n",
      "[176]\tvalidation_0-logloss:0.40850\n",
      "[177]\tvalidation_0-logloss:0.40850\n",
      "[178]\tvalidation_0-logloss:0.40821\n",
      "[179]\tvalidation_0-logloss:0.40769\n",
      "[180]\tvalidation_0-logloss:0.40767\n",
      "[181]\tvalidation_0-logloss:0.40799\n",
      "[182]\tvalidation_0-logloss:0.40802\n",
      "[183]\tvalidation_0-logloss:0.40783\n",
      "[184]\tvalidation_0-logloss:0.40800\n",
      "[185]\tvalidation_0-logloss:0.40795\n",
      "[186]\tvalidation_0-logloss:0.40781\n",
      "[187]\tvalidation_0-logloss:0.40776\n",
      "[188]\tvalidation_0-logloss:0.40787\n",
      "[189]\tvalidation_0-logloss:0.40796\n",
      "[190]\tvalidation_0-logloss:0.40802\n",
      "[191]\tvalidation_0-logloss:0.40824\n",
      "[192]\tvalidation_0-logloss:0.40755\n",
      "[193]\tvalidation_0-logloss:0.40769\n",
      "[194]\tvalidation_0-logloss:0.40766\n",
      "[195]\tvalidation_0-logloss:0.40767\n",
      "[196]\tvalidation_0-logloss:0.40770\n",
      "[197]\tvalidation_0-logloss:0.40789\n",
      "[198]\tvalidation_0-logloss:0.40781\n",
      "[199]\tvalidation_0-logloss:0.40822\n",
      "[200]\tvalidation_0-logloss:0.40793\n",
      "[201]\tvalidation_0-logloss:0.40800\n",
      "[202]\tvalidation_0-logloss:0.40819\n",
      "[203]\tvalidation_0-logloss:0.40834\n",
      "[204]\tvalidation_0-logloss:0.40833\n",
      "[205]\tvalidation_0-logloss:0.40838\n",
      "[206]\tvalidation_0-logloss:0.40847\n",
      "[207]\tvalidation_0-logloss:0.40888\n",
      "[208]\tvalidation_0-logloss:0.40888\n",
      "[209]\tvalidation_0-logloss:0.40912\n",
      "[210]\tvalidation_0-logloss:0.40919\n",
      "[211]\tvalidation_0-logloss:0.40915\n",
      "[212]\tvalidation_0-logloss:0.40922\n",
      "[213]\tvalidation_0-logloss:0.40921\n",
      "[214]\tvalidation_0-logloss:0.40926\n",
      "[215]\tvalidation_0-logloss:0.40929\n",
      "[216]\tvalidation_0-logloss:0.40942\n",
      "[217]\tvalidation_0-logloss:0.40952\n",
      "[218]\tvalidation_0-logloss:0.40950\n",
      "[219]\tvalidation_0-logloss:0.40973\n",
      "[220]\tvalidation_0-logloss:0.40973\n",
      "[221]\tvalidation_0-logloss:0.40975\n",
      "[222]\tvalidation_0-logloss:0.40979\n",
      "[223]\tvalidation_0-logloss:0.40980\n",
      "[224]\tvalidation_0-logloss:0.40964\n",
      "[225]\tvalidation_0-logloss:0.40974\n",
      "[226]\tvalidation_0-logloss:0.40976\n",
      "[227]\tvalidation_0-logloss:0.40976\n",
      "[228]\tvalidation_0-logloss:0.40983\n",
      "[229]\tvalidation_0-logloss:0.40980\n",
      "[230]\tvalidation_0-logloss:0.41052\n",
      "[231]\tvalidation_0-logloss:0.41017\n",
      "[232]\tvalidation_0-logloss:0.41019\n",
      "[233]\tvalidation_0-logloss:0.41034\n",
      "[234]\tvalidation_0-logloss:0.41036\n",
      "[235]\tvalidation_0-logloss:0.41038\n",
      "[236]\tvalidation_0-logloss:0.41036\n",
      "[237]\tvalidation_0-logloss:0.41035\n",
      "[238]\tvalidation_0-logloss:0.41040\n",
      "[239]\tvalidation_0-logloss:0.41040\n",
      "[240]\tvalidation_0-logloss:0.41019\n",
      "[241]\tvalidation_0-logloss:0.41021\n",
      "[242]\tvalidation_0-logloss:0.41034\n",
      "[243]\tvalidation_0-logloss:0.41008\n",
      "[244]\tvalidation_0-logloss:0.41015\n",
      "[245]\tvalidation_0-logloss:0.41020\n",
      "[246]\tvalidation_0-logloss:0.41024\n",
      "[247]\tvalidation_0-logloss:0.41010\n",
      "[248]\tvalidation_0-logloss:0.41010\n",
      "[249]\tvalidation_0-logloss:0.41010\n",
      "[250]\tvalidation_0-logloss:0.41008\n",
      "[251]\tvalidation_0-logloss:0.41005\n",
      "[252]\tvalidation_0-logloss:0.41038\n",
      "[253]\tvalidation_0-logloss:0.41036\n",
      "[254]\tvalidation_0-logloss:0.41033\n",
      "[255]\tvalidation_0-logloss:0.41036\n",
      "[256]\tvalidation_0-logloss:0.41036\n",
      "[257]\tvalidation_0-logloss:0.41032\n",
      "[258]\tvalidation_0-logloss:0.41036\n",
      "[259]\tvalidation_0-logloss:0.41049\n",
      "[260]\tvalidation_0-logloss:0.41052\n",
      "[261]\tvalidation_0-logloss:0.41053\n",
      "[262]\tvalidation_0-logloss:0.41062\n",
      "[263]\tvalidation_0-logloss:0.41059\n",
      "[264]\tvalidation_0-logloss:0.41064\n",
      "[265]\tvalidation_0-logloss:0.41064\n",
      "[266]\tvalidation_0-logloss:0.41062\n",
      "[267]\tvalidation_0-logloss:0.41078\n",
      "[268]\tvalidation_0-logloss:0.41097\n",
      "[269]\tvalidation_0-logloss:0.41103\n",
      "[270]\tvalidation_0-logloss:0.41097\n",
      "[271]\tvalidation_0-logloss:0.41094\n",
      "[272]\tvalidation_0-logloss:0.41102\n",
      "[273]\tvalidation_0-logloss:0.41107\n",
      "[274]\tvalidation_0-logloss:0.41106\n",
      "[275]\tvalidation_0-logloss:0.41109\n",
      "[276]\tvalidation_0-logloss:0.41109\n",
      "[277]\tvalidation_0-logloss:0.41111\n",
      "[278]\tvalidation_0-logloss:0.41107\n",
      "[279]\tvalidation_0-logloss:0.41106\n",
      "[280]\tvalidation_0-logloss:0.41096\n",
      "[281]\tvalidation_0-logloss:0.41094\n",
      "[282]\tvalidation_0-logloss:0.41092\n",
      "[283]\tvalidation_0-logloss:0.41092\n",
      "[284]\tvalidation_0-logloss:0.41099\n",
      "[285]\tvalidation_0-logloss:0.41099\n",
      "[286]\tvalidation_0-logloss:0.41101\n",
      "[287]\tvalidation_0-logloss:0.41121\n",
      "[288]\tvalidation_0-logloss:0.41115\n",
      "[289]\tvalidation_0-logloss:0.41117\n",
      "[290]\tvalidation_0-logloss:0.41116\n",
      "[291]\tvalidation_0-logloss:0.41118\n",
      "[292]\tvalidation_0-logloss:0.41132\n",
      "[293]\tvalidation_0-logloss:0.41057\n",
      "[294]\tvalidation_0-logloss:0.41066\n",
      "[295]\tvalidation_0-logloss:0.41066\n",
      "[296]\tvalidation_0-logloss:0.41061\n",
      "[297]\tvalidation_0-logloss:0.41059\n",
      "[298]\tvalidation_0-logloss:0.41058\n",
      "[299]\tvalidation_0-logloss:0.41062\n",
      "[300]\tvalidation_0-logloss:0.41056\n",
      "[301]\tvalidation_0-logloss:0.41082\n",
      "[302]\tvalidation_0-logloss:0.41083\n",
      "[303]\tvalidation_0-logloss:0.41087\n",
      "[304]\tvalidation_0-logloss:0.41089\n",
      "[305]\tvalidation_0-logloss:0.41089\n",
      "[306]\tvalidation_0-logloss:0.41090\n",
      "[307]\tvalidation_0-logloss:0.41093\n",
      "[308]\tvalidation_0-logloss:0.41095\n",
      "[309]\tvalidation_0-logloss:0.41099\n",
      "[310]\tvalidation_0-logloss:0.41099\n",
      "[311]\tvalidation_0-logloss:0.41052\n",
      "[312]\tvalidation_0-logloss:0.41055\n",
      "[313]\tvalidation_0-logloss:0.41057\n",
      "[314]\tvalidation_0-logloss:0.41057\n",
      "[315]\tvalidation_0-logloss:0.41059\n",
      "[316]\tvalidation_0-logloss:0.41065\n",
      "[317]\tvalidation_0-logloss:0.41062\n",
      "[318]\tvalidation_0-logloss:0.41065\n",
      "[319]\tvalidation_0-logloss:0.41063\n",
      "[320]\tvalidation_0-logloss:0.41056\n",
      "[321]\tvalidation_0-logloss:0.41066\n",
      "[322]\tvalidation_0-logloss:0.41066\n",
      "[323]\tvalidation_0-logloss:0.41078\n",
      "[324]\tvalidation_0-logloss:0.41079\n",
      "[325]\tvalidation_0-logloss:0.41076\n",
      "[326]\tvalidation_0-logloss:0.41076\n",
      "[327]\tvalidation_0-logloss:0.41073\n",
      "[328]\tvalidation_0-logloss:0.41073\n",
      "[329]\tvalidation_0-logloss:0.41081\n",
      "[330]\tvalidation_0-logloss:0.41087\n",
      "[331]\tvalidation_0-logloss:0.41152\n",
      "[332]\tvalidation_0-logloss:0.41146\n",
      "[333]\tvalidation_0-logloss:0.41146\n",
      "[334]\tvalidation_0-logloss:0.41143\n",
      "[335]\tvalidation_0-logloss:0.41144\n",
      "[336]\tvalidation_0-logloss:0.41146\n",
      "[337]\tvalidation_0-logloss:0.41145\n",
      "[338]\tvalidation_0-logloss:0.41147\n",
      "[339]\tvalidation_0-logloss:0.41160\n",
      "[340]\tvalidation_0-logloss:0.41160\n",
      "[341]\tvalidation_0-logloss:0.41163\n",
      "[342]\tvalidation_0-logloss:0.41172\n",
      "[343]\tvalidation_0-logloss:0.41162\n",
      "[344]\tvalidation_0-logloss:0.41166\n",
      "[345]\tvalidation_0-logloss:0.41165\n",
      "[346]\tvalidation_0-logloss:0.41171\n",
      "[347]\tvalidation_0-logloss:0.41173\n",
      "[348]\tvalidation_0-logloss:0.41167\n",
      "[349]\tvalidation_0-logloss:0.41169\n",
      "[350]\tvalidation_0-logloss:0.41170\n",
      "[351]\tvalidation_0-logloss:0.41192\n",
      "[352]\tvalidation_0-logloss:0.41199\n",
      "[353]\tvalidation_0-logloss:0.41199\n",
      "[354]\tvalidation_0-logloss:0.41196\n",
      "[355]\tvalidation_0-logloss:0.41196\n",
      "[356]\tvalidation_0-logloss:0.41205\n",
      "[357]\tvalidation_0-logloss:0.41205\n",
      "[358]\tvalidation_0-logloss:0.41206\n",
      "[359]\tvalidation_0-logloss:0.41207\n",
      "[360]\tvalidation_0-logloss:0.41208\n",
      "[361]\tvalidation_0-logloss:0.41210\n",
      "[362]\tvalidation_0-logloss:0.41212\n",
      "[363]\tvalidation_0-logloss:0.41214\n",
      "[364]\tvalidation_0-logloss:0.41213\n",
      "[365]\tvalidation_0-logloss:0.41212\n",
      "[366]\tvalidation_0-logloss:0.41215\n",
      "[367]\tvalidation_0-logloss:0.41225\n",
      "[368]\tvalidation_0-logloss:0.41224\n",
      "[369]\tvalidation_0-logloss:0.41224\n",
      "[370]\tvalidation_0-logloss:0.41217\n",
      "[371]\tvalidation_0-logloss:0.41218\n",
      "[372]\tvalidation_0-logloss:0.41223\n",
      "[373]\tvalidation_0-logloss:0.41229\n",
      "[374]\tvalidation_0-logloss:0.41220\n",
      "[375]\tvalidation_0-logloss:0.41228\n",
      "[376]\tvalidation_0-logloss:0.41214\n",
      "[377]\tvalidation_0-logloss:0.41212\n",
      "[378]\tvalidation_0-logloss:0.41214\n",
      "[379]\tvalidation_0-logloss:0.41214\n",
      "[380]\tvalidation_0-logloss:0.41201\n",
      "[381]\tvalidation_0-logloss:0.41202\n",
      "[382]\tvalidation_0-logloss:0.41202\n",
      "[383]\tvalidation_0-logloss:0.41204\n",
      "[384]\tvalidation_0-logloss:0.41202\n",
      "[385]\tvalidation_0-logloss:0.41201\n",
      "[386]\tvalidation_0-logloss:0.41205\n",
      "[387]\tvalidation_0-logloss:0.41204\n",
      "[388]\tvalidation_0-logloss:0.41207\n",
      "[389]\tvalidation_0-logloss:0.41211\n",
      "[390]\tvalidation_0-logloss:0.41212\n",
      "[391]\tvalidation_0-logloss:0.41213\n",
      "[392]\tvalidation_0-logloss:0.41193\n",
      "[393]\tvalidation_0-logloss:0.41192\n",
      "[394]\tvalidation_0-logloss:0.41187\n",
      "[395]\tvalidation_0-logloss:0.41187\n",
      "[396]\tvalidation_0-logloss:0.41188\n",
      "[397]\tvalidation_0-logloss:0.41186\n",
      "[398]\tvalidation_0-logloss:0.41185\n",
      "[399]\tvalidation_0-logloss:0.41181\n",
      "[400]\tvalidation_0-logloss:0.41184\n",
      "[401]\tvalidation_0-logloss:0.41184\n",
      "[402]\tvalidation_0-logloss:0.41178\n",
      "[403]\tvalidation_0-logloss:0.41181\n",
      "[404]\tvalidation_0-logloss:0.41180\n",
      "[405]\tvalidation_0-logloss:0.41180\n",
      "[406]\tvalidation_0-logloss:0.41183\n",
      "[407]\tvalidation_0-logloss:0.41175\n",
      "[408]\tvalidation_0-logloss:0.41172\n",
      "[409]\tvalidation_0-logloss:0.41175\n",
      "[410]\tvalidation_0-logloss:0.41150\n",
      "[411]\tvalidation_0-logloss:0.41149\n",
      "[412]\tvalidation_0-logloss:0.41154\n",
      "[413]\tvalidation_0-logloss:0.41153\n",
      "[414]\tvalidation_0-logloss:0.41151\n",
      "[415]\tvalidation_0-logloss:0.41152\n",
      "[416]\tvalidation_0-logloss:0.41151\n",
      "[417]\tvalidation_0-logloss:0.41151\n",
      "[418]\tvalidation_0-logloss:0.41154\n",
      "[419]\tvalidation_0-logloss:0.41155\n",
      "[420]\tvalidation_0-logloss:0.41154\n",
      "[421]\tvalidation_0-logloss:0.41149\n",
      "[422]\tvalidation_0-logloss:0.41150\n",
      "[423]\tvalidation_0-logloss:0.41141\n",
      "[424]\tvalidation_0-logloss:0.41141\n",
      "[425]\tvalidation_0-logloss:0.41146\n",
      "[426]\tvalidation_0-logloss:0.41149\n",
      "[427]\tvalidation_0-logloss:0.41149\n",
      "[428]\tvalidation_0-logloss:0.41153\n",
      "[429]\tvalidation_0-logloss:0.41150\n",
      "[430]\tvalidation_0-logloss:0.41177\n",
      "[431]\tvalidation_0-logloss:0.41179\n",
      "[432]\tvalidation_0-logloss:0.41179\n",
      "[433]\tvalidation_0-logloss:0.41165\n",
      "[434]\tvalidation_0-logloss:0.41164\n",
      "[435]\tvalidation_0-logloss:0.41164\n",
      "[436]\tvalidation_0-logloss:0.41163\n",
      "[437]\tvalidation_0-logloss:0.41161\n",
      "[438]\tvalidation_0-logloss:0.41167\n",
      "[439]\tvalidation_0-logloss:0.41160\n",
      "[440]\tvalidation_0-logloss:0.41158\n",
      "[441]\tvalidation_0-logloss:0.41157\n",
      "[442]\tvalidation_0-logloss:0.41152\n",
      "[443]\tvalidation_0-logloss:0.41158\n",
      "[444]\tvalidation_0-logloss:0.41157\n",
      "[445]\tvalidation_0-logloss:0.41159\n",
      "[446]\tvalidation_0-logloss:0.41140\n",
      "[447]\tvalidation_0-logloss:0.41145\n",
      "[448]\tvalidation_0-logloss:0.41154\n",
      "[449]\tvalidation_0-logloss:0.41171\n",
      "[450]\tvalidation_0-logloss:0.41171\n",
      "[451]\tvalidation_0-logloss:0.41170\n",
      "[452]\tvalidation_0-logloss:0.41163\n",
      "[453]\tvalidation_0-logloss:0.41166\n",
      "[454]\tvalidation_0-logloss:0.41164\n",
      "[455]\tvalidation_0-logloss:0.41161\n",
      "[456]\tvalidation_0-logloss:0.41161\n",
      "[457]\tvalidation_0-logloss:0.41160\n",
      "[458]\tvalidation_0-logloss:0.41156\n",
      "[459]\tvalidation_0-logloss:0.41155\n",
      "[460]\tvalidation_0-logloss:0.41165\n",
      "[461]\tvalidation_0-logloss:0.41157\n",
      "[462]\tvalidation_0-logloss:0.41160\n",
      "[463]\tvalidation_0-logloss:0.41165\n",
      "[464]\tvalidation_0-logloss:0.41167\n",
      "[465]\tvalidation_0-logloss:0.41167\n",
      "[466]\tvalidation_0-logloss:0.41171\n",
      "[467]\tvalidation_0-logloss:0.41173\n",
      "[468]\tvalidation_0-logloss:0.41176\n",
      "[469]\tvalidation_0-logloss:0.41180\n",
      "[470]\tvalidation_0-logloss:0.41180\n",
      "[471]\tvalidation_0-logloss:0.41180\n",
      "[472]\tvalidation_0-logloss:0.41180\n",
      "[473]\tvalidation_0-logloss:0.41180\n",
      "[474]\tvalidation_0-logloss:0.41189\n",
      "[475]\tvalidation_0-logloss:0.41184\n",
      "[476]\tvalidation_0-logloss:0.41185\n",
      "[477]\tvalidation_0-logloss:0.41187\n",
      "[478]\tvalidation_0-logloss:0.41185\n",
      "[479]\tvalidation_0-logloss:0.41177\n",
      "[480]\tvalidation_0-logloss:0.41176\n",
      "[481]\tvalidation_0-logloss:0.41188\n",
      "[482]\tvalidation_0-logloss:0.41189\n",
      "[483]\tvalidation_0-logloss:0.41192\n",
      "[484]\tvalidation_0-logloss:0.41186\n",
      "[485]\tvalidation_0-logloss:0.41215\n",
      "[486]\tvalidation_0-logloss:0.41227\n",
      "[487]\tvalidation_0-logloss:0.41224\n",
      "[488]\tvalidation_0-logloss:0.41256\n",
      "[489]\tvalidation_0-logloss:0.41253\n",
      "[490]\tvalidation_0-logloss:0.41250\n",
      "[491]\tvalidation_0-logloss:0.41249\n",
      "[492]\tvalidation_0-logloss:0.41248\n",
      "[493]\tvalidation_0-logloss:0.41252\n",
      "[494]\tvalidation_0-logloss:0.41252\n",
      "[495]\tvalidation_0-logloss:0.41256\n",
      "[496]\tvalidation_0-logloss:0.41255\n",
      "[497]\tvalidation_0-logloss:0.41254\n",
      "[498]\tvalidation_0-logloss:0.41268\n",
      "[499]\tvalidation_0-logloss:0.41278\n",
      "[500]\tvalidation_0-logloss:0.41280\n",
      "[501]\tvalidation_0-logloss:0.41279\n",
      "[502]\tvalidation_0-logloss:0.41279\n",
      "[503]\tvalidation_0-logloss:0.41273\n",
      "[504]\tvalidation_0-logloss:0.41277\n",
      "[505]\tvalidation_0-logloss:0.41278\n",
      "[506]\tvalidation_0-logloss:0.41277\n",
      "[507]\tvalidation_0-logloss:0.41282\n",
      "[508]\tvalidation_0-logloss:0.41299\n",
      "[509]\tvalidation_0-logloss:0.41298\n",
      "[510]\tvalidation_0-logloss:0.41327\n",
      "[511]\tvalidation_0-logloss:0.41325\n",
      "[512]\tvalidation_0-logloss:0.41323\n",
      "[513]\tvalidation_0-logloss:0.41322\n",
      "[514]\tvalidation_0-logloss:0.41321\n",
      "[515]\tvalidation_0-logloss:0.41322\n",
      "[516]\tvalidation_0-logloss:0.41325\n",
      "[517]\tvalidation_0-logloss:0.41325\n",
      "[518]\tvalidation_0-logloss:0.41321\n",
      "[519]\tvalidation_0-logloss:0.41325\n",
      "[520]\tvalidation_0-logloss:0.41325\n",
      "[521]\tvalidation_0-logloss:0.41329\n",
      "[522]\tvalidation_0-logloss:0.41328\n",
      "[523]\tvalidation_0-logloss:0.41329\n",
      "[524]\tvalidation_0-logloss:0.41329\n",
      "[525]\tvalidation_0-logloss:0.41327\n",
      "[526]\tvalidation_0-logloss:0.41326\n",
      "[527]\tvalidation_0-logloss:0.41339\n",
      "[528]\tvalidation_0-logloss:0.41338\n",
      "[529]\tvalidation_0-logloss:0.41338\n",
      "[530]\tvalidation_0-logloss:0.41334\n",
      "[531]\tvalidation_0-logloss:0.41330\n",
      "[532]\tvalidation_0-logloss:0.41329\n",
      "[533]\tvalidation_0-logloss:0.41328\n",
      "[534]\tvalidation_0-logloss:0.41327\n",
      "[535]\tvalidation_0-logloss:0.41326\n",
      "[536]\tvalidation_0-logloss:0.41365\n",
      "[537]\tvalidation_0-logloss:0.41358\n",
      "[538]\tvalidation_0-logloss:0.41360\n",
      "[539]\tvalidation_0-logloss:0.41363\n",
      "[540]\tvalidation_0-logloss:0.41362\n",
      "[541]\tvalidation_0-logloss:0.41363\n",
      "[542]\tvalidation_0-logloss:0.41363\n",
      "[543]\tvalidation_0-logloss:0.41364\n",
      "[544]\tvalidation_0-logloss:0.41354\n",
      "[545]\tvalidation_0-logloss:0.41357\n",
      "[546]\tvalidation_0-logloss:0.41356\n",
      "[547]\tvalidation_0-logloss:0.41382\n",
      "[548]\tvalidation_0-logloss:0.41393\n",
      "[549]\tvalidation_0-logloss:0.41394\n",
      "[550]\tvalidation_0-logloss:0.41397\n",
      "[551]\tvalidation_0-logloss:0.41397\n",
      "[552]\tvalidation_0-logloss:0.41397\n",
      "[553]\tvalidation_0-logloss:0.41401\n",
      "[554]\tvalidation_0-logloss:0.41403\n",
      "[555]\tvalidation_0-logloss:0.41407\n",
      "[556]\tvalidation_0-logloss:0.41410\n",
      "[557]\tvalidation_0-logloss:0.41407\n",
      "[558]\tvalidation_0-logloss:0.41412\n",
      "[559]\tvalidation_0-logloss:0.41413\n",
      "[560]\tvalidation_0-logloss:0.41414\n",
      "[561]\tvalidation_0-logloss:0.41410\n",
      "[562]\tvalidation_0-logloss:0.41405\n",
      "[563]\tvalidation_0-logloss:0.41407\n",
      "[564]\tvalidation_0-logloss:0.41408\n",
      "[565]\tvalidation_0-logloss:0.41409\n",
      "[566]\tvalidation_0-logloss:0.41407\n",
      "[567]\tvalidation_0-logloss:0.41404\n",
      "[568]\tvalidation_0-logloss:0.41403\n",
      "[569]\tvalidation_0-logloss:0.41405\n",
      "[570]\tvalidation_0-logloss:0.41403\n",
      "[571]\tvalidation_0-logloss:0.41407\n",
      "[572]\tvalidation_0-logloss:0.41403\n",
      "[573]\tvalidation_0-logloss:0.41402\n",
      "[574]\tvalidation_0-logloss:0.41403\n",
      "[575]\tvalidation_0-logloss:0.41404\n",
      "[576]\tvalidation_0-logloss:0.41402\n",
      "[577]\tvalidation_0-logloss:0.41411\n",
      "[578]\tvalidation_0-logloss:0.41413\n",
      "[579]\tvalidation_0-logloss:0.41415\n",
      "[580]\tvalidation_0-logloss:0.41415\n",
      "[581]\tvalidation_0-logloss:0.41416\n",
      "[582]\tvalidation_0-logloss:0.41418\n",
      "[583]\tvalidation_0-logloss:0.41416\n",
      "[584]\tvalidation_0-logloss:0.41416\n",
      "[585]\tvalidation_0-logloss:0.41420\n",
      "[586]\tvalidation_0-logloss:0.41434\n",
      "[587]\tvalidation_0-logloss:0.41435\n",
      "[588]\tvalidation_0-logloss:0.41433\n",
      "[589]\tvalidation_0-logloss:0.41434\n",
      "[590]\tvalidation_0-logloss:0.41431\n",
      "[591]\tvalidation_0-logloss:0.41431\n",
      "[592]\tvalidation_0-logloss:0.41435\n",
      "[593]\tvalidation_0-logloss:0.41439\n",
      "[594]\tvalidation_0-logloss:0.41440\n",
      "[595]\tvalidation_0-logloss:0.41442\n",
      "[596]\tvalidation_0-logloss:0.41442\n",
      "[597]\tvalidation_0-logloss:0.41442\n",
      "[598]\tvalidation_0-logloss:0.41445\n",
      "[599]\tvalidation_0-logloss:0.41444\n",
      "[600]\tvalidation_0-logloss:0.41446\n",
      "[601]\tvalidation_0-logloss:0.41446\n",
      "[602]\tvalidation_0-logloss:0.41449\n",
      "[603]\tvalidation_0-logloss:0.41448\n",
      "[604]\tvalidation_0-logloss:0.41451\n",
      "[605]\tvalidation_0-logloss:0.41451\n",
      "[606]\tvalidation_0-logloss:0.41449\n",
      "[607]\tvalidation_0-logloss:0.41444\n",
      "[608]\tvalidation_0-logloss:0.41444\n",
      "[609]\tvalidation_0-logloss:0.41446\n",
      "[610]\tvalidation_0-logloss:0.41446\n",
      "[611]\tvalidation_0-logloss:0.41447\n",
      "[612]\tvalidation_0-logloss:0.41454\n",
      "[613]\tvalidation_0-logloss:0.41461\n",
      "[614]\tvalidation_0-logloss:0.41460\n",
      "[615]\tvalidation_0-logloss:0.41460\n",
      "[616]\tvalidation_0-logloss:0.41460\n",
      "[617]\tvalidation_0-logloss:0.41458\n",
      "[618]\tvalidation_0-logloss:0.41459\n",
      "[619]\tvalidation_0-logloss:0.41459\n",
      "[620]\tvalidation_0-logloss:0.41457\n",
      "[621]\tvalidation_0-logloss:0.41458\n",
      "[622]\tvalidation_0-logloss:0.41457\n",
      "[623]\tvalidation_0-logloss:0.41463\n",
      "[624]\tvalidation_0-logloss:0.41464\n",
      "[625]\tvalidation_0-logloss:0.41458\n",
      "[626]\tvalidation_0-logloss:0.41458\n",
      "[627]\tvalidation_0-logloss:0.41457\n",
      "[628]\tvalidation_0-logloss:0.41457\n",
      "[629]\tvalidation_0-logloss:0.41460\n",
      "[630]\tvalidation_0-logloss:0.41455\n",
      "[631]\tvalidation_0-logloss:0.41457\n",
      "[632]\tvalidation_0-logloss:0.41458\n",
      "[633]\tvalidation_0-logloss:0.41458\n",
      "[634]\tvalidation_0-logloss:0.41456\n",
      "[635]\tvalidation_0-logloss:0.41455\n",
      "[636]\tvalidation_0-logloss:0.41456\n",
      "[637]\tvalidation_0-logloss:0.41460\n",
      "[638]\tvalidation_0-logloss:0.41462\n",
      "[639]\tvalidation_0-logloss:0.41464\n",
      "[640]\tvalidation_0-logloss:0.41466\n",
      "[641]\tvalidation_0-logloss:0.41467\n",
      "[642]\tvalidation_0-logloss:0.41465\n",
      "[643]\tvalidation_0-logloss:0.41468\n",
      "[644]\tvalidation_0-logloss:0.41479\n",
      "[645]\tvalidation_0-logloss:0.41491\n",
      "[646]\tvalidation_0-logloss:0.41493\n",
      "[647]\tvalidation_0-logloss:0.41497\n",
      "[648]\tvalidation_0-logloss:0.41496\n",
      "[649]\tvalidation_0-logloss:0.41469\n",
      "[650]\tvalidation_0-logloss:0.41467\n",
      "[651]\tvalidation_0-logloss:0.41469\n",
      "[652]\tvalidation_0-logloss:0.41468\n",
      "[653]\tvalidation_0-logloss:0.41466\n",
      "[654]\tvalidation_0-logloss:0.41466\n",
      "[655]\tvalidation_0-logloss:0.41465\n",
      "[656]\tvalidation_0-logloss:0.41465\n",
      "[657]\tvalidation_0-logloss:0.41463\n",
      "[658]\tvalidation_0-logloss:0.41466\n",
      "[659]\tvalidation_0-logloss:0.41464\n",
      "[660]\tvalidation_0-logloss:0.41430\n",
      "[661]\tvalidation_0-logloss:0.41431\n",
      "[662]\tvalidation_0-logloss:0.41430\n",
      "[663]\tvalidation_0-logloss:0.41437\n",
      "[664]\tvalidation_0-logloss:0.41434\n",
      "[665]\tvalidation_0-logloss:0.41428\n",
      "[666]\tvalidation_0-logloss:0.41444\n",
      "[667]\tvalidation_0-logloss:0.41444\n",
      "[668]\tvalidation_0-logloss:0.41442\n",
      "[669]\tvalidation_0-logloss:0.41443\n",
      "[670]\tvalidation_0-logloss:0.41444\n",
      "[671]\tvalidation_0-logloss:0.41446\n",
      "[672]\tvalidation_0-logloss:0.41444\n",
      "[673]\tvalidation_0-logloss:0.41443\n",
      "[674]\tvalidation_0-logloss:0.41445\n",
      "[675]\tvalidation_0-logloss:0.41450\n",
      "[676]\tvalidation_0-logloss:0.41449\n",
      "[677]\tvalidation_0-logloss:0.41447\n",
      "[678]\tvalidation_0-logloss:0.41449\n",
      "[679]\tvalidation_0-logloss:0.41449\n",
      "[680]\tvalidation_0-logloss:0.41448\n",
      "[681]\tvalidation_0-logloss:0.41454\n",
      "[682]\tvalidation_0-logloss:0.41458\n",
      "[683]\tvalidation_0-logloss:0.41453\n",
      "[684]\tvalidation_0-logloss:0.41448\n",
      "[685]\tvalidation_0-logloss:0.41453\n",
      "[686]\tvalidation_0-logloss:0.41451\n",
      "[687]\tvalidation_0-logloss:0.41452\n",
      "[688]\tvalidation_0-logloss:0.41467\n",
      "[689]\tvalidation_0-logloss:0.41471\n",
      "[690]\tvalidation_0-logloss:0.41471\n",
      "[691]\tvalidation_0-logloss:0.41467\n",
      "[692]\tvalidation_0-logloss:0.41461\n",
      "[693]\tvalidation_0-logloss:0.41463\n",
      "[694]\tvalidation_0-logloss:0.41461\n",
      "[695]\tvalidation_0-logloss:0.41471\n",
      "[696]\tvalidation_0-logloss:0.41468\n",
      "[697]\tvalidation_0-logloss:0.41469\n",
      "[698]\tvalidation_0-logloss:0.41470\n",
      "[699]\tvalidation_0-logloss:0.41468\n",
      "[700]\tvalidation_0-logloss:0.41466\n",
      "[701]\tvalidation_0-logloss:0.41463\n",
      "[702]\tvalidation_0-logloss:0.41462\n",
      "[703]\tvalidation_0-logloss:0.41464\n",
      "[704]\tvalidation_0-logloss:0.41446\n",
      "[705]\tvalidation_0-logloss:0.41445\n",
      "[706]\tvalidation_0-logloss:0.41446\n",
      "[707]\tvalidation_0-logloss:0.41442\n",
      "[708]\tvalidation_0-logloss:0.41445\n",
      "[709]\tvalidation_0-logloss:0.41442\n",
      "[710]\tvalidation_0-logloss:0.41444\n",
      "[711]\tvalidation_0-logloss:0.41443\n",
      "[712]\tvalidation_0-logloss:0.41445\n",
      "[713]\tvalidation_0-logloss:0.41444\n",
      "[714]\tvalidation_0-logloss:0.41443\n",
      "[715]\tvalidation_0-logloss:0.41446\n",
      "[716]\tvalidation_0-logloss:0.41446\n",
      "[717]\tvalidation_0-logloss:0.41450\n",
      "[718]\tvalidation_0-logloss:0.41451\n",
      "[719]\tvalidation_0-logloss:0.41455\n",
      "[720]\tvalidation_0-logloss:0.41459\n",
      "[721]\tvalidation_0-logloss:0.41456\n",
      "[722]\tvalidation_0-logloss:0.41457\n",
      "[723]\tvalidation_0-logloss:0.41460\n",
      "[724]\tvalidation_0-logloss:0.41459\n",
      "[725]\tvalidation_0-logloss:0.41460\n",
      "[726]\tvalidation_0-logloss:0.41459\n",
      "[727]\tvalidation_0-logloss:0.41457\n",
      "[728]\tvalidation_0-logloss:0.41453\n",
      "[729]\tvalidation_0-logloss:0.41450\n",
      "[730]\tvalidation_0-logloss:0.41450\n",
      "[731]\tvalidation_0-logloss:0.41452\n",
      "[732]\tvalidation_0-logloss:0.41472\n",
      "[733]\tvalidation_0-logloss:0.41476\n",
      "[734]\tvalidation_0-logloss:0.41482\n",
      "[735]\tvalidation_0-logloss:0.41485\n",
      "[736]\tvalidation_0-logloss:0.41483\n",
      "[737]\tvalidation_0-logloss:0.41485\n",
      "[738]\tvalidation_0-logloss:0.41489\n",
      "[739]\tvalidation_0-logloss:0.41487\n",
      "[740]\tvalidation_0-logloss:0.41487\n",
      "[741]\tvalidation_0-logloss:0.41489\n",
      "[742]\tvalidation_0-logloss:0.41485\n",
      "[743]\tvalidation_0-logloss:0.41487\n",
      "[744]\tvalidation_0-logloss:0.41512\n",
      "[745]\tvalidation_0-logloss:0.41513\n",
      "[746]\tvalidation_0-logloss:0.41511\n",
      "[747]\tvalidation_0-logloss:0.41515\n",
      "[748]\tvalidation_0-logloss:0.41518\n",
      "[749]\tvalidation_0-logloss:0.41518\n",
      "[750]\tvalidation_0-logloss:0.41522\n",
      "[751]\tvalidation_0-logloss:0.41522\n",
      "[752]\tvalidation_0-logloss:0.41520\n",
      "[753]\tvalidation_0-logloss:0.41519\n",
      "[754]\tvalidation_0-logloss:0.41525\n",
      "[755]\tvalidation_0-logloss:0.41525\n",
      "[756]\tvalidation_0-logloss:0.41525\n",
      "[757]\tvalidation_0-logloss:0.41523\n",
      "[758]\tvalidation_0-logloss:0.41517\n",
      "[759]\tvalidation_0-logloss:0.41524\n",
      "[760]\tvalidation_0-logloss:0.41510\n",
      "[761]\tvalidation_0-logloss:0.41509\n",
      "[762]\tvalidation_0-logloss:0.41498\n",
      "[763]\tvalidation_0-logloss:0.41497\n",
      "[764]\tvalidation_0-logloss:0.41502\n",
      "[765]\tvalidation_0-logloss:0.41508\n",
      "[766]\tvalidation_0-logloss:0.41508\n",
      "[767]\tvalidation_0-logloss:0.41514\n",
      "[768]\tvalidation_0-logloss:0.41513\n",
      "[769]\tvalidation_0-logloss:0.41514\n",
      "[770]\tvalidation_0-logloss:0.41515\n",
      "[771]\tvalidation_0-logloss:0.41516\n",
      "[772]\tvalidation_0-logloss:0.41514\n",
      "[773]\tvalidation_0-logloss:0.41517\n",
      "[774]\tvalidation_0-logloss:0.41517\n",
      "[775]\tvalidation_0-logloss:0.41517\n",
      "[776]\tvalidation_0-logloss:0.41520\n",
      "[777]\tvalidation_0-logloss:0.41520\n",
      "[778]\tvalidation_0-logloss:0.41526\n",
      "[779]\tvalidation_0-logloss:0.41522\n",
      "[780]\tvalidation_0-logloss:0.41522\n",
      "[781]\tvalidation_0-logloss:0.41520\n",
      "[782]\tvalidation_0-logloss:0.41520\n",
      "[783]\tvalidation_0-logloss:0.41517\n",
      "[784]\tvalidation_0-logloss:0.41519\n",
      "[785]\tvalidation_0-logloss:0.41524\n",
      "[786]\tvalidation_0-logloss:0.41526\n",
      "[787]\tvalidation_0-logloss:0.41524\n",
      "[788]\tvalidation_0-logloss:0.41528\n",
      "[789]\tvalidation_0-logloss:0.41523\n",
      "[790]\tvalidation_0-logloss:0.41525\n",
      "[791]\tvalidation_0-logloss:0.41525\n",
      "[792]\tvalidation_0-logloss:0.41527\n",
      "[793]\tvalidation_0-logloss:0.41523\n",
      "[794]\tvalidation_0-logloss:0.41521\n",
      "[795]\tvalidation_0-logloss:0.41518\n",
      "[796]\tvalidation_0-logloss:0.41516\n",
      "[797]\tvalidation_0-logloss:0.41517\n",
      "[798]\tvalidation_0-logloss:0.41517\n",
      "[799]\tvalidation_0-logloss:0.41532\n",
      "[800]\tvalidation_0-logloss:0.41532\n",
      "[801]\tvalidation_0-logloss:0.41530\n",
      "[802]\tvalidation_0-logloss:0.41530\n",
      "[803]\tvalidation_0-logloss:0.41533\n",
      "[804]\tvalidation_0-logloss:0.41535\n",
      "[805]\tvalidation_0-logloss:0.41538\n",
      "[806]\tvalidation_0-logloss:0.41538\n",
      "[807]\tvalidation_0-logloss:0.41534\n",
      "[808]\tvalidation_0-logloss:0.41536\n",
      "[809]\tvalidation_0-logloss:0.41531\n",
      "[810]\tvalidation_0-logloss:0.41533\n",
      "[811]\tvalidation_0-logloss:0.41530\n",
      "[812]\tvalidation_0-logloss:0.41534\n",
      "[813]\tvalidation_0-logloss:0.41533\n",
      "[814]\tvalidation_0-logloss:0.41536\n",
      "[815]\tvalidation_0-logloss:0.41538\n",
      "[816]\tvalidation_0-logloss:0.41538\n",
      "[817]\tvalidation_0-logloss:0.41540\n",
      "[818]\tvalidation_0-logloss:0.41542\n",
      "[819]\tvalidation_0-logloss:0.41542\n",
      "[820]\tvalidation_0-logloss:0.41545\n",
      "[821]\tvalidation_0-logloss:0.41547\n",
      "[822]\tvalidation_0-logloss:0.41546\n",
      "[823]\tvalidation_0-logloss:0.41546\n",
      "[824]\tvalidation_0-logloss:0.41542\n",
      "[825]\tvalidation_0-logloss:0.41545\n",
      "[826]\tvalidation_0-logloss:0.41543\n",
      "[827]\tvalidation_0-logloss:0.41540\n",
      "[828]\tvalidation_0-logloss:0.41538\n",
      "[829]\tvalidation_0-logloss:0.41537\n",
      "[830]\tvalidation_0-logloss:0.41537\n",
      "[831]\tvalidation_0-logloss:0.41538\n",
      "[832]\tvalidation_0-logloss:0.41536\n",
      "[833]\tvalidation_0-logloss:0.41532\n",
      "[834]\tvalidation_0-logloss:0.41528\n",
      "[835]\tvalidation_0-logloss:0.41531\n",
      "[836]\tvalidation_0-logloss:0.41516\n",
      "[837]\tvalidation_0-logloss:0.41519\n",
      "[838]\tvalidation_0-logloss:0.41519\n",
      "[839]\tvalidation_0-logloss:0.41518\n",
      "[840]\tvalidation_0-logloss:0.41525\n",
      "[841]\tvalidation_0-logloss:0.41526\n",
      "[842]\tvalidation_0-logloss:0.41528\n",
      "[843]\tvalidation_0-logloss:0.41525\n",
      "[844]\tvalidation_0-logloss:0.41522\n",
      "[845]\tvalidation_0-logloss:0.41524\n",
      "[846]\tvalidation_0-logloss:0.41525\n",
      "[847]\tvalidation_0-logloss:0.41525\n",
      "[848]\tvalidation_0-logloss:0.41526\n",
      "[849]\tvalidation_0-logloss:0.41571\n",
      "[850]\tvalidation_0-logloss:0.41574\n",
      "[851]\tvalidation_0-logloss:0.41578\n",
      "[852]\tvalidation_0-logloss:0.41577\n",
      "[853]\tvalidation_0-logloss:0.41576\n",
      "[854]\tvalidation_0-logloss:0.41577\n",
      "[855]\tvalidation_0-logloss:0.41573\n",
      "[856]\tvalidation_0-logloss:0.41570\n",
      "[857]\tvalidation_0-logloss:0.41568\n",
      "[858]\tvalidation_0-logloss:0.41565\n",
      "[859]\tvalidation_0-logloss:0.41565\n",
      "[860]\tvalidation_0-logloss:0.41571\n",
      "[861]\tvalidation_0-logloss:0.41561\n",
      "[862]\tvalidation_0-logloss:0.41561\n",
      "[863]\tvalidation_0-logloss:0.41560\n",
      "[864]\tvalidation_0-logloss:0.41556\n",
      "[865]\tvalidation_0-logloss:0.41555\n",
      "[866]\tvalidation_0-logloss:0.41564\n",
      "[867]\tvalidation_0-logloss:0.41565\n",
      "[868]\tvalidation_0-logloss:0.41563\n",
      "[869]\tvalidation_0-logloss:0.41549\n",
      "[870]\tvalidation_0-logloss:0.41549\n",
      "[871]\tvalidation_0-logloss:0.41549\n",
      "[872]\tvalidation_0-logloss:0.41553\n",
      "[873]\tvalidation_0-logloss:0.41550\n",
      "[874]\tvalidation_0-logloss:0.41553\n",
      "[875]\tvalidation_0-logloss:0.41548\n",
      "[876]\tvalidation_0-logloss:0.41548\n",
      "[877]\tvalidation_0-logloss:0.41548\n",
      "[878]\tvalidation_0-logloss:0.41546\n",
      "[879]\tvalidation_0-logloss:0.41549\n",
      "[880]\tvalidation_0-logloss:0.41552\n",
      "[881]\tvalidation_0-logloss:0.41548\n",
      "[882]\tvalidation_0-logloss:0.41549\n",
      "[883]\tvalidation_0-logloss:0.41550\n",
      "[884]\tvalidation_0-logloss:0.41549\n",
      "[885]\tvalidation_0-logloss:0.41547\n",
      "[886]\tvalidation_0-logloss:0.41551\n",
      "[887]\tvalidation_0-logloss:0.41545\n",
      "[888]\tvalidation_0-logloss:0.41546\n",
      "[889]\tvalidation_0-logloss:0.41547\n",
      "[890]\tvalidation_0-logloss:0.41548\n",
      "[891]\tvalidation_0-logloss:0.41549\n",
      "[892]\tvalidation_0-logloss:0.41552\n",
      "[893]\tvalidation_0-logloss:0.41565\n",
      "[894]\tvalidation_0-logloss:0.41562\n",
      "[895]\tvalidation_0-logloss:0.41561\n",
      "[896]\tvalidation_0-logloss:0.41563\n",
      "[897]\tvalidation_0-logloss:0.41566\n",
      "[898]\tvalidation_0-logloss:0.41567\n",
      "[899]\tvalidation_0-logloss:0.41570\n",
      "[900]\tvalidation_0-logloss:0.41573\n",
      "[901]\tvalidation_0-logloss:0.41573\n",
      "[902]\tvalidation_0-logloss:0.41575\n",
      "[903]\tvalidation_0-logloss:0.41595\n",
      "[904]\tvalidation_0-logloss:0.41596\n",
      "[905]\tvalidation_0-logloss:0.41596\n",
      "[906]\tvalidation_0-logloss:0.41596\n",
      "[907]\tvalidation_0-logloss:0.41597\n",
      "[908]\tvalidation_0-logloss:0.41598\n",
      "[909]\tvalidation_0-logloss:0.41593\n",
      "[910]\tvalidation_0-logloss:0.41592\n",
      "[911]\tvalidation_0-logloss:0.41590\n",
      "[912]\tvalidation_0-logloss:0.41593\n",
      "[913]\tvalidation_0-logloss:0.41591\n",
      "[914]\tvalidation_0-logloss:0.41592\n",
      "[915]\tvalidation_0-logloss:0.41593\n",
      "[916]\tvalidation_0-logloss:0.41596\n",
      "[917]\tvalidation_0-logloss:0.41596\n",
      "[918]\tvalidation_0-logloss:0.41598\n",
      "[919]\tvalidation_0-logloss:0.41598\n",
      "[920]\tvalidation_0-logloss:0.41598\n",
      "[921]\tvalidation_0-logloss:0.41596\n",
      "[922]\tvalidation_0-logloss:0.41596\n",
      "[923]\tvalidation_0-logloss:0.41594\n",
      "[924]\tvalidation_0-logloss:0.41588\n",
      "[925]\tvalidation_0-logloss:0.41588\n",
      "[926]\tvalidation_0-logloss:0.41592\n",
      "[927]\tvalidation_0-logloss:0.41594\n",
      "[928]\tvalidation_0-logloss:0.41596\n",
      "[929]\tvalidation_0-logloss:0.41600\n",
      "[930]\tvalidation_0-logloss:0.41600\n",
      "[931]\tvalidation_0-logloss:0.41599\n",
      "[932]\tvalidation_0-logloss:0.41604\n",
      "[933]\tvalidation_0-logloss:0.41606\n",
      "[934]\tvalidation_0-logloss:0.41604\n",
      "[935]\tvalidation_0-logloss:0.41604\n",
      "[936]\tvalidation_0-logloss:0.41587\n",
      "[937]\tvalidation_0-logloss:0.41586\n",
      "[938]\tvalidation_0-logloss:0.41583\n",
      "[939]\tvalidation_0-logloss:0.41582\n",
      "[940]\tvalidation_0-logloss:0.41582\n",
      "[941]\tvalidation_0-logloss:0.41585\n",
      "[942]\tvalidation_0-logloss:0.41588\n",
      "[943]\tvalidation_0-logloss:0.41588\n",
      "[944]\tvalidation_0-logloss:0.41591\n",
      "[945]\tvalidation_0-logloss:0.41594\n",
      "[946]\tvalidation_0-logloss:0.41594\n",
      "[947]\tvalidation_0-logloss:0.41591\n",
      "[948]\tvalidation_0-logloss:0.41591\n",
      "[949]\tvalidation_0-logloss:0.41592\n",
      "[950]\tvalidation_0-logloss:0.41594\n",
      "[951]\tvalidation_0-logloss:0.41589\n",
      "[952]\tvalidation_0-logloss:0.41583\n",
      "[953]\tvalidation_0-logloss:0.41583\n",
      "[954]\tvalidation_0-logloss:0.41581\n",
      "[955]\tvalidation_0-logloss:0.41575\n",
      "[956]\tvalidation_0-logloss:0.41575\n",
      "[957]\tvalidation_0-logloss:0.41572\n",
      "[958]\tvalidation_0-logloss:0.41562\n",
      "[959]\tvalidation_0-logloss:0.41561\n",
      "[960]\tvalidation_0-logloss:0.41561\n",
      "[961]\tvalidation_0-logloss:0.41561\n",
      "[962]\tvalidation_0-logloss:0.41563\n",
      "[963]\tvalidation_0-logloss:0.41564\n",
      "[964]\tvalidation_0-logloss:0.41562\n",
      "[965]\tvalidation_0-logloss:0.41565\n",
      "[966]\tvalidation_0-logloss:0.41566\n",
      "[967]\tvalidation_0-logloss:0.41569\n",
      "[968]\tvalidation_0-logloss:0.41564\n",
      "[969]\tvalidation_0-logloss:0.41576\n",
      "[970]\tvalidation_0-logloss:0.41576\n",
      "[971]\tvalidation_0-logloss:0.41582\n",
      "[972]\tvalidation_0-logloss:0.41581\n",
      "[973]\tvalidation_0-logloss:0.41579\n",
      "[974]\tvalidation_0-logloss:0.41579\n",
      "[975]\tvalidation_0-logloss:0.41579\n",
      "[976]\tvalidation_0-logloss:0.41577\n",
      "[977]\tvalidation_0-logloss:0.41580\n",
      "[978]\tvalidation_0-logloss:0.41582\n",
      "[979]\tvalidation_0-logloss:0.41583\n",
      "[980]\tvalidation_0-logloss:0.41587\n",
      "[981]\tvalidation_0-logloss:0.41587\n",
      "[982]\tvalidation_0-logloss:0.41586\n",
      "[983]\tvalidation_0-logloss:0.41588\n",
      "[984]\tvalidation_0-logloss:0.41586\n",
      "[985]\tvalidation_0-logloss:0.41585\n",
      "[986]\tvalidation_0-logloss:0.41589\n",
      "[987]\tvalidation_0-logloss:0.41589\n",
      "[988]\tvalidation_0-logloss:0.41586\n",
      "[989]\tvalidation_0-logloss:0.41588\n",
      "[990]\tvalidation_0-logloss:0.41591\n",
      "[991]\tvalidation_0-logloss:0.41597\n",
      "[992]\tvalidation_0-logloss:0.41589\n",
      "[993]\tvalidation_0-logloss:0.41590\n",
      "[994]\tvalidation_0-logloss:0.41592\n",
      "[995]\tvalidation_0-logloss:0.41592\n",
      "[996]\tvalidation_0-logloss:0.41593\n",
      "[997]\tvalidation_0-logloss:0.41595\n",
      "[998]\tvalidation_0-logloss:0.41595\n",
      "[999]\tvalidation_0-logloss:0.41595\n",
      "[1000]\tvalidation_0-logloss:0.41596\n",
      "[1001]\tvalidation_0-logloss:0.41613\n",
      "[1002]\tvalidation_0-logloss:0.41611\n",
      "[1003]\tvalidation_0-logloss:0.41607\n",
      "[1004]\tvalidation_0-logloss:0.41610\n",
      "[1005]\tvalidation_0-logloss:0.41605\n",
      "[1006]\tvalidation_0-logloss:0.41607\n",
      "[1007]\tvalidation_0-logloss:0.41606\n",
      "[1008]\tvalidation_0-logloss:0.41608\n",
      "[1009]\tvalidation_0-logloss:0.41606\n",
      "[1010]\tvalidation_0-logloss:0.41605\n",
      "[1011]\tvalidation_0-logloss:0.41603\n",
      "[1012]\tvalidation_0-logloss:0.41608\n",
      "[1013]\tvalidation_0-logloss:0.41600\n",
      "[1014]\tvalidation_0-logloss:0.41602\n",
      "[1015]\tvalidation_0-logloss:0.41603\n",
      "[1016]\tvalidation_0-logloss:0.41603\n",
      "[1017]\tvalidation_0-logloss:0.41605\n",
      "[1018]\tvalidation_0-logloss:0.41602\n",
      "[1019]\tvalidation_0-logloss:0.41602\n",
      "[1020]\tvalidation_0-logloss:0.41598\n",
      "[1021]\tvalidation_0-logloss:0.41598\n",
      "[1022]\tvalidation_0-logloss:0.41597\n",
      "[1023]\tvalidation_0-logloss:0.41601\n",
      "[1024]\tvalidation_0-logloss:0.41593\n",
      "[1025]\tvalidation_0-logloss:0.41594\n",
      "[1026]\tvalidation_0-logloss:0.41601\n",
      "[1027]\tvalidation_0-logloss:0.41599\n",
      "[1028]\tvalidation_0-logloss:0.41595\n",
      "[1029]\tvalidation_0-logloss:0.41597\n",
      "[1030]\tvalidation_0-logloss:0.41596\n",
      "[1031]\tvalidation_0-logloss:0.41600\n",
      "[1032]\tvalidation_0-logloss:0.41600\n",
      "[1033]\tvalidation_0-logloss:0.41601\n",
      "[1034]\tvalidation_0-logloss:0.41604\n",
      "[1035]\tvalidation_0-logloss:0.41607\n",
      "[1036]\tvalidation_0-logloss:0.41608\n",
      "[1037]\tvalidation_0-logloss:0.41608\n",
      "[1038]\tvalidation_0-logloss:0.41605\n",
      "[1039]\tvalidation_0-logloss:0.41611\n",
      "[1040]\tvalidation_0-logloss:0.41610\n",
      "[1041]\tvalidation_0-logloss:0.41612\n",
      "[1042]\tvalidation_0-logloss:0.41612\n",
      "[1043]\tvalidation_0-logloss:0.41608\n",
      "[1044]\tvalidation_0-logloss:0.41610\n",
      "[1045]\tvalidation_0-logloss:0.41609\n",
      "[1046]\tvalidation_0-logloss:0.41601\n",
      "[1047]\tvalidation_0-logloss:0.41599\n",
      "[1048]\tvalidation_0-logloss:0.41599\n",
      "[1049]\tvalidation_0-logloss:0.41600\n",
      "[1050]\tvalidation_0-logloss:0.41597\n",
      "[1051]\tvalidation_0-logloss:0.41601\n",
      "[1052]\tvalidation_0-logloss:0.41598\n",
      "[1053]\tvalidation_0-logloss:0.41598\n",
      "[1054]\tvalidation_0-logloss:0.41593\n",
      "[1055]\tvalidation_0-logloss:0.41592\n",
      "[1056]\tvalidation_0-logloss:0.41601\n",
      "[1057]\tvalidation_0-logloss:0.41601\n",
      "[1058]\tvalidation_0-logloss:0.41600\n",
      "[1059]\tvalidation_0-logloss:0.41600\n",
      "[1060]\tvalidation_0-logloss:0.41602\n",
      "[1061]\tvalidation_0-logloss:0.41602\n",
      "[1062]\tvalidation_0-logloss:0.41605\n",
      "[1063]\tvalidation_0-logloss:0.41606\n",
      "[1064]\tvalidation_0-logloss:0.41606\n",
      "[1065]\tvalidation_0-logloss:0.41606\n",
      "[1066]\tvalidation_0-logloss:0.41606\n",
      "[1067]\tvalidation_0-logloss:0.41606\n",
      "[1068]\tvalidation_0-logloss:0.41608\n",
      "[1069]\tvalidation_0-logloss:0.41614\n",
      "[1070]\tvalidation_0-logloss:0.41613\n",
      "[1071]\tvalidation_0-logloss:0.41612\n",
      "[1072]\tvalidation_0-logloss:0.41614\n",
      "[1073]\tvalidation_0-logloss:0.41614\n",
      "[1074]\tvalidation_0-logloss:0.41611\n",
      "[1075]\tvalidation_0-logloss:0.41613\n",
      "[1076]\tvalidation_0-logloss:0.41618\n",
      "[1077]\tvalidation_0-logloss:0.41616\n",
      "[1078]\tvalidation_0-logloss:0.41614\n",
      "[1079]\tvalidation_0-logloss:0.41614\n",
      "[1080]\tvalidation_0-logloss:0.41616\n",
      "[1081]\tvalidation_0-logloss:0.41615\n",
      "[1082]\tvalidation_0-logloss:0.41617\n",
      "[1083]\tvalidation_0-logloss:0.41617\n",
      "[1084]\tvalidation_0-logloss:0.41618\n",
      "[1085]\tvalidation_0-logloss:0.41618\n",
      "[1086]\tvalidation_0-logloss:0.41619\n",
      "[1087]\tvalidation_0-logloss:0.41621\n",
      "[1088]\tvalidation_0-logloss:0.41623\n",
      "[1089]\tvalidation_0-logloss:0.41622\n",
      "[1090]\tvalidation_0-logloss:0.41623\n",
      "[1091]\tvalidation_0-logloss:0.41623\n",
      "[1092]\tvalidation_0-logloss:0.41622\n",
      "[1093]\tvalidation_0-logloss:0.41618\n",
      "[1094]\tvalidation_0-logloss:0.41619\n",
      "[1095]\tvalidation_0-logloss:0.41618\n",
      "[1096]\tvalidation_0-logloss:0.41620\n",
      "[1097]\tvalidation_0-logloss:0.41623\n",
      "[1098]\tvalidation_0-logloss:0.41622\n",
      "[1099]\tvalidation_0-logloss:0.41621\n",
      "[1100]\tvalidation_0-logloss:0.41624\n",
      "[1101]\tvalidation_0-logloss:0.41627\n",
      "[1102]\tvalidation_0-logloss:0.41630\n",
      "[1103]\tvalidation_0-logloss:0.41629\n",
      "[1104]\tvalidation_0-logloss:0.41630\n",
      "[1105]\tvalidation_0-logloss:0.41619\n",
      "[1106]\tvalidation_0-logloss:0.41614\n",
      "[1107]\tvalidation_0-logloss:0.41616\n",
      "[1108]\tvalidation_0-logloss:0.41615\n",
      "[1109]\tvalidation_0-logloss:0.41614\n",
      "[1110]\tvalidation_0-logloss:0.41614\n",
      "[1111]\tvalidation_0-logloss:0.41615\n",
      "[1112]\tvalidation_0-logloss:0.41618\n",
      "[1113]\tvalidation_0-logloss:0.41619\n",
      "[1114]\tvalidation_0-logloss:0.41624\n",
      "[1115]\tvalidation_0-logloss:0.41625\n",
      "[1116]\tvalidation_0-logloss:0.41629\n",
      "[1117]\tvalidation_0-logloss:0.41622\n",
      "[1118]\tvalidation_0-logloss:0.41622\n",
      "[1119]\tvalidation_0-logloss:0.41620\n",
      "[1120]\tvalidation_0-logloss:0.41622\n",
      "[1121]\tvalidation_0-logloss:0.41624\n",
      "[1122]\tvalidation_0-logloss:0.41623\n",
      "[1123]\tvalidation_0-logloss:0.41623\n",
      "[1124]\tvalidation_0-logloss:0.41625\n",
      "[1125]\tvalidation_0-logloss:0.41626\n",
      "[1126]\tvalidation_0-logloss:0.41621\n",
      "[1127]\tvalidation_0-logloss:0.41627\n",
      "[1128]\tvalidation_0-logloss:0.41631\n",
      "[1129]\tvalidation_0-logloss:0.41632\n",
      "[1130]\tvalidation_0-logloss:0.41631\n",
      "[1131]\tvalidation_0-logloss:0.41633\n",
      "[1132]\tvalidation_0-logloss:0.41635\n",
      "[1133]\tvalidation_0-logloss:0.41633\n",
      "[1134]\tvalidation_0-logloss:0.41635\n",
      "[1135]\tvalidation_0-logloss:0.41636\n",
      "[1136]\tvalidation_0-logloss:0.41635\n",
      "[1137]\tvalidation_0-logloss:0.41633\n",
      "[1138]\tvalidation_0-logloss:0.41633\n",
      "[1139]\tvalidation_0-logloss:0.41630\n",
      "[1140]\tvalidation_0-logloss:0.41632\n",
      "[1141]\tvalidation_0-logloss:0.41632\n",
      "[1142]\tvalidation_0-logloss:0.41632\n",
      "[1143]\tvalidation_0-logloss:0.41631\n",
      "[1144]\tvalidation_0-logloss:0.41632\n",
      "[1145]\tvalidation_0-logloss:0.41631\n",
      "[1146]\tvalidation_0-logloss:0.41631\n",
      "[1147]\tvalidation_0-logloss:0.41634\n",
      "[1148]\tvalidation_0-logloss:0.41623\n",
      "[1149]\tvalidation_0-logloss:0.41624\n",
      "[1150]\tvalidation_0-logloss:0.41624\n",
      "[1151]\tvalidation_0-logloss:0.41622\n",
      "[1152]\tvalidation_0-logloss:0.41625\n",
      "[1153]\tvalidation_0-logloss:0.41625\n",
      "[1154]\tvalidation_0-logloss:0.41624\n",
      "[1155]\tvalidation_0-logloss:0.41620\n",
      "[1156]\tvalidation_0-logloss:0.41621\n",
      "[1157]\tvalidation_0-logloss:0.41618\n",
      "[1158]\tvalidation_0-logloss:0.41616\n",
      "[1159]\tvalidation_0-logloss:0.41615\n",
      "[1160]\tvalidation_0-logloss:0.41615\n",
      "[1161]\tvalidation_0-logloss:0.41617\n",
      "[1162]\tvalidation_0-logloss:0.41618\n",
      "[1163]\tvalidation_0-logloss:0.41616\n",
      "[1164]\tvalidation_0-logloss:0.41611\n",
      "[1165]\tvalidation_0-logloss:0.41612\n",
      "[1166]\tvalidation_0-logloss:0.41608\n",
      "[1167]\tvalidation_0-logloss:0.41608\n",
      "[1168]\tvalidation_0-logloss:0.41611\n",
      "[1169]\tvalidation_0-logloss:0.41610\n",
      "[1170]\tvalidation_0-logloss:0.41610\n",
      "[1171]\tvalidation_0-logloss:0.41612\n",
      "[1172]\tvalidation_0-logloss:0.41617\n",
      "[1173]\tvalidation_0-logloss:0.41621\n",
      "[1174]\tvalidation_0-logloss:0.41623\n",
      "[1175]\tvalidation_0-logloss:0.41620\n",
      "[1176]\tvalidation_0-logloss:0.41623\n",
      "[1177]\tvalidation_0-logloss:0.41627\n",
      "[1178]\tvalidation_0-logloss:0.41629\n",
      "[1179]\tvalidation_0-logloss:0.41630\n",
      "[1180]\tvalidation_0-logloss:0.41627\n",
      "[1181]\tvalidation_0-logloss:0.41633\n",
      "[1182]\tvalidation_0-logloss:0.41629\n",
      "[1183]\tvalidation_0-logloss:0.41632\n",
      "[1184]\tvalidation_0-logloss:0.41638\n",
      "[1185]\tvalidation_0-logloss:0.41639\n",
      "[1186]\tvalidation_0-logloss:0.41639\n",
      "[1187]\tvalidation_0-logloss:0.41640\n",
      "[1188]\tvalidation_0-logloss:0.41634\n",
      "[1189]\tvalidation_0-logloss:0.41634\n",
      "[1190]\tvalidation_0-logloss:0.41634\n",
      "[1191]\tvalidation_0-logloss:0.41636\n",
      "[1192]\tvalidation_0-logloss:0.41639\n",
      "[1193]\tvalidation_0-logloss:0.41637\n",
      "[1194]\tvalidation_0-logloss:0.41633\n",
      "[1195]\tvalidation_0-logloss:0.41628\n",
      "[1196]\tvalidation_0-logloss:0.41628\n",
      "[1197]\tvalidation_0-logloss:0.41629\n",
      "[1198]\tvalidation_0-logloss:0.41626\n",
      "[1199]\tvalidation_0-logloss:0.41629\n",
      "[1200]\tvalidation_0-logloss:0.41626\n",
      "[1201]\tvalidation_0-logloss:0.41630\n",
      "[1202]\tvalidation_0-logloss:0.41628\n",
      "[1203]\tvalidation_0-logloss:0.41629\n",
      "[1204]\tvalidation_0-logloss:0.41627\n",
      "[1205]\tvalidation_0-logloss:0.41628\n",
      "[1206]\tvalidation_0-logloss:0.41630\n",
      "[1207]\tvalidation_0-logloss:0.41632\n",
      "[1208]\tvalidation_0-logloss:0.41629\n",
      "[1209]\tvalidation_0-logloss:0.41631\n",
      "[1210]\tvalidation_0-logloss:0.41634\n",
      "[1211]\tvalidation_0-logloss:0.41633\n",
      "[1212]\tvalidation_0-logloss:0.41631\n",
      "[1213]\tvalidation_0-logloss:0.41626\n",
      "[1214]\tvalidation_0-logloss:0.41626\n",
      "[1215]\tvalidation_0-logloss:0.41624\n",
      "[1216]\tvalidation_0-logloss:0.41624\n",
      "[1217]\tvalidation_0-logloss:0.41624\n",
      "[1218]\tvalidation_0-logloss:0.41627\n",
      "[1219]\tvalidation_0-logloss:0.41627\n",
      "[1220]\tvalidation_0-logloss:0.41628\n",
      "[1221]\tvalidation_0-logloss:0.41631\n",
      "[1222]\tvalidation_0-logloss:0.41632\n",
      "[1223]\tvalidation_0-logloss:0.41634\n",
      "[1224]\tvalidation_0-logloss:0.41633\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.7608426444691376,\n",
       "              colsample_bynode=0.7964685684175228,\n",
       "              colsample_bytree=0.6629506354849434, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=0.6779205303297494, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.040803984002659034,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=0, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1225, n_jobs=-1,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gbtree&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">0.7608426444691376</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">0.7964685684175228</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.6629506354849434</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">0.6779205303297494</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.040803984002659034</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">1225</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">13</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.10190980346908472</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.9427251689165057</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(2.866913123844732)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.8573575194549008</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;hist&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=0.7608426444691376,\n",
       "              colsample_bynode=0.7964685684175228,\n",
       "              colsample_bytree=0.6629506354849434, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=0.6779205303297494, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.040803984002659034,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=0, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1225, n_jobs=-1,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_xgbm: dict = study_xgbm.best_params.copy()\n",
    "BASE_MODEL_XGBM: XGBClassifier = XGBClassifier(\n",
    "    **best_params_xgbm , \n",
    "    random_state = 13,\n",
    "    objective = 'binary:logistic',\n",
    "    booster= 'gbtree',\n",
    "    tree_method = 'hist',\n",
    "    n_jobs = -1,\n",
    "    scale_pos_weight = (Y_ROOT_TRAIN == 0).sum()/(Y_ROOT_TRAIN == 1).sum()\n",
    "    )\n",
    "BASE_MODEL_XGBM.fit(X_ROOT_TRAIN , \n",
    "                    Y_ROOT_TRAIN , \n",
    "                    eval_set = [(X_ROOT_TEST , Y_ROOT_TEST)],\n",
    "                    verbose = True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73157501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 541, number of negative: 1551\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 752\n",
      "[LightGBM] [Info] Number of data points in the train set: 2092, number of used features: 65\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258604 -> initscore=-1.053236\n",
      "[LightGBM] [Info] Start training from score -1.053236\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(colsample_bytree=0.4550136414377964,\n",
       "               learning_rate=0.04347414519375591, max_bin=46, max_depth=7,\n",
       "               min_child_samples=5, min_child_weight=0.3023021334034122,\n",
       "               n_estimators=1729, n_jobs=-1, objective=&#x27;binary&#x27;,\n",
       "               random_state=13, reg_alpha=1.1965259005415732,\n",
       "               reg_lambda=0.11421626702180687,\n",
       "               scale_pos_weight=np.float64(2.866913123844732),\n",
       "               subsample=0.9704153174039498)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('boosting_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">boosting_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gbdt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves&nbsp;</td>\n",
       "            <td class=\"value\">31</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.04347414519375591</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">1729</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_for_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_for_bin&nbsp;</td>\n",
       "            <td class=\"value\">200000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_split_gain',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_split_gain&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">0.3023021334034122</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.9704153174039498</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_freq',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_freq&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.4550136414377964</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">1.1965259005415732</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.11421626702180687</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">13</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;split&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">46</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(2.866913123844732)</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.4550136414377964,\n",
       "               learning_rate=0.04347414519375591, max_bin=46, max_depth=7,\n",
       "               min_child_samples=5, min_child_weight=0.3023021334034122,\n",
       "               n_estimators=1729, n_jobs=-1, objective='binary',\n",
       "               random_state=13, reg_alpha=1.1965259005415732,\n",
       "               reg_lambda=0.11421626702180687,\n",
       "               scale_pos_weight=np.float64(2.866913123844732),\n",
       "               subsample=0.9704153174039498)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_lgbm: dict = study_lgbm.best_params.copy()\n",
    "BASE_MODEL_LGBM: LGBMClassifier = LGBMClassifier(\n",
    "    **best_params_lgbm ,\n",
    "    n_jobs = -1,\n",
    "    random_state = 13,\n",
    "    boosting_type = 'gbdt',\n",
    "    objective = 'binary',\n",
    "    scale_pos_weight = (Y_ROOT_TRAIN == 0).sum()/(Y_ROOT_TRAIN == 1).sum()\n",
    "    )\n",
    "BASE_MODEL_LGBM.fit(\n",
    "    X_ROOT_TRAIN,\n",
    "    Y_ROOT_TRAIN,\n",
    "    eval_set = [(X_ROOT_TEST, Y_ROOT_TEST)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a6e1099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6856310\ttest: 0.6879249\tbest: 0.6879249 (0)\ttotal: 150ms\tremaining: 2m 48s\n",
      "1:\tlearn: 0.6790761\ttest: 0.6831120\tbest: 0.6831120 (1)\ttotal: 154ms\tremaining: 1m 26s\n",
      "2:\tlearn: 0.6712247\ttest: 0.6776106\tbest: 0.6776106 (2)\ttotal: 157ms\tremaining: 59s\n",
      "3:\tlearn: 0.6636492\ttest: 0.6724871\tbest: 0.6724871 (3)\ttotal: 161ms\tremaining: 45.1s\n",
      "4:\tlearn: 0.6568483\ttest: 0.6673685\tbest: 0.6673685 (4)\ttotal: 164ms\tremaining: 36.8s\n",
      "5:\tlearn: 0.6494051\ttest: 0.6615250\tbest: 0.6615250 (5)\ttotal: 168ms\tremaining: 31.4s\n",
      "6:\tlearn: 0.6426725\ttest: 0.6560672\tbest: 0.6560672 (6)\ttotal: 172ms\tremaining: 27.5s\n",
      "7:\tlearn: 0.6362942\ttest: 0.6514951\tbest: 0.6514951 (7)\ttotal: 175ms\tremaining: 24.5s\n",
      "8:\tlearn: 0.6293386\ttest: 0.6463849\tbest: 0.6463849 (8)\ttotal: 179ms\tremaining: 22.2s\n",
      "9:\tlearn: 0.6230319\ttest: 0.6418959\tbest: 0.6418959 (9)\ttotal: 183ms\tremaining: 20.4s\n",
      "10:\tlearn: 0.6165988\ttest: 0.6371324\tbest: 0.6371324 (10)\ttotal: 186ms\tremaining: 18.9s\n",
      "11:\tlearn: 0.6105294\ttest: 0.6334278\tbest: 0.6334278 (11)\ttotal: 189ms\tremaining: 17.6s\n",
      "12:\tlearn: 0.6045752\ttest: 0.6290506\tbest: 0.6290506 (12)\ttotal: 193ms\tremaining: 16.6s\n",
      "13:\tlearn: 0.5986789\ttest: 0.6247080\tbest: 0.6247080 (13)\ttotal: 196ms\tremaining: 15.6s\n",
      "14:\tlearn: 0.5929011\ttest: 0.6213405\tbest: 0.6213405 (14)\ttotal: 200ms\tremaining: 14.8s\n",
      "15:\tlearn: 0.5873877\ttest: 0.6172410\tbest: 0.6172410 (15)\ttotal: 204ms\tremaining: 14.2s\n",
      "16:\tlearn: 0.5821751\ttest: 0.6133477\tbest: 0.6133477 (16)\ttotal: 208ms\tremaining: 13.6s\n",
      "17:\tlearn: 0.5772440\ttest: 0.6099746\tbest: 0.6099746 (17)\ttotal: 211ms\tremaining: 13s\n",
      "18:\tlearn: 0.5725999\ttest: 0.6071798\tbest: 0.6071798 (18)\ttotal: 215ms\tremaining: 12.6s\n",
      "19:\tlearn: 0.5677752\ttest: 0.6045710\tbest: 0.6045710 (19)\ttotal: 219ms\tremaining: 12.1s\n",
      "20:\tlearn: 0.5630125\ttest: 0.6009388\tbest: 0.6009388 (20)\ttotal: 223ms\tremaining: 11.7s\n",
      "21:\tlearn: 0.5583740\ttest: 0.5983033\tbest: 0.5983033 (21)\ttotal: 226ms\tremaining: 11.4s\n",
      "22:\tlearn: 0.5533886\ttest: 0.5947545\tbest: 0.5947545 (22)\ttotal: 230ms\tremaining: 11s\n",
      "23:\tlearn: 0.5490221\ttest: 0.5921497\tbest: 0.5921497 (23)\ttotal: 233ms\tremaining: 10.7s\n",
      "24:\tlearn: 0.5435505\ttest: 0.5886387\tbest: 0.5886387 (24)\ttotal: 237ms\tremaining: 10.5s\n",
      "25:\tlearn: 0.5392280\ttest: 0.5857358\tbest: 0.5857358 (25)\ttotal: 241ms\tremaining: 10.2s\n",
      "26:\tlearn: 0.5349279\ttest: 0.5828591\tbest: 0.5828591 (26)\ttotal: 245ms\tremaining: 9.97s\n",
      "27:\tlearn: 0.5300984\ttest: 0.5798369\tbest: 0.5798369 (27)\ttotal: 248ms\tremaining: 9.75s\n",
      "28:\tlearn: 0.5265379\ttest: 0.5771187\tbest: 0.5771187 (28)\ttotal: 252ms\tremaining: 9.57s\n",
      "29:\tlearn: 0.5224369\ttest: 0.5739832\tbest: 0.5739832 (29)\ttotal: 256ms\tremaining: 9.36s\n",
      "30:\tlearn: 0.5185985\ttest: 0.5712533\tbest: 0.5712533 (30)\ttotal: 259ms\tremaining: 9.17s\n",
      "31:\tlearn: 0.5144949\ttest: 0.5683455\tbest: 0.5683455 (31)\ttotal: 263ms\tremaining: 9.01s\n",
      "32:\tlearn: 0.5105740\ttest: 0.5656956\tbest: 0.5656956 (32)\ttotal: 267ms\tremaining: 8.86s\n",
      "33:\tlearn: 0.5067004\ttest: 0.5631559\tbest: 0.5631559 (33)\ttotal: 270ms\tremaining: 8.7s\n",
      "34:\tlearn: 0.5028389\ttest: 0.5610024\tbest: 0.5610024 (34)\ttotal: 274ms\tremaining: 8.54s\n",
      "35:\tlearn: 0.4988578\ttest: 0.5585308\tbest: 0.5585308 (35)\ttotal: 277ms\tremaining: 8.41s\n",
      "36:\tlearn: 0.4952532\ttest: 0.5566919\tbest: 0.5566919 (36)\ttotal: 281ms\tremaining: 8.29s\n",
      "37:\tlearn: 0.4912741\ttest: 0.5542564\tbest: 0.5542564 (37)\ttotal: 284ms\tremaining: 8.16s\n",
      "38:\tlearn: 0.4883473\ttest: 0.5523512\tbest: 0.5523512 (38)\ttotal: 288ms\tremaining: 8.03s\n",
      "39:\tlearn: 0.4847669\ttest: 0.5500853\tbest: 0.5500853 (39)\ttotal: 292ms\tremaining: 7.93s\n",
      "40:\tlearn: 0.4816078\ttest: 0.5479373\tbest: 0.5479373 (40)\ttotal: 295ms\tremaining: 7.83s\n",
      "41:\tlearn: 0.4787752\ttest: 0.5458902\tbest: 0.5458902 (41)\ttotal: 299ms\tremaining: 7.74s\n",
      "42:\tlearn: 0.4754653\ttest: 0.5440860\tbest: 0.5440860 (42)\ttotal: 303ms\tremaining: 7.63s\n",
      "43:\tlearn: 0.4720716\ttest: 0.5419792\tbest: 0.5419792 (43)\ttotal: 306ms\tremaining: 7.54s\n",
      "44:\tlearn: 0.4692959\ttest: 0.5408814\tbest: 0.5408814 (44)\ttotal: 310ms\tremaining: 7.45s\n",
      "45:\tlearn: 0.4661527\ttest: 0.5395426\tbest: 0.5395426 (45)\ttotal: 313ms\tremaining: 7.36s\n",
      "46:\tlearn: 0.4630320\ttest: 0.5374950\tbest: 0.5374950 (46)\ttotal: 316ms\tremaining: 7.28s\n",
      "47:\tlearn: 0.4598798\ttest: 0.5357505\tbest: 0.5357505 (47)\ttotal: 320ms\tremaining: 7.19s\n",
      "48:\tlearn: 0.4570256\ttest: 0.5342342\tbest: 0.5342342 (48)\ttotal: 323ms\tremaining: 7.11s\n",
      "49:\tlearn: 0.4545336\ttest: 0.5326791\tbest: 0.5326791 (49)\ttotal: 326ms\tremaining: 7.04s\n",
      "50:\tlearn: 0.4518394\ttest: 0.5307183\tbest: 0.5307183 (50)\ttotal: 331ms\tremaining: 6.98s\n",
      "51:\tlearn: 0.4494259\ttest: 0.5296246\tbest: 0.5296246 (51)\ttotal: 334ms\tremaining: 6.92s\n",
      "52:\tlearn: 0.4459697\ttest: 0.5277529\tbest: 0.5277529 (52)\ttotal: 338ms\tremaining: 6.85s\n",
      "53:\tlearn: 0.4431164\ttest: 0.5258440\tbest: 0.5258440 (53)\ttotal: 342ms\tremaining: 6.79s\n",
      "54:\tlearn: 0.4405960\ttest: 0.5244796\tbest: 0.5244796 (54)\ttotal: 345ms\tremaining: 6.74s\n",
      "55:\tlearn: 0.4376738\ttest: 0.5230885\tbest: 0.5230885 (55)\ttotal: 349ms\tremaining: 6.67s\n",
      "56:\tlearn: 0.4353421\ttest: 0.5214141\tbest: 0.5214141 (56)\ttotal: 352ms\tremaining: 6.61s\n",
      "57:\tlearn: 0.4329287\ttest: 0.5202150\tbest: 0.5202150 (57)\ttotal: 356ms\tremaining: 6.56s\n",
      "58:\tlearn: 0.4307594\ttest: 0.5190169\tbest: 0.5190169 (58)\ttotal: 360ms\tremaining: 6.53s\n",
      "59:\tlearn: 0.4286643\ttest: 0.5183731\tbest: 0.5183731 (59)\ttotal: 365ms\tremaining: 6.5s\n",
      "60:\tlearn: 0.4259093\ttest: 0.5170362\tbest: 0.5170362 (60)\ttotal: 369ms\tremaining: 6.45s\n",
      "61:\tlearn: 0.4232758\ttest: 0.5155793\tbest: 0.5155793 (61)\ttotal: 373ms\tremaining: 6.41s\n",
      "62:\tlearn: 0.4209644\ttest: 0.5140458\tbest: 0.5140458 (62)\ttotal: 376ms\tremaining: 6.36s\n",
      "63:\tlearn: 0.4186516\ttest: 0.5131813\tbest: 0.5131813 (63)\ttotal: 380ms\tremaining: 6.31s\n",
      "64:\tlearn: 0.4167549\ttest: 0.5121437\tbest: 0.5121437 (64)\ttotal: 383ms\tremaining: 6.26s\n",
      "65:\tlearn: 0.4144393\ttest: 0.5110626\tbest: 0.5110626 (65)\ttotal: 387ms\tremaining: 6.22s\n",
      "66:\tlearn: 0.4123201\ttest: 0.5100865\tbest: 0.5100865 (66)\ttotal: 391ms\tremaining: 6.18s\n",
      "67:\tlearn: 0.4100178\ttest: 0.5091364\tbest: 0.5091364 (67)\ttotal: 394ms\tremaining: 6.14s\n",
      "68:\tlearn: 0.4080369\ttest: 0.5081492\tbest: 0.5081492 (68)\ttotal: 397ms\tremaining: 6.1s\n",
      "69:\tlearn: 0.4060373\ttest: 0.5071076\tbest: 0.5071076 (69)\ttotal: 401ms\tremaining: 6.05s\n",
      "70:\tlearn: 0.4045790\ttest: 0.5063636\tbest: 0.5063636 (70)\ttotal: 404ms\tremaining: 6.01s\n",
      "71:\tlearn: 0.4023680\ttest: 0.5056668\tbest: 0.5056668 (71)\ttotal: 407ms\tremaining: 5.97s\n",
      "72:\tlearn: 0.4002675\ttest: 0.5045412\tbest: 0.5045412 (72)\ttotal: 410ms\tremaining: 5.93s\n",
      "73:\tlearn: 0.3989198\ttest: 0.5037316\tbest: 0.5037316 (73)\ttotal: 413ms\tremaining: 5.89s\n",
      "74:\tlearn: 0.3972050\ttest: 0.5030199\tbest: 0.5030199 (74)\ttotal: 417ms\tremaining: 5.85s\n",
      "75:\tlearn: 0.3955795\ttest: 0.5019946\tbest: 0.5019946 (75)\ttotal: 420ms\tremaining: 5.82s\n",
      "76:\tlearn: 0.3938573\ttest: 0.5007832\tbest: 0.5007832 (76)\ttotal: 424ms\tremaining: 5.78s\n",
      "77:\tlearn: 0.3916947\ttest: 0.5001069\tbest: 0.5001069 (77)\ttotal: 427ms\tremaining: 5.75s\n",
      "78:\tlearn: 0.3901331\ttest: 0.4993264\tbest: 0.4993264 (78)\ttotal: 430ms\tremaining: 5.71s\n",
      "79:\tlearn: 0.3882833\ttest: 0.4987139\tbest: 0.4987139 (79)\ttotal: 434ms\tremaining: 5.68s\n",
      "80:\tlearn: 0.3868213\ttest: 0.4981852\tbest: 0.4981852 (80)\ttotal: 438ms\tremaining: 5.66s\n",
      "81:\tlearn: 0.3850247\ttest: 0.4971376\tbest: 0.4971376 (81)\ttotal: 441ms\tremaining: 5.62s\n",
      "82:\tlearn: 0.3836887\ttest: 0.4965479\tbest: 0.4965479 (82)\ttotal: 444ms\tremaining: 5.59s\n",
      "83:\tlearn: 0.3819123\ttest: 0.4962140\tbest: 0.4962140 (83)\ttotal: 448ms\tremaining: 5.56s\n",
      "84:\tlearn: 0.3800137\ttest: 0.4951087\tbest: 0.4951087 (84)\ttotal: 451ms\tremaining: 5.54s\n",
      "85:\tlearn: 0.3781529\ttest: 0.4945372\tbest: 0.4945372 (85)\ttotal: 455ms\tremaining: 5.51s\n",
      "86:\tlearn: 0.3763303\ttest: 0.4938134\tbest: 0.4938134 (86)\ttotal: 458ms\tremaining: 5.48s\n",
      "87:\tlearn: 0.3747990\ttest: 0.4931541\tbest: 0.4931541 (87)\ttotal: 461ms\tremaining: 5.45s\n",
      "88:\tlearn: 0.3729538\ttest: 0.4928771\tbest: 0.4928771 (88)\ttotal: 465ms\tremaining: 5.43s\n",
      "89:\tlearn: 0.3714737\ttest: 0.4919181\tbest: 0.4919181 (89)\ttotal: 469ms\tremaining: 5.41s\n",
      "90:\tlearn: 0.3700656\ttest: 0.4913012\tbest: 0.4913012 (90)\ttotal: 473ms\tremaining: 5.38s\n",
      "91:\tlearn: 0.3686150\ttest: 0.4907814\tbest: 0.4907814 (91)\ttotal: 476ms\tremaining: 5.36s\n",
      "92:\tlearn: 0.3674945\ttest: 0.4902133\tbest: 0.4902133 (92)\ttotal: 479ms\tremaining: 5.33s\n",
      "93:\tlearn: 0.3661896\ttest: 0.4899770\tbest: 0.4899770 (93)\ttotal: 483ms\tremaining: 5.31s\n",
      "94:\tlearn: 0.3648354\ttest: 0.4895929\tbest: 0.4895929 (94)\ttotal: 486ms\tremaining: 5.28s\n",
      "95:\tlearn: 0.3630520\ttest: 0.4892021\tbest: 0.4892021 (95)\ttotal: 489ms\tremaining: 5.26s\n",
      "96:\tlearn: 0.3618169\ttest: 0.4888131\tbest: 0.4888131 (96)\ttotal: 492ms\tremaining: 5.23s\n",
      "97:\tlearn: 0.3603357\ttest: 0.4883263\tbest: 0.4883263 (97)\ttotal: 496ms\tremaining: 5.21s\n",
      "98:\tlearn: 0.3588362\ttest: 0.4872900\tbest: 0.4872900 (98)\ttotal: 499ms\tremaining: 5.19s\n",
      "99:\tlearn: 0.3574712\ttest: 0.4864306\tbest: 0.4864306 (99)\ttotal: 502ms\tremaining: 5.16s\n",
      "100:\tlearn: 0.3557915\ttest: 0.4859324\tbest: 0.4859324 (100)\ttotal: 506ms\tremaining: 5.14s\n",
      "101:\tlearn: 0.3542404\ttest: 0.4852310\tbest: 0.4852310 (101)\ttotal: 509ms\tremaining: 5.12s\n",
      "102:\tlearn: 0.3527931\ttest: 0.4843377\tbest: 0.4843377 (102)\ttotal: 513ms\tremaining: 5.1s\n",
      "103:\tlearn: 0.3510292\ttest: 0.4840481\tbest: 0.4840481 (103)\ttotal: 517ms\tremaining: 5.09s\n",
      "104:\tlearn: 0.3498446\ttest: 0.4831936\tbest: 0.4831936 (104)\ttotal: 520ms\tremaining: 5.07s\n",
      "105:\tlearn: 0.3484889\ttest: 0.4825080\tbest: 0.4825080 (105)\ttotal: 524ms\tremaining: 5.05s\n",
      "106:\tlearn: 0.3472880\ttest: 0.4823870\tbest: 0.4823870 (106)\ttotal: 528ms\tremaining: 5.04s\n",
      "107:\tlearn: 0.3461060\ttest: 0.4820597\tbest: 0.4820597 (107)\ttotal: 532ms\tremaining: 5.03s\n",
      "108:\tlearn: 0.3443138\ttest: 0.4814466\tbest: 0.4814466 (108)\ttotal: 536ms\tremaining: 5.01s\n",
      "109:\tlearn: 0.3434129\ttest: 0.4812288\tbest: 0.4812288 (109)\ttotal: 540ms\tremaining: 5s\n",
      "110:\tlearn: 0.3422759\ttest: 0.4806871\tbest: 0.4806871 (110)\ttotal: 544ms\tremaining: 4.98s\n",
      "111:\tlearn: 0.3407804\ttest: 0.4802919\tbest: 0.4802919 (111)\ttotal: 548ms\tremaining: 4.97s\n",
      "112:\tlearn: 0.3397797\ttest: 0.4798925\tbest: 0.4798925 (112)\ttotal: 551ms\tremaining: 4.95s\n",
      "113:\tlearn: 0.3388067\ttest: 0.4796176\tbest: 0.4796176 (113)\ttotal: 555ms\tremaining: 4.94s\n",
      "114:\tlearn: 0.3375947\ttest: 0.4789042\tbest: 0.4789042 (114)\ttotal: 559ms\tremaining: 4.92s\n",
      "115:\tlearn: 0.3360898\ttest: 0.4787846\tbest: 0.4787846 (115)\ttotal: 563ms\tremaining: 4.91s\n",
      "116:\tlearn: 0.3347231\ttest: 0.4786912\tbest: 0.4786912 (116)\ttotal: 567ms\tremaining: 4.9s\n",
      "117:\tlearn: 0.3334383\ttest: 0.4784674\tbest: 0.4784674 (117)\ttotal: 570ms\tremaining: 4.88s\n",
      "118:\tlearn: 0.3325824\ttest: 0.4782033\tbest: 0.4782033 (118)\ttotal: 574ms\tremaining: 4.86s\n",
      "119:\tlearn: 0.3315766\ttest: 0.4777868\tbest: 0.4777868 (119)\ttotal: 578ms\tremaining: 4.85s\n",
      "120:\tlearn: 0.3305990\ttest: 0.4775491\tbest: 0.4775491 (120)\ttotal: 581ms\tremaining: 4.84s\n",
      "121:\tlearn: 0.3290762\ttest: 0.4771335\tbest: 0.4771335 (121)\ttotal: 585ms\tremaining: 4.82s\n",
      "122:\tlearn: 0.3279397\ttest: 0.4767423\tbest: 0.4767423 (122)\ttotal: 588ms\tremaining: 4.8s\n",
      "123:\tlearn: 0.3269079\ttest: 0.4761781\tbest: 0.4761781 (123)\ttotal: 591ms\tremaining: 4.79s\n",
      "124:\tlearn: 0.3259664\ttest: 0.4759273\tbest: 0.4759273 (124)\ttotal: 595ms\tremaining: 4.78s\n",
      "125:\tlearn: 0.3248649\ttest: 0.4752561\tbest: 0.4752561 (125)\ttotal: 600ms\tremaining: 4.77s\n",
      "126:\tlearn: 0.3240112\ttest: 0.4750072\tbest: 0.4750072 (126)\ttotal: 603ms\tremaining: 4.75s\n",
      "127:\tlearn: 0.3229384\ttest: 0.4750157\tbest: 0.4750072 (126)\ttotal: 607ms\tremaining: 4.74s\n",
      "128:\tlearn: 0.3222082\ttest: 0.4744783\tbest: 0.4744783 (128)\ttotal: 611ms\tremaining: 4.73s\n",
      "129:\tlearn: 0.3214088\ttest: 0.4743409\tbest: 0.4743409 (129)\ttotal: 614ms\tremaining: 4.71s\n",
      "130:\tlearn: 0.3206980\ttest: 0.4741428\tbest: 0.4741428 (130)\ttotal: 618ms\tremaining: 4.7s\n",
      "131:\tlearn: 0.3196889\ttest: 0.4737127\tbest: 0.4737127 (131)\ttotal: 621ms\tremaining: 4.68s\n",
      "132:\tlearn: 0.3190489\ttest: 0.4732479\tbest: 0.4732479 (132)\ttotal: 624ms\tremaining: 4.67s\n",
      "133:\tlearn: 0.3181579\ttest: 0.4732447\tbest: 0.4732447 (133)\ttotal: 628ms\tremaining: 4.66s\n",
      "134:\tlearn: 0.3172090\ttest: 0.4730859\tbest: 0.4730859 (134)\ttotal: 631ms\tremaining: 4.64s\n",
      "135:\tlearn: 0.3158421\ttest: 0.4725898\tbest: 0.4725898 (135)\ttotal: 634ms\tremaining: 4.62s\n",
      "136:\tlearn: 0.3152823\ttest: 0.4723510\tbest: 0.4723510 (136)\ttotal: 638ms\tremaining: 4.61s\n",
      "137:\tlearn: 0.3143625\ttest: 0.4723776\tbest: 0.4723510 (136)\ttotal: 641ms\tremaining: 4.6s\n",
      "138:\tlearn: 0.3134859\ttest: 0.4723759\tbest: 0.4723510 (136)\ttotal: 644ms\tremaining: 4.58s\n",
      "139:\tlearn: 0.3127680\ttest: 0.4721996\tbest: 0.4721996 (139)\ttotal: 648ms\tremaining: 4.57s\n",
      "140:\tlearn: 0.3119791\ttest: 0.4721149\tbest: 0.4721149 (140)\ttotal: 651ms\tremaining: 4.55s\n",
      "141:\tlearn: 0.3111796\ttest: 0.4717714\tbest: 0.4717714 (141)\ttotal: 654ms\tremaining: 4.54s\n",
      "142:\tlearn: 0.3101530\ttest: 0.4711910\tbest: 0.4711910 (142)\ttotal: 658ms\tremaining: 4.53s\n",
      "143:\tlearn: 0.3092341\ttest: 0.4711388\tbest: 0.4711388 (143)\ttotal: 661ms\tremaining: 4.52s\n",
      "144:\tlearn: 0.3081814\ttest: 0.4713244\tbest: 0.4711388 (143)\ttotal: 664ms\tremaining: 4.5s\n",
      "145:\tlearn: 0.3072837\ttest: 0.4710316\tbest: 0.4710316 (145)\ttotal: 667ms\tremaining: 4.49s\n",
      "146:\tlearn: 0.3066879\ttest: 0.4709856\tbest: 0.4709856 (146)\ttotal: 671ms\tremaining: 4.48s\n",
      "147:\tlearn: 0.3059765\ttest: 0.4708659\tbest: 0.4708659 (147)\ttotal: 674ms\tremaining: 4.47s\n",
      "148:\tlearn: 0.3052774\ttest: 0.4706228\tbest: 0.4706228 (148)\ttotal: 678ms\tremaining: 4.45s\n",
      "149:\tlearn: 0.3043182\ttest: 0.4705596\tbest: 0.4705596 (149)\ttotal: 681ms\tremaining: 4.44s\n",
      "150:\tlearn: 0.3034430\ttest: 0.4700994\tbest: 0.4700994 (150)\ttotal: 684ms\tremaining: 4.43s\n",
      "151:\tlearn: 0.3025760\ttest: 0.4704399\tbest: 0.4700994 (150)\ttotal: 688ms\tremaining: 4.42s\n",
      "152:\tlearn: 0.3018307\ttest: 0.4704330\tbest: 0.4700994 (150)\ttotal: 691ms\tremaining: 4.41s\n",
      "153:\tlearn: 0.3010392\ttest: 0.4698859\tbest: 0.4698859 (153)\ttotal: 695ms\tremaining: 4.39s\n",
      "154:\tlearn: 0.3002485\ttest: 0.4699651\tbest: 0.4698859 (153)\ttotal: 698ms\tremaining: 4.38s\n",
      "155:\tlearn: 0.2994691\ttest: 0.4697999\tbest: 0.4697999 (155)\ttotal: 701ms\tremaining: 4.37s\n",
      "156:\tlearn: 0.2987733\ttest: 0.4694764\tbest: 0.4694764 (156)\ttotal: 705ms\tremaining: 4.36s\n",
      "157:\tlearn: 0.2981355\ttest: 0.4691579\tbest: 0.4691579 (157)\ttotal: 708ms\tremaining: 4.35s\n",
      "158:\tlearn: 0.2976124\ttest: 0.4692148\tbest: 0.4691579 (157)\ttotal: 712ms\tremaining: 4.34s\n",
      "159:\tlearn: 0.2968208\ttest: 0.4693517\tbest: 0.4691579 (157)\ttotal: 715ms\tremaining: 4.33s\n",
      "160:\tlearn: 0.2959918\ttest: 0.4693475\tbest: 0.4691579 (157)\ttotal: 718ms\tremaining: 4.31s\n",
      "161:\tlearn: 0.2949670\ttest: 0.4690162\tbest: 0.4690162 (161)\ttotal: 722ms\tremaining: 4.3s\n",
      "162:\tlearn: 0.2941505\ttest: 0.4690339\tbest: 0.4690162 (161)\ttotal: 725ms\tremaining: 4.29s\n",
      "163:\tlearn: 0.2934863\ttest: 0.4690124\tbest: 0.4690124 (163)\ttotal: 728ms\tremaining: 4.28s\n",
      "164:\tlearn: 0.2927692\ttest: 0.4686034\tbest: 0.4686034 (164)\ttotal: 731ms\tremaining: 4.27s\n",
      "165:\tlearn: 0.2918210\ttest: 0.4686139\tbest: 0.4686034 (164)\ttotal: 735ms\tremaining: 4.26s\n",
      "166:\tlearn: 0.2913085\ttest: 0.4683921\tbest: 0.4683921 (166)\ttotal: 739ms\tremaining: 4.25s\n",
      "167:\tlearn: 0.2904362\ttest: 0.4687950\tbest: 0.4683921 (166)\ttotal: 742ms\tremaining: 4.24s\n",
      "168:\tlearn: 0.2897568\ttest: 0.4686248\tbest: 0.4683921 (166)\ttotal: 745ms\tremaining: 4.23s\n",
      "169:\tlearn: 0.2890420\ttest: 0.4685785\tbest: 0.4683921 (166)\ttotal: 748ms\tremaining: 4.22s\n",
      "170:\tlearn: 0.2884491\ttest: 0.4682932\tbest: 0.4682932 (170)\ttotal: 752ms\tremaining: 4.21s\n",
      "171:\tlearn: 0.2877507\ttest: 0.4682055\tbest: 0.4682055 (171)\ttotal: 756ms\tremaining: 4.2s\n",
      "172:\tlearn: 0.2867837\ttest: 0.4680796\tbest: 0.4680796 (172)\ttotal: 760ms\tremaining: 4.19s\n",
      "173:\tlearn: 0.2863080\ttest: 0.4678751\tbest: 0.4678751 (173)\ttotal: 763ms\tremaining: 4.18s\n",
      "174:\tlearn: 0.2855820\ttest: 0.4676512\tbest: 0.4676512 (174)\ttotal: 767ms\tremaining: 4.17s\n",
      "175:\tlearn: 0.2850084\ttest: 0.4675704\tbest: 0.4675704 (175)\ttotal: 770ms\tremaining: 4.17s\n",
      "176:\tlearn: 0.2843101\ttest: 0.4674288\tbest: 0.4674288 (176)\ttotal: 774ms\tremaining: 4.16s\n",
      "177:\tlearn: 0.2836769\ttest: 0.4675421\tbest: 0.4674288 (176)\ttotal: 777ms\tremaining: 4.14s\n",
      "178:\tlearn: 0.2832182\ttest: 0.4673034\tbest: 0.4673034 (178)\ttotal: 780ms\tremaining: 4.13s\n",
      "179:\tlearn: 0.2825382\ttest: 0.4670841\tbest: 0.4670841 (179)\ttotal: 784ms\tremaining: 4.13s\n",
      "180:\tlearn: 0.2816354\ttest: 0.4673385\tbest: 0.4670841 (179)\ttotal: 787ms\tremaining: 4.12s\n",
      "181:\tlearn: 0.2811188\ttest: 0.4672154\tbest: 0.4670841 (179)\ttotal: 791ms\tremaining: 4.11s\n",
      "182:\tlearn: 0.2805954\ttest: 0.4670662\tbest: 0.4670662 (182)\ttotal: 794ms\tremaining: 4.1s\n",
      "183:\tlearn: 0.2797991\ttest: 0.4669344\tbest: 0.4669344 (183)\ttotal: 797ms\tremaining: 4.09s\n",
      "184:\tlearn: 0.2791498\ttest: 0.4668123\tbest: 0.4668123 (184)\ttotal: 801ms\tremaining: 4.08s\n",
      "185:\tlearn: 0.2785768\ttest: 0.4666556\tbest: 0.4666556 (185)\ttotal: 804ms\tremaining: 4.07s\n",
      "186:\tlearn: 0.2779341\ttest: 0.4665939\tbest: 0.4665939 (186)\ttotal: 807ms\tremaining: 4.06s\n",
      "187:\tlearn: 0.2772927\ttest: 0.4669125\tbest: 0.4665939 (186)\ttotal: 811ms\tremaining: 4.05s\n",
      "188:\tlearn: 0.2766939\ttest: 0.4670477\tbest: 0.4665939 (186)\ttotal: 814ms\tremaining: 4.05s\n",
      "189:\tlearn: 0.2758714\ttest: 0.4671981\tbest: 0.4665939 (186)\ttotal: 818ms\tremaining: 4.04s\n",
      "190:\tlearn: 0.2752913\ttest: 0.4669277\tbest: 0.4665939 (186)\ttotal: 822ms\tremaining: 4.03s\n",
      "191:\tlearn: 0.2746115\ttest: 0.4668455\tbest: 0.4665939 (186)\ttotal: 825ms\tremaining: 4.02s\n",
      "192:\tlearn: 0.2740417\ttest: 0.4669002\tbest: 0.4665939 (186)\ttotal: 829ms\tremaining: 4.01s\n",
      "193:\tlearn: 0.2735795\ttest: 0.4666095\tbest: 0.4665939 (186)\ttotal: 832ms\tremaining: 4.01s\n",
      "194:\tlearn: 0.2729763\ttest: 0.4666170\tbest: 0.4665939 (186)\ttotal: 836ms\tremaining: 4s\n",
      "195:\tlearn: 0.2725494\ttest: 0.4664526\tbest: 0.4664526 (195)\ttotal: 840ms\tremaining: 3.99s\n",
      "196:\tlearn: 0.2717367\ttest: 0.4662899\tbest: 0.4662899 (196)\ttotal: 843ms\tremaining: 3.98s\n",
      "197:\tlearn: 0.2710215\ttest: 0.4663315\tbest: 0.4662899 (196)\ttotal: 847ms\tremaining: 3.98s\n",
      "198:\tlearn: 0.2705490\ttest: 0.4662950\tbest: 0.4662899 (196)\ttotal: 850ms\tremaining: 3.97s\n",
      "199:\tlearn: 0.2700284\ttest: 0.4660540\tbest: 0.4660540 (199)\ttotal: 854ms\tremaining: 3.96s\n",
      "200:\tlearn: 0.2690796\ttest: 0.4659906\tbest: 0.4659906 (200)\ttotal: 857ms\tremaining: 3.95s\n",
      "201:\tlearn: 0.2687023\ttest: 0.4657673\tbest: 0.4657673 (201)\ttotal: 861ms\tremaining: 3.95s\n",
      "202:\tlearn: 0.2680798\ttest: 0.4655842\tbest: 0.4655842 (202)\ttotal: 865ms\tremaining: 3.94s\n",
      "203:\tlearn: 0.2673845\ttest: 0.4658041\tbest: 0.4655842 (202)\ttotal: 868ms\tremaining: 3.93s\n",
      "204:\tlearn: 0.2669443\ttest: 0.4657802\tbest: 0.4655842 (202)\ttotal: 871ms\tremaining: 3.92s\n",
      "205:\tlearn: 0.2665746\ttest: 0.4659619\tbest: 0.4655842 (202)\ttotal: 875ms\tremaining: 3.91s\n",
      "206:\tlearn: 0.2659166\ttest: 0.4659679\tbest: 0.4655842 (202)\ttotal: 878ms\tremaining: 3.91s\n",
      "207:\tlearn: 0.2652919\ttest: 0.4659319\tbest: 0.4655842 (202)\ttotal: 882ms\tremaining: 3.9s\n",
      "208:\tlearn: 0.2647290\ttest: 0.4657764\tbest: 0.4655842 (202)\ttotal: 886ms\tremaining: 3.89s\n",
      "209:\tlearn: 0.2643552\ttest: 0.4657408\tbest: 0.4655842 (202)\ttotal: 889ms\tremaining: 3.89s\n",
      "210:\tlearn: 0.2638626\ttest: 0.4657661\tbest: 0.4655842 (202)\ttotal: 893ms\tremaining: 3.88s\n",
      "211:\tlearn: 0.2633290\ttest: 0.4657383\tbest: 0.4655842 (202)\ttotal: 896ms\tremaining: 3.87s\n",
      "212:\tlearn: 0.2628039\ttest: 0.4653050\tbest: 0.4653050 (212)\ttotal: 900ms\tremaining: 3.87s\n",
      "213:\tlearn: 0.2622203\ttest: 0.4655387\tbest: 0.4653050 (212)\ttotal: 904ms\tremaining: 3.86s\n",
      "214:\tlearn: 0.2618470\ttest: 0.4654202\tbest: 0.4653050 (212)\ttotal: 907ms\tremaining: 3.85s\n",
      "215:\tlearn: 0.2611571\ttest: 0.4650851\tbest: 0.4650851 (215)\ttotal: 910ms\tremaining: 3.84s\n",
      "216:\tlearn: 0.2607057\ttest: 0.4649993\tbest: 0.4649993 (216)\ttotal: 914ms\tremaining: 3.84s\n",
      "217:\tlearn: 0.2602959\ttest: 0.4649342\tbest: 0.4649342 (217)\ttotal: 917ms\tremaining: 3.83s\n",
      "218:\tlearn: 0.2598448\ttest: 0.4652059\tbest: 0.4649342 (217)\ttotal: 920ms\tremaining: 3.82s\n",
      "219:\tlearn: 0.2593482\ttest: 0.4652859\tbest: 0.4649342 (217)\ttotal: 924ms\tremaining: 3.81s\n",
      "220:\tlearn: 0.2587087\ttest: 0.4649490\tbest: 0.4649342 (217)\ttotal: 927ms\tremaining: 3.81s\n",
      "221:\tlearn: 0.2581667\ttest: 0.4648663\tbest: 0.4648663 (221)\ttotal: 931ms\tremaining: 3.8s\n",
      "222:\tlearn: 0.2576327\ttest: 0.4647252\tbest: 0.4647252 (222)\ttotal: 935ms\tremaining: 3.79s\n",
      "223:\tlearn: 0.2572747\ttest: 0.4646224\tbest: 0.4646224 (223)\ttotal: 938ms\tremaining: 3.78s\n",
      "224:\tlearn: 0.2565175\ttest: 0.4648786\tbest: 0.4646224 (223)\ttotal: 941ms\tremaining: 3.78s\n",
      "225:\tlearn: 0.2559722\ttest: 0.4648414\tbest: 0.4646224 (223)\ttotal: 945ms\tremaining: 3.77s\n",
      "226:\tlearn: 0.2554611\ttest: 0.4648854\tbest: 0.4646224 (223)\ttotal: 948ms\tremaining: 3.76s\n",
      "227:\tlearn: 0.2547853\ttest: 0.4648044\tbest: 0.4646224 (223)\ttotal: 952ms\tremaining: 3.76s\n",
      "228:\tlearn: 0.2542697\ttest: 0.4645935\tbest: 0.4645935 (228)\ttotal: 955ms\tremaining: 3.75s\n",
      "229:\tlearn: 0.2537838\ttest: 0.4647375\tbest: 0.4645935 (228)\ttotal: 959ms\tremaining: 3.74s\n",
      "230:\tlearn: 0.2531148\ttest: 0.4647727\tbest: 0.4645935 (228)\ttotal: 962ms\tremaining: 3.73s\n",
      "231:\tlearn: 0.2525687\ttest: 0.4642652\tbest: 0.4642652 (231)\ttotal: 965ms\tremaining: 3.73s\n",
      "232:\tlearn: 0.2520770\ttest: 0.4641491\tbest: 0.4641491 (232)\ttotal: 969ms\tremaining: 3.72s\n",
      "233:\tlearn: 0.2516100\ttest: 0.4640902\tbest: 0.4640902 (233)\ttotal: 973ms\tremaining: 3.72s\n",
      "234:\tlearn: 0.2509449\ttest: 0.4640595\tbest: 0.4640595 (234)\ttotal: 976ms\tremaining: 3.71s\n",
      "235:\tlearn: 0.2505120\ttest: 0.4639786\tbest: 0.4639786 (235)\ttotal: 980ms\tremaining: 3.7s\n",
      "236:\tlearn: 0.2499174\ttest: 0.4637402\tbest: 0.4637402 (236)\ttotal: 983ms\tremaining: 3.7s\n",
      "237:\tlearn: 0.2495221\ttest: 0.4638913\tbest: 0.4637402 (236)\ttotal: 987ms\tremaining: 3.69s\n",
      "238:\tlearn: 0.2490068\ttest: 0.4639693\tbest: 0.4637402 (236)\ttotal: 991ms\tremaining: 3.69s\n",
      "239:\tlearn: 0.2485031\ttest: 0.4643057\tbest: 0.4637402 (236)\ttotal: 994ms\tremaining: 3.68s\n",
      "240:\tlearn: 0.2479748\ttest: 0.4643728\tbest: 0.4637402 (236)\ttotal: 998ms\tremaining: 3.67s\n",
      "241:\tlearn: 0.2475073\ttest: 0.4645941\tbest: 0.4637402 (236)\ttotal: 1s\tremaining: 3.67s\n",
      "242:\tlearn: 0.2469275\ttest: 0.4649608\tbest: 0.4637402 (236)\ttotal: 1s\tremaining: 3.66s\n",
      "243:\tlearn: 0.2462771\ttest: 0.4652439\tbest: 0.4637402 (236)\ttotal: 1.01s\tremaining: 3.66s\n",
      "244:\tlearn: 0.2454916\ttest: 0.4655398\tbest: 0.4637402 (236)\ttotal: 1.01s\tremaining: 3.65s\n",
      "245:\tlearn: 0.2450552\ttest: 0.4653549\tbest: 0.4637402 (236)\ttotal: 1.02s\tremaining: 3.64s\n",
      "246:\tlearn: 0.2446592\ttest: 0.4654481\tbest: 0.4637402 (236)\ttotal: 1.02s\tremaining: 3.64s\n",
      "247:\tlearn: 0.2442039\ttest: 0.4654907\tbest: 0.4637402 (236)\ttotal: 1.02s\tremaining: 3.63s\n",
      "248:\tlearn: 0.2437159\ttest: 0.4655992\tbest: 0.4637402 (236)\ttotal: 1.03s\tremaining: 3.63s\n",
      "249:\tlearn: 0.2432634\ttest: 0.4655418\tbest: 0.4637402 (236)\ttotal: 1.03s\tremaining: 3.62s\n",
      "250:\tlearn: 0.2429331\ttest: 0.4654160\tbest: 0.4637402 (236)\ttotal: 1.03s\tremaining: 3.62s\n",
      "251:\tlearn: 0.2425530\ttest: 0.4652851\tbest: 0.4637402 (236)\ttotal: 1.04s\tremaining: 3.61s\n",
      "252:\tlearn: 0.2421587\ttest: 0.4653093\tbest: 0.4637402 (236)\ttotal: 1.04s\tremaining: 3.61s\n",
      "253:\tlearn: 0.2415567\ttest: 0.4655332\tbest: 0.4637402 (236)\ttotal: 1.05s\tremaining: 3.6s\n",
      "254:\tlearn: 0.2412711\ttest: 0.4655408\tbest: 0.4637402 (236)\ttotal: 1.05s\tremaining: 3.6s\n",
      "255:\tlearn: 0.2408849\ttest: 0.4656701\tbest: 0.4637402 (236)\ttotal: 1.05s\tremaining: 3.59s\n",
      "256:\tlearn: 0.2404123\ttest: 0.4655073\tbest: 0.4637402 (236)\ttotal: 1.06s\tremaining: 3.58s\n",
      "257:\tlearn: 0.2400339\ttest: 0.4653959\tbest: 0.4637402 (236)\ttotal: 1.06s\tremaining: 3.57s\n",
      "258:\tlearn: 0.2396144\ttest: 0.4653145\tbest: 0.4637402 (236)\ttotal: 1.06s\tremaining: 3.57s\n",
      "259:\tlearn: 0.2390896\ttest: 0.4654171\tbest: 0.4637402 (236)\ttotal: 1.07s\tremaining: 3.56s\n",
      "260:\tlearn: 0.2387124\ttest: 0.4650945\tbest: 0.4637402 (236)\ttotal: 1.07s\tremaining: 3.56s\n",
      "261:\tlearn: 0.2384486\ttest: 0.4651437\tbest: 0.4637402 (236)\ttotal: 1.07s\tremaining: 3.55s\n",
      "262:\tlearn: 0.2378683\ttest: 0.4652723\tbest: 0.4637402 (236)\ttotal: 1.08s\tremaining: 3.54s\n",
      "263:\tlearn: 0.2374187\ttest: 0.4653803\tbest: 0.4637402 (236)\ttotal: 1.08s\tremaining: 3.54s\n",
      "264:\tlearn: 0.2368800\ttest: 0.4652473\tbest: 0.4637402 (236)\ttotal: 1.08s\tremaining: 3.54s\n",
      "265:\tlearn: 0.2362573\ttest: 0.4653750\tbest: 0.4637402 (236)\ttotal: 1.09s\tremaining: 3.53s\n",
      "266:\tlearn: 0.2356251\ttest: 0.4651591\tbest: 0.4637402 (236)\ttotal: 1.09s\tremaining: 3.52s\n",
      "267:\tlearn: 0.2352190\ttest: 0.4654144\tbest: 0.4637402 (236)\ttotal: 1.09s\tremaining: 3.52s\n",
      "268:\tlearn: 0.2347133\ttest: 0.4655646\tbest: 0.4637402 (236)\ttotal: 1.1s\tremaining: 3.51s\n",
      "269:\tlearn: 0.2341259\ttest: 0.4658402\tbest: 0.4637402 (236)\ttotal: 1.1s\tremaining: 3.5s\n",
      "270:\tlearn: 0.2337179\ttest: 0.4657786\tbest: 0.4637402 (236)\ttotal: 1.1s\tremaining: 3.5s\n",
      "271:\tlearn: 0.2333221\ttest: 0.4654677\tbest: 0.4637402 (236)\ttotal: 1.11s\tremaining: 3.49s\n",
      "272:\tlearn: 0.2329128\ttest: 0.4656602\tbest: 0.4637402 (236)\ttotal: 1.11s\tremaining: 3.48s\n",
      "273:\tlearn: 0.2324409\ttest: 0.4656033\tbest: 0.4637402 (236)\ttotal: 1.11s\tremaining: 3.48s\n",
      "274:\tlearn: 0.2317305\ttest: 0.4659095\tbest: 0.4637402 (236)\ttotal: 1.12s\tremaining: 3.47s\n",
      "275:\tlearn: 0.2310756\ttest: 0.4662757\tbest: 0.4637402 (236)\ttotal: 1.12s\tremaining: 3.47s\n",
      "276:\tlearn: 0.2304758\ttest: 0.4663435\tbest: 0.4637402 (236)\ttotal: 1.13s\tremaining: 3.46s\n",
      "277:\tlearn: 0.2299189\ttest: 0.4663266\tbest: 0.4637402 (236)\ttotal: 1.13s\tremaining: 3.46s\n",
      "278:\tlearn: 0.2293250\ttest: 0.4660100\tbest: 0.4637402 (236)\ttotal: 1.13s\tremaining: 3.45s\n",
      "279:\tlearn: 0.2287750\ttest: 0.4660580\tbest: 0.4637402 (236)\ttotal: 1.14s\tremaining: 3.45s\n",
      "280:\tlearn: 0.2282303\ttest: 0.4662443\tbest: 0.4637402 (236)\ttotal: 1.14s\tremaining: 3.44s\n",
      "281:\tlearn: 0.2277826\ttest: 0.4661529\tbest: 0.4637402 (236)\ttotal: 1.15s\tremaining: 3.44s\n",
      "282:\tlearn: 0.2272298\ttest: 0.4660028\tbest: 0.4637402 (236)\ttotal: 1.15s\tremaining: 3.44s\n",
      "283:\tlearn: 0.2268729\ttest: 0.4662050\tbest: 0.4637402 (236)\ttotal: 1.16s\tremaining: 3.45s\n",
      "284:\tlearn: 0.2265377\ttest: 0.4660863\tbest: 0.4637402 (236)\ttotal: 1.17s\tremaining: 3.45s\n",
      "285:\tlearn: 0.2261069\ttest: 0.4660313\tbest: 0.4637402 (236)\ttotal: 1.17s\tremaining: 3.45s\n",
      "286:\tlearn: 0.2257992\ttest: 0.4658235\tbest: 0.4637402 (236)\ttotal: 1.18s\tremaining: 3.46s\n",
      "287:\tlearn: 0.2252757\ttest: 0.4658220\tbest: 0.4637402 (236)\ttotal: 1.19s\tremaining: 3.46s\n",
      "288:\tlearn: 0.2246969\ttest: 0.4657429\tbest: 0.4637402 (236)\ttotal: 1.19s\tremaining: 3.45s\n",
      "289:\tlearn: 0.2242682\ttest: 0.4657669\tbest: 0.4637402 (236)\ttotal: 1.19s\tremaining: 3.44s\n",
      "290:\tlearn: 0.2239541\ttest: 0.4658075\tbest: 0.4637402 (236)\ttotal: 1.2s\tremaining: 3.45s\n",
      "291:\tlearn: 0.2235125\ttest: 0.4659521\tbest: 0.4637402 (236)\ttotal: 1.2s\tremaining: 3.45s\n",
      "292:\tlearn: 0.2230722\ttest: 0.4656719\tbest: 0.4637402 (236)\ttotal: 1.21s\tremaining: 3.44s\n",
      "293:\tlearn: 0.2226217\ttest: 0.4656759\tbest: 0.4637402 (236)\ttotal: 1.21s\tremaining: 3.44s\n",
      "294:\tlearn: 0.2220605\ttest: 0.4658725\tbest: 0.4637402 (236)\ttotal: 1.21s\tremaining: 3.43s\n",
      "295:\tlearn: 0.2216067\ttest: 0.4657921\tbest: 0.4637402 (236)\ttotal: 1.22s\tremaining: 3.42s\n",
      "296:\tlearn: 0.2211467\ttest: 0.4660349\tbest: 0.4637402 (236)\ttotal: 1.22s\tremaining: 3.42s\n",
      "297:\tlearn: 0.2208119\ttest: 0.4658726\tbest: 0.4637402 (236)\ttotal: 1.23s\tremaining: 3.41s\n",
      "298:\tlearn: 0.2204666\ttest: 0.4658364\tbest: 0.4637402 (236)\ttotal: 1.23s\tremaining: 3.41s\n",
      "299:\tlearn: 0.2199051\ttest: 0.4657961\tbest: 0.4637402 (236)\ttotal: 1.23s\tremaining: 3.4s\n",
      "300:\tlearn: 0.2195315\ttest: 0.4655638\tbest: 0.4637402 (236)\ttotal: 1.24s\tremaining: 3.4s\n",
      "301:\tlearn: 0.2189030\ttest: 0.4653676\tbest: 0.4637402 (236)\ttotal: 1.24s\tremaining: 3.39s\n",
      "302:\tlearn: 0.2184204\ttest: 0.4655291\tbest: 0.4637402 (236)\ttotal: 1.24s\tremaining: 3.38s\n",
      "303:\tlearn: 0.2179740\ttest: 0.4652661\tbest: 0.4637402 (236)\ttotal: 1.25s\tremaining: 3.38s\n",
      "304:\tlearn: 0.2177113\ttest: 0.4652580\tbest: 0.4637402 (236)\ttotal: 1.25s\tremaining: 3.37s\n",
      "305:\tlearn: 0.2171800\ttest: 0.4655112\tbest: 0.4637402 (236)\ttotal: 1.25s\tremaining: 3.36s\n",
      "306:\tlearn: 0.2168312\ttest: 0.4656429\tbest: 0.4637402 (236)\ttotal: 1.25s\tremaining: 3.36s\n",
      "307:\tlearn: 0.2164509\ttest: 0.4656976\tbest: 0.4637402 (236)\ttotal: 1.26s\tremaining: 3.35s\n",
      "308:\tlearn: 0.2160915\ttest: 0.4657286\tbest: 0.4637402 (236)\ttotal: 1.26s\tremaining: 3.35s\n",
      "309:\tlearn: 0.2155626\ttest: 0.4659504\tbest: 0.4637402 (236)\ttotal: 1.26s\tremaining: 3.34s\n",
      "310:\tlearn: 0.2152082\ttest: 0.4660697\tbest: 0.4637402 (236)\ttotal: 1.27s\tremaining: 3.33s\n",
      "311:\tlearn: 0.2146920\ttest: 0.4658798\tbest: 0.4637402 (236)\ttotal: 1.27s\tremaining: 3.33s\n",
      "312:\tlearn: 0.2141059\ttest: 0.4660729\tbest: 0.4637402 (236)\ttotal: 1.27s\tremaining: 3.32s\n",
      "313:\tlearn: 0.2138821\ttest: 0.4659925\tbest: 0.4637402 (236)\ttotal: 1.28s\tremaining: 3.31s\n",
      "314:\tlearn: 0.2135522\ttest: 0.4661614\tbest: 0.4637402 (236)\ttotal: 1.28s\tremaining: 3.31s\n",
      "315:\tlearn: 0.2132168\ttest: 0.4660430\tbest: 0.4637402 (236)\ttotal: 1.28s\tremaining: 3.3s\n",
      "316:\tlearn: 0.2129055\ttest: 0.4661008\tbest: 0.4637402 (236)\ttotal: 1.29s\tremaining: 3.3s\n",
      "317:\tlearn: 0.2123921\ttest: 0.4664748\tbest: 0.4637402 (236)\ttotal: 1.29s\tremaining: 3.29s\n",
      "318:\tlearn: 0.2120061\ttest: 0.4664678\tbest: 0.4637402 (236)\ttotal: 1.29s\tremaining: 3.29s\n",
      "319:\tlearn: 0.2116468\ttest: 0.4668012\tbest: 0.4637402 (236)\ttotal: 1.3s\tremaining: 3.28s\n",
      "320:\tlearn: 0.2114168\ttest: 0.4667371\tbest: 0.4637402 (236)\ttotal: 1.3s\tremaining: 3.27s\n",
      "321:\tlearn: 0.2109627\ttest: 0.4671121\tbest: 0.4637402 (236)\ttotal: 1.3s\tremaining: 3.27s\n",
      "322:\tlearn: 0.2104829\ttest: 0.4671682\tbest: 0.4637402 (236)\ttotal: 1.31s\tremaining: 3.26s\n",
      "323:\tlearn: 0.2100625\ttest: 0.4670036\tbest: 0.4637402 (236)\ttotal: 1.31s\tremaining: 3.26s\n",
      "324:\tlearn: 0.2096678\ttest: 0.4669913\tbest: 0.4637402 (236)\ttotal: 1.31s\tremaining: 3.25s\n",
      "325:\tlearn: 0.2093110\ttest: 0.4673265\tbest: 0.4637402 (236)\ttotal: 1.32s\tremaining: 3.24s\n",
      "326:\tlearn: 0.2088870\ttest: 0.4673176\tbest: 0.4637402 (236)\ttotal: 1.32s\tremaining: 3.24s\n",
      "327:\tlearn: 0.2083893\ttest: 0.4674965\tbest: 0.4637402 (236)\ttotal: 1.32s\tremaining: 3.23s\n",
      "328:\tlearn: 0.2078345\ttest: 0.4672190\tbest: 0.4637402 (236)\ttotal: 1.33s\tremaining: 3.23s\n",
      "329:\tlearn: 0.2076861\ttest: 0.4672845\tbest: 0.4637402 (236)\ttotal: 1.33s\tremaining: 3.22s\n",
      "330:\tlearn: 0.2074233\ttest: 0.4672792\tbest: 0.4637402 (236)\ttotal: 1.33s\tremaining: 3.22s\n",
      "331:\tlearn: 0.2071226\ttest: 0.4672837\tbest: 0.4637402 (236)\ttotal: 1.34s\tremaining: 3.21s\n",
      "332:\tlearn: 0.2068139\ttest: 0.4672556\tbest: 0.4637402 (236)\ttotal: 1.34s\tremaining: 3.21s\n",
      "333:\tlearn: 0.2065233\ttest: 0.4674871\tbest: 0.4637402 (236)\ttotal: 1.35s\tremaining: 3.2s\n",
      "334:\tlearn: 0.2061948\ttest: 0.4674892\tbest: 0.4637402 (236)\ttotal: 1.35s\tremaining: 3.2s\n",
      "335:\tlearn: 0.2057079\ttest: 0.4671272\tbest: 0.4637402 (236)\ttotal: 1.35s\tremaining: 3.19s\n",
      "336:\tlearn: 0.2051169\ttest: 0.4671846\tbest: 0.4637402 (236)\ttotal: 1.36s\tremaining: 3.19s\n",
      "337:\tlearn: 0.2048001\ttest: 0.4670819\tbest: 0.4637402 (236)\ttotal: 1.36s\tremaining: 3.18s\n",
      "338:\tlearn: 0.2044138\ttest: 0.4672759\tbest: 0.4637402 (236)\ttotal: 1.36s\tremaining: 3.17s\n",
      "339:\tlearn: 0.2039776\ttest: 0.4672548\tbest: 0.4637402 (236)\ttotal: 1.37s\tremaining: 3.17s\n",
      "340:\tlearn: 0.2037690\ttest: 0.4671933\tbest: 0.4637402 (236)\ttotal: 1.37s\tremaining: 3.16s\n",
      "341:\tlearn: 0.2032457\ttest: 0.4669742\tbest: 0.4637402 (236)\ttotal: 1.37s\tremaining: 3.16s\n",
      "342:\tlearn: 0.2029345\ttest: 0.4668335\tbest: 0.4637402 (236)\ttotal: 1.38s\tremaining: 3.15s\n",
      "343:\tlearn: 0.2021693\ttest: 0.4667209\tbest: 0.4637402 (236)\ttotal: 1.38s\tremaining: 3.15s\n",
      "344:\tlearn: 0.2017121\ttest: 0.4669022\tbest: 0.4637402 (236)\ttotal: 1.38s\tremaining: 3.14s\n",
      "345:\tlearn: 0.2013862\ttest: 0.4668560\tbest: 0.4637402 (236)\ttotal: 1.39s\tremaining: 3.13s\n",
      "346:\tlearn: 0.2009934\ttest: 0.4667669\tbest: 0.4637402 (236)\ttotal: 1.39s\tremaining: 3.13s\n",
      "347:\tlearn: 0.2006414\ttest: 0.4666908\tbest: 0.4637402 (236)\ttotal: 1.39s\tremaining: 3.12s\n",
      "348:\tlearn: 0.2004163\ttest: 0.4666368\tbest: 0.4637402 (236)\ttotal: 1.4s\tremaining: 3.12s\n",
      "349:\tlearn: 0.1999639\ttest: 0.4667383\tbest: 0.4637402 (236)\ttotal: 1.4s\tremaining: 3.11s\n",
      "350:\tlearn: 0.1995363\ttest: 0.4670605\tbest: 0.4637402 (236)\ttotal: 1.4s\tremaining: 3.11s\n",
      "351:\tlearn: 0.1992339\ttest: 0.4670176\tbest: 0.4637402 (236)\ttotal: 1.41s\tremaining: 3.1s\n",
      "352:\tlearn: 0.1988610\ttest: 0.4670756\tbest: 0.4637402 (236)\ttotal: 1.41s\tremaining: 3.1s\n",
      "353:\tlearn: 0.1985232\ttest: 0.4671605\tbest: 0.4637402 (236)\ttotal: 1.41s\tremaining: 3.09s\n",
      "354:\tlearn: 0.1981682\ttest: 0.4674671\tbest: 0.4637402 (236)\ttotal: 1.42s\tremaining: 3.09s\n",
      "355:\tlearn: 0.1978688\ttest: 0.4675066\tbest: 0.4637402 (236)\ttotal: 1.42s\tremaining: 3.08s\n",
      "356:\tlearn: 0.1975665\ttest: 0.4675976\tbest: 0.4637402 (236)\ttotal: 1.42s\tremaining: 3.08s\n",
      "357:\tlearn: 0.1972975\ttest: 0.4675738\tbest: 0.4637402 (236)\ttotal: 1.43s\tremaining: 3.07s\n",
      "358:\tlearn: 0.1970024\ttest: 0.4678953\tbest: 0.4637402 (236)\ttotal: 1.43s\tremaining: 3.07s\n",
      "359:\tlearn: 0.1967465\ttest: 0.4678897\tbest: 0.4637402 (236)\ttotal: 1.44s\tremaining: 3.06s\n",
      "360:\tlearn: 0.1962823\ttest: 0.4678930\tbest: 0.4637402 (236)\ttotal: 1.44s\tremaining: 3.06s\n",
      "361:\tlearn: 0.1959461\ttest: 0.4676530\tbest: 0.4637402 (236)\ttotal: 1.44s\tremaining: 3.05s\n",
      "362:\tlearn: 0.1954851\ttest: 0.4678738\tbest: 0.4637402 (236)\ttotal: 1.45s\tremaining: 3.05s\n",
      "363:\tlearn: 0.1949692\ttest: 0.4680039\tbest: 0.4637402 (236)\ttotal: 1.45s\tremaining: 3.04s\n",
      "364:\tlearn: 0.1943419\ttest: 0.4684923\tbest: 0.4637402 (236)\ttotal: 1.45s\tremaining: 3.04s\n",
      "365:\tlearn: 0.1938960\ttest: 0.4687716\tbest: 0.4637402 (236)\ttotal: 1.46s\tremaining: 3.03s\n",
      "366:\tlearn: 0.1934228\ttest: 0.4687230\tbest: 0.4637402 (236)\ttotal: 1.46s\tremaining: 3.03s\n",
      "367:\tlearn: 0.1931381\ttest: 0.4686978\tbest: 0.4637402 (236)\ttotal: 1.46s\tremaining: 3.02s\n",
      "368:\tlearn: 0.1928782\ttest: 0.4686587\tbest: 0.4637402 (236)\ttotal: 1.47s\tremaining: 3.02s\n",
      "369:\tlearn: 0.1924780\ttest: 0.4688190\tbest: 0.4637402 (236)\ttotal: 1.47s\tremaining: 3.02s\n",
      "370:\tlearn: 0.1920323\ttest: 0.4689005\tbest: 0.4637402 (236)\ttotal: 1.48s\tremaining: 3.01s\n",
      "371:\tlearn: 0.1915758\ttest: 0.4689820\tbest: 0.4637402 (236)\ttotal: 1.48s\tremaining: 3.01s\n",
      "372:\tlearn: 0.1913862\ttest: 0.4689371\tbest: 0.4637402 (236)\ttotal: 1.48s\tremaining: 3s\n",
      "373:\tlearn: 0.1910052\ttest: 0.4687418\tbest: 0.4637402 (236)\ttotal: 1.49s\tremaining: 3s\n",
      "374:\tlearn: 0.1907894\ttest: 0.4688285\tbest: 0.4637402 (236)\ttotal: 1.49s\tremaining: 2.99s\n",
      "375:\tlearn: 0.1904435\ttest: 0.4689747\tbest: 0.4637402 (236)\ttotal: 1.49s\tremaining: 2.98s\n",
      "376:\tlearn: 0.1901897\ttest: 0.4691129\tbest: 0.4637402 (236)\ttotal: 1.5s\tremaining: 2.98s\n",
      "377:\tlearn: 0.1898331\ttest: 0.4692499\tbest: 0.4637402 (236)\ttotal: 1.5s\tremaining: 2.98s\n",
      "378:\tlearn: 0.1894426\ttest: 0.4691662\tbest: 0.4637402 (236)\ttotal: 1.5s\tremaining: 2.97s\n",
      "379:\tlearn: 0.1890487\ttest: 0.4692760\tbest: 0.4637402 (236)\ttotal: 1.51s\tremaining: 2.96s\n",
      "380:\tlearn: 0.1887920\ttest: 0.4692380\tbest: 0.4637402 (236)\ttotal: 1.51s\tremaining: 2.96s\n",
      "381:\tlearn: 0.1884993\ttest: 0.4694670\tbest: 0.4637402 (236)\ttotal: 1.51s\tremaining: 2.96s\n",
      "382:\tlearn: 0.1881918\ttest: 0.4695309\tbest: 0.4637402 (236)\ttotal: 1.52s\tremaining: 2.95s\n",
      "383:\tlearn: 0.1879740\ttest: 0.4695222\tbest: 0.4637402 (236)\ttotal: 1.52s\tremaining: 2.94s\n",
      "384:\tlearn: 0.1877924\ttest: 0.4696334\tbest: 0.4637402 (236)\ttotal: 1.52s\tremaining: 2.94s\n",
      "385:\tlearn: 0.1875051\ttest: 0.4695551\tbest: 0.4637402 (236)\ttotal: 1.53s\tremaining: 2.94s\n",
      "386:\tlearn: 0.1872510\ttest: 0.4694226\tbest: 0.4637402 (236)\ttotal: 1.53s\tremaining: 2.93s\n",
      "387:\tlearn: 0.1870051\ttest: 0.4693852\tbest: 0.4637402 (236)\ttotal: 1.53s\tremaining: 2.93s\n",
      "388:\tlearn: 0.1866211\ttest: 0.4692389\tbest: 0.4637402 (236)\ttotal: 1.54s\tremaining: 2.92s\n",
      "389:\tlearn: 0.1863398\ttest: 0.4692675\tbest: 0.4637402 (236)\ttotal: 1.54s\tremaining: 2.92s\n",
      "390:\tlearn: 0.1859826\ttest: 0.4694893\tbest: 0.4637402 (236)\ttotal: 1.55s\tremaining: 2.92s\n",
      "391:\tlearn: 0.1856878\ttest: 0.4695376\tbest: 0.4637402 (236)\ttotal: 1.55s\tremaining: 2.91s\n",
      "392:\tlearn: 0.1854606\ttest: 0.4695802\tbest: 0.4637402 (236)\ttotal: 1.55s\tremaining: 2.9s\n",
      "393:\tlearn: 0.1851851\ttest: 0.4696050\tbest: 0.4637402 (236)\ttotal: 1.56s\tremaining: 2.9s\n",
      "394:\tlearn: 0.1849179\ttest: 0.4696217\tbest: 0.4637402 (236)\ttotal: 1.56s\tremaining: 2.9s\n",
      "395:\tlearn: 0.1846328\ttest: 0.4697680\tbest: 0.4637402 (236)\ttotal: 1.56s\tremaining: 2.89s\n",
      "396:\tlearn: 0.1844003\ttest: 0.4696054\tbest: 0.4637402 (236)\ttotal: 1.57s\tremaining: 2.88s\n",
      "397:\tlearn: 0.1841719\ttest: 0.4696502\tbest: 0.4637402 (236)\ttotal: 1.57s\tremaining: 2.88s\n",
      "398:\tlearn: 0.1838954\ttest: 0.4695895\tbest: 0.4637402 (236)\ttotal: 1.57s\tremaining: 2.87s\n",
      "399:\tlearn: 0.1836525\ttest: 0.4696315\tbest: 0.4637402 (236)\ttotal: 1.58s\tremaining: 2.87s\n",
      "400:\tlearn: 0.1833270\ttest: 0.4696096\tbest: 0.4637402 (236)\ttotal: 1.58s\tremaining: 2.86s\n",
      "401:\tlearn: 0.1831211\ttest: 0.4694004\tbest: 0.4637402 (236)\ttotal: 1.58s\tremaining: 2.86s\n",
      "402:\tlearn: 0.1825036\ttest: 0.4693982\tbest: 0.4637402 (236)\ttotal: 1.59s\tremaining: 2.85s\n",
      "403:\tlearn: 0.1820100\ttest: 0.4693965\tbest: 0.4637402 (236)\ttotal: 1.59s\tremaining: 2.85s\n",
      "404:\tlearn: 0.1817766\ttest: 0.4695644\tbest: 0.4637402 (236)\ttotal: 1.59s\tremaining: 2.84s\n",
      "405:\tlearn: 0.1814736\ttest: 0.4694249\tbest: 0.4637402 (236)\ttotal: 1.6s\tremaining: 2.84s\n",
      "406:\tlearn: 0.1810890\ttest: 0.4698105\tbest: 0.4637402 (236)\ttotal: 1.6s\tremaining: 2.83s\n",
      "407:\tlearn: 0.1808544\ttest: 0.4697742\tbest: 0.4637402 (236)\ttotal: 1.6s\tremaining: 2.83s\n",
      "408:\tlearn: 0.1803405\ttest: 0.4699278\tbest: 0.4637402 (236)\ttotal: 1.61s\tremaining: 2.82s\n",
      "409:\tlearn: 0.1800761\ttest: 0.4698310\tbest: 0.4637402 (236)\ttotal: 1.61s\tremaining: 2.82s\n",
      "410:\tlearn: 0.1797759\ttest: 0.4699602\tbest: 0.4637402 (236)\ttotal: 1.61s\tremaining: 2.81s\n",
      "411:\tlearn: 0.1793658\ttest: 0.4698061\tbest: 0.4637402 (236)\ttotal: 1.62s\tremaining: 2.81s\n",
      "412:\tlearn: 0.1791200\ttest: 0.4699187\tbest: 0.4637402 (236)\ttotal: 1.62s\tremaining: 2.81s\n",
      "413:\tlearn: 0.1789243\ttest: 0.4698743\tbest: 0.4637402 (236)\ttotal: 1.62s\tremaining: 2.8s\n",
      "414:\tlearn: 0.1785617\ttest: 0.4697067\tbest: 0.4637402 (236)\ttotal: 1.63s\tremaining: 2.79s\n",
      "415:\tlearn: 0.1781693\ttest: 0.4694947\tbest: 0.4637402 (236)\ttotal: 1.63s\tremaining: 2.79s\n",
      "416:\tlearn: 0.1777381\ttest: 0.4696653\tbest: 0.4637402 (236)\ttotal: 1.63s\tremaining: 2.79s\n",
      "417:\tlearn: 0.1774633\ttest: 0.4697006\tbest: 0.4637402 (236)\ttotal: 1.64s\tremaining: 2.78s\n",
      "418:\tlearn: 0.1770392\ttest: 0.4697956\tbest: 0.4637402 (236)\ttotal: 1.64s\tremaining: 2.78s\n",
      "419:\tlearn: 0.1767137\ttest: 0.4699295\tbest: 0.4637402 (236)\ttotal: 1.64s\tremaining: 2.77s\n",
      "420:\tlearn: 0.1763504\ttest: 0.4701158\tbest: 0.4637402 (236)\ttotal: 1.65s\tremaining: 2.77s\n",
      "421:\tlearn: 0.1760524\ttest: 0.4701825\tbest: 0.4637402 (236)\ttotal: 1.65s\tremaining: 2.76s\n",
      "422:\tlearn: 0.1758496\ttest: 0.4701818\tbest: 0.4637402 (236)\ttotal: 1.65s\tremaining: 2.76s\n",
      "423:\tlearn: 0.1755619\ttest: 0.4703930\tbest: 0.4637402 (236)\ttotal: 1.66s\tremaining: 2.75s\n",
      "424:\tlearn: 0.1752834\ttest: 0.4707144\tbest: 0.4637402 (236)\ttotal: 1.66s\tremaining: 2.75s\n",
      "425:\tlearn: 0.1749325\ttest: 0.4709257\tbest: 0.4637402 (236)\ttotal: 1.66s\tremaining: 2.74s\n",
      "426:\tlearn: 0.1746311\ttest: 0.4710927\tbest: 0.4637402 (236)\ttotal: 1.67s\tremaining: 2.74s\n",
      "427:\tlearn: 0.1742547\ttest: 0.4717892\tbest: 0.4637402 (236)\ttotal: 1.67s\tremaining: 2.73s\n",
      "428:\tlearn: 0.1740325\ttest: 0.4716734\tbest: 0.4637402 (236)\ttotal: 1.67s\tremaining: 2.73s\n",
      "429:\tlearn: 0.1736389\ttest: 0.4717204\tbest: 0.4637402 (236)\ttotal: 1.68s\tremaining: 2.72s\n",
      "430:\tlearn: 0.1733656\ttest: 0.4716426\tbest: 0.4637402 (236)\ttotal: 1.68s\tremaining: 2.72s\n",
      "431:\tlearn: 0.1731822\ttest: 0.4716498\tbest: 0.4637402 (236)\ttotal: 1.68s\tremaining: 2.71s\n",
      "432:\tlearn: 0.1727522\ttest: 0.4716476\tbest: 0.4637402 (236)\ttotal: 1.69s\tremaining: 2.71s\n",
      "433:\tlearn: 0.1722757\ttest: 0.4722138\tbest: 0.4637402 (236)\ttotal: 1.69s\tremaining: 2.7s\n",
      "434:\tlearn: 0.1719027\ttest: 0.4722727\tbest: 0.4637402 (236)\ttotal: 1.69s\tremaining: 2.7s\n",
      "435:\tlearn: 0.1716897\ttest: 0.4723033\tbest: 0.4637402 (236)\ttotal: 1.7s\tremaining: 2.69s\n",
      "436:\tlearn: 0.1714756\ttest: 0.4722979\tbest: 0.4637402 (236)\ttotal: 1.7s\tremaining: 2.69s\n",
      "437:\tlearn: 0.1709899\ttest: 0.4722925\tbest: 0.4637402 (236)\ttotal: 1.7s\tremaining: 2.68s\n",
      "438:\tlearn: 0.1707446\ttest: 0.4724982\tbest: 0.4637402 (236)\ttotal: 1.71s\tremaining: 2.68s\n",
      "439:\tlearn: 0.1706016\ttest: 0.4725387\tbest: 0.4637402 (236)\ttotal: 1.71s\tremaining: 2.67s\n",
      "440:\tlearn: 0.1702840\ttest: 0.4724559\tbest: 0.4637402 (236)\ttotal: 1.71s\tremaining: 2.67s\n",
      "441:\tlearn: 0.1700750\ttest: 0.4726570\tbest: 0.4637402 (236)\ttotal: 1.72s\tremaining: 2.66s\n",
      "442:\tlearn: 0.1695650\ttest: 0.4728545\tbest: 0.4637402 (236)\ttotal: 1.72s\tremaining: 2.66s\n",
      "443:\tlearn: 0.1692804\ttest: 0.4729051\tbest: 0.4637402 (236)\ttotal: 1.72s\tremaining: 2.65s\n",
      "444:\tlearn: 0.1690380\ttest: 0.4730638\tbest: 0.4637402 (236)\ttotal: 1.73s\tremaining: 2.65s\n",
      "445:\tlearn: 0.1686407\ttest: 0.4733312\tbest: 0.4637402 (236)\ttotal: 1.73s\tremaining: 2.65s\n",
      "446:\tlearn: 0.1682880\ttest: 0.4734073\tbest: 0.4637402 (236)\ttotal: 1.73s\tremaining: 2.64s\n",
      "447:\tlearn: 0.1681305\ttest: 0.4733436\tbest: 0.4637402 (236)\ttotal: 1.74s\tremaining: 2.64s\n",
      "448:\tlearn: 0.1677421\ttest: 0.4732391\tbest: 0.4637402 (236)\ttotal: 1.74s\tremaining: 2.63s\n",
      "449:\tlearn: 0.1675443\ttest: 0.4734624\tbest: 0.4637402 (236)\ttotal: 1.75s\tremaining: 2.63s\n",
      "450:\tlearn: 0.1672768\ttest: 0.4737060\tbest: 0.4637402 (236)\ttotal: 1.75s\tremaining: 2.63s\n",
      "451:\tlearn: 0.1670915\ttest: 0.4737627\tbest: 0.4637402 (236)\ttotal: 1.75s\tremaining: 2.62s\n",
      "452:\tlearn: 0.1668910\ttest: 0.4740111\tbest: 0.4637402 (236)\ttotal: 1.76s\tremaining: 2.62s\n",
      "453:\tlearn: 0.1665401\ttest: 0.4740110\tbest: 0.4637402 (236)\ttotal: 1.76s\tremaining: 2.62s\n",
      "454:\tlearn: 0.1662669\ttest: 0.4740626\tbest: 0.4637402 (236)\ttotal: 1.77s\tremaining: 2.61s\n",
      "455:\tlearn: 0.1660170\ttest: 0.4740118\tbest: 0.4637402 (236)\ttotal: 1.77s\tremaining: 2.61s\n",
      "456:\tlearn: 0.1657643\ttest: 0.4743677\tbest: 0.4637402 (236)\ttotal: 1.77s\tremaining: 2.6s\n",
      "457:\tlearn: 0.1654859\ttest: 0.4744667\tbest: 0.4637402 (236)\ttotal: 1.78s\tremaining: 2.6s\n",
      "458:\tlearn: 0.1651744\ttest: 0.4749290\tbest: 0.4637402 (236)\ttotal: 1.78s\tremaining: 2.6s\n",
      "459:\tlearn: 0.1650009\ttest: 0.4749953\tbest: 0.4637402 (236)\ttotal: 1.79s\tremaining: 2.59s\n",
      "460:\tlearn: 0.1647258\ttest: 0.4752191\tbest: 0.4637402 (236)\ttotal: 1.79s\tremaining: 2.59s\n",
      "461:\tlearn: 0.1644596\ttest: 0.4752290\tbest: 0.4637402 (236)\ttotal: 1.79s\tremaining: 2.58s\n",
      "462:\tlearn: 0.1641471\ttest: 0.4753019\tbest: 0.4637402 (236)\ttotal: 1.8s\tremaining: 2.58s\n",
      "463:\tlearn: 0.1638595\ttest: 0.4753784\tbest: 0.4637402 (236)\ttotal: 1.8s\tremaining: 2.58s\n",
      "464:\tlearn: 0.1634451\ttest: 0.4753683\tbest: 0.4637402 (236)\ttotal: 1.8s\tremaining: 2.57s\n",
      "465:\tlearn: 0.1631474\ttest: 0.4751636\tbest: 0.4637402 (236)\ttotal: 1.81s\tremaining: 2.57s\n",
      "466:\tlearn: 0.1629851\ttest: 0.4751804\tbest: 0.4637402 (236)\ttotal: 1.81s\tremaining: 2.56s\n",
      "467:\tlearn: 0.1627987\ttest: 0.4751649\tbest: 0.4637402 (236)\ttotal: 1.81s\tremaining: 2.56s\n",
      "468:\tlearn: 0.1625000\ttest: 0.4751713\tbest: 0.4637402 (236)\ttotal: 1.82s\tremaining: 2.56s\n",
      "469:\tlearn: 0.1621880\ttest: 0.4751701\tbest: 0.4637402 (236)\ttotal: 1.82s\tremaining: 2.55s\n",
      "470:\tlearn: 0.1618235\ttest: 0.4751697\tbest: 0.4637402 (236)\ttotal: 1.82s\tremaining: 2.55s\n",
      "471:\tlearn: 0.1616784\ttest: 0.4752555\tbest: 0.4637402 (236)\ttotal: 1.83s\tremaining: 2.54s\n",
      "472:\tlearn: 0.1613801\ttest: 0.4751912\tbest: 0.4637402 (236)\ttotal: 1.83s\tremaining: 2.54s\n",
      "473:\tlearn: 0.1611795\ttest: 0.4750719\tbest: 0.4637402 (236)\ttotal: 1.83s\tremaining: 2.53s\n",
      "474:\tlearn: 0.1609441\ttest: 0.4751586\tbest: 0.4637402 (236)\ttotal: 1.84s\tremaining: 2.53s\n",
      "475:\tlearn: 0.1605501\ttest: 0.4753026\tbest: 0.4637402 (236)\ttotal: 1.84s\tremaining: 2.52s\n",
      "476:\tlearn: 0.1603307\ttest: 0.4751242\tbest: 0.4637402 (236)\ttotal: 1.85s\tremaining: 2.52s\n",
      "477:\tlearn: 0.1601130\ttest: 0.4748595\tbest: 0.4637402 (236)\ttotal: 1.85s\tremaining: 2.52s\n",
      "478:\tlearn: 0.1597740\ttest: 0.4745745\tbest: 0.4637402 (236)\ttotal: 1.85s\tremaining: 2.51s\n",
      "479:\tlearn: 0.1594165\ttest: 0.4746673\tbest: 0.4637402 (236)\ttotal: 1.86s\tremaining: 2.51s\n",
      "480:\tlearn: 0.1591558\ttest: 0.4746610\tbest: 0.4637402 (236)\ttotal: 1.86s\tremaining: 2.5s\n",
      "481:\tlearn: 0.1588643\ttest: 0.4747685\tbest: 0.4637402 (236)\ttotal: 1.86s\tremaining: 2.5s\n",
      "482:\tlearn: 0.1586135\ttest: 0.4746607\tbest: 0.4637402 (236)\ttotal: 1.87s\tremaining: 2.49s\n",
      "483:\tlearn: 0.1583986\ttest: 0.4749175\tbest: 0.4637402 (236)\ttotal: 1.87s\tremaining: 2.49s\n",
      "484:\tlearn: 0.1581351\ttest: 0.4748103\tbest: 0.4637402 (236)\ttotal: 1.87s\tremaining: 2.48s\n",
      "485:\tlearn: 0.1578566\ttest: 0.4750825\tbest: 0.4637402 (236)\ttotal: 1.88s\tremaining: 2.48s\n",
      "486:\tlearn: 0.1576704\ttest: 0.4753329\tbest: 0.4637402 (236)\ttotal: 1.88s\tremaining: 2.47s\n",
      "487:\tlearn: 0.1572988\ttest: 0.4752698\tbest: 0.4637402 (236)\ttotal: 1.88s\tremaining: 2.47s\n",
      "488:\tlearn: 0.1570562\ttest: 0.4750595\tbest: 0.4637402 (236)\ttotal: 1.89s\tremaining: 2.46s\n",
      "489:\tlearn: 0.1567801\ttest: 0.4750795\tbest: 0.4637402 (236)\ttotal: 1.89s\tremaining: 2.46s\n",
      "490:\tlearn: 0.1562406\ttest: 0.4755271\tbest: 0.4637402 (236)\ttotal: 1.89s\tremaining: 2.46s\n",
      "491:\tlearn: 0.1559619\ttest: 0.4757459\tbest: 0.4637402 (236)\ttotal: 1.9s\tremaining: 2.45s\n",
      "492:\tlearn: 0.1556820\ttest: 0.4759568\tbest: 0.4637402 (236)\ttotal: 1.9s\tremaining: 2.45s\n",
      "493:\tlearn: 0.1553422\ttest: 0.4758515\tbest: 0.4637402 (236)\ttotal: 1.9s\tremaining: 2.44s\n",
      "494:\tlearn: 0.1550644\ttest: 0.4760653\tbest: 0.4637402 (236)\ttotal: 1.91s\tremaining: 2.44s\n",
      "495:\tlearn: 0.1547705\ttest: 0.4762406\tbest: 0.4637402 (236)\ttotal: 1.91s\tremaining: 2.43s\n",
      "496:\tlearn: 0.1545443\ttest: 0.4762100\tbest: 0.4637402 (236)\ttotal: 1.91s\tremaining: 2.43s\n",
      "497:\tlearn: 0.1543360\ttest: 0.4761290\tbest: 0.4637402 (236)\ttotal: 1.92s\tremaining: 2.42s\n",
      "498:\tlearn: 0.1539908\ttest: 0.4762212\tbest: 0.4637402 (236)\ttotal: 1.92s\tremaining: 2.42s\n",
      "499:\tlearn: 0.1537511\ttest: 0.4763073\tbest: 0.4637402 (236)\ttotal: 1.92s\tremaining: 2.42s\n",
      "500:\tlearn: 0.1534849\ttest: 0.4761739\tbest: 0.4637402 (236)\ttotal: 1.93s\tremaining: 2.41s\n",
      "501:\tlearn: 0.1531960\ttest: 0.4763536\tbest: 0.4637402 (236)\ttotal: 1.93s\tremaining: 2.41s\n",
      "502:\tlearn: 0.1529137\ttest: 0.4765800\tbest: 0.4637402 (236)\ttotal: 1.93s\tremaining: 2.4s\n",
      "503:\tlearn: 0.1527272\ttest: 0.4767048\tbest: 0.4637402 (236)\ttotal: 1.94s\tremaining: 2.4s\n",
      "504:\tlearn: 0.1525847\ttest: 0.4768577\tbest: 0.4637402 (236)\ttotal: 1.94s\tremaining: 2.39s\n",
      "505:\tlearn: 0.1522641\ttest: 0.4768420\tbest: 0.4637402 (236)\ttotal: 1.94s\tremaining: 2.39s\n",
      "506:\tlearn: 0.1520048\ttest: 0.4767711\tbest: 0.4637402 (236)\ttotal: 1.95s\tremaining: 2.38s\n",
      "507:\tlearn: 0.1517820\ttest: 0.4766218\tbest: 0.4637402 (236)\ttotal: 1.95s\tremaining: 2.38s\n",
      "508:\tlearn: 0.1515575\ttest: 0.4768147\tbest: 0.4637402 (236)\ttotal: 1.95s\tremaining: 2.38s\n",
      "509:\tlearn: 0.1512787\ttest: 0.4769077\tbest: 0.4637402 (236)\ttotal: 1.96s\tremaining: 2.37s\n",
      "510:\tlearn: 0.1510541\ttest: 0.4770565\tbest: 0.4637402 (236)\ttotal: 1.96s\tremaining: 2.37s\n",
      "511:\tlearn: 0.1508293\ttest: 0.4770532\tbest: 0.4637402 (236)\ttotal: 1.96s\tremaining: 2.36s\n",
      "512:\tlearn: 0.1505405\ttest: 0.4770567\tbest: 0.4637402 (236)\ttotal: 1.97s\tremaining: 2.36s\n",
      "513:\tlearn: 0.1503694\ttest: 0.4771041\tbest: 0.4637402 (236)\ttotal: 1.97s\tremaining: 2.35s\n",
      "514:\tlearn: 0.1501154\ttest: 0.4770960\tbest: 0.4637402 (236)\ttotal: 1.97s\tremaining: 2.35s\n",
      "515:\tlearn: 0.1498020\ttest: 0.4771582\tbest: 0.4637402 (236)\ttotal: 1.98s\tremaining: 2.35s\n",
      "516:\tlearn: 0.1497255\ttest: 0.4771550\tbest: 0.4637402 (236)\ttotal: 1.98s\tremaining: 2.34s\n",
      "517:\tlearn: 0.1494976\ttest: 0.4774198\tbest: 0.4637402 (236)\ttotal: 1.99s\tremaining: 2.34s\n",
      "518:\tlearn: 0.1492784\ttest: 0.4774636\tbest: 0.4637402 (236)\ttotal: 1.99s\tremaining: 2.33s\n",
      "519:\tlearn: 0.1489985\ttest: 0.4774351\tbest: 0.4637402 (236)\ttotal: 1.99s\tremaining: 2.33s\n",
      "520:\tlearn: 0.1486808\ttest: 0.4773937\tbest: 0.4637402 (236)\ttotal: 2s\tremaining: 2.33s\n",
      "521:\tlearn: 0.1483868\ttest: 0.4774494\tbest: 0.4637402 (236)\ttotal: 2s\tremaining: 2.32s\n",
      "522:\tlearn: 0.1482219\ttest: 0.4775197\tbest: 0.4637402 (236)\ttotal: 2s\tremaining: 2.32s\n",
      "523:\tlearn: 0.1479857\ttest: 0.4776333\tbest: 0.4637402 (236)\ttotal: 2.01s\tremaining: 2.31s\n",
      "524:\tlearn: 0.1477633\ttest: 0.4776063\tbest: 0.4637402 (236)\ttotal: 2.01s\tremaining: 2.31s\n",
      "525:\tlearn: 0.1474800\ttest: 0.4774664\tbest: 0.4637402 (236)\ttotal: 2.01s\tremaining: 2.3s\n",
      "526:\tlearn: 0.1473366\ttest: 0.4773684\tbest: 0.4637402 (236)\ttotal: 2.02s\tremaining: 2.3s\n",
      "527:\tlearn: 0.1472085\ttest: 0.4774447\tbest: 0.4637402 (236)\ttotal: 2.02s\tremaining: 2.29s\n",
      "528:\tlearn: 0.1470172\ttest: 0.4773476\tbest: 0.4637402 (236)\ttotal: 2.02s\tremaining: 2.29s\n",
      "529:\tlearn: 0.1467281\ttest: 0.4773543\tbest: 0.4637402 (236)\ttotal: 2.02s\tremaining: 2.29s\n",
      "530:\tlearn: 0.1464551\ttest: 0.4772959\tbest: 0.4637402 (236)\ttotal: 2.03s\tremaining: 2.28s\n",
      "531:\tlearn: 0.1462546\ttest: 0.4775379\tbest: 0.4637402 (236)\ttotal: 2.03s\tremaining: 2.28s\n",
      "532:\tlearn: 0.1459632\ttest: 0.4778590\tbest: 0.4637402 (236)\ttotal: 2.04s\tremaining: 2.27s\n",
      "533:\tlearn: 0.1457364\ttest: 0.4778400\tbest: 0.4637402 (236)\ttotal: 2.04s\tremaining: 2.27s\n",
      "534:\tlearn: 0.1454348\ttest: 0.4780345\tbest: 0.4637402 (236)\ttotal: 2.04s\tremaining: 2.26s\n",
      "535:\tlearn: 0.1451438\ttest: 0.4781109\tbest: 0.4637402 (236)\ttotal: 2.04s\tremaining: 2.26s\n",
      "536:\tlearn: 0.1449129\ttest: 0.4781919\tbest: 0.4637402 (236)\ttotal: 2.05s\tremaining: 2.25s\n",
      "537:\tlearn: 0.1446637\ttest: 0.4783054\tbest: 0.4637402 (236)\ttotal: 2.05s\tremaining: 2.25s\n",
      "538:\tlearn: 0.1444374\ttest: 0.4785630\tbest: 0.4637402 (236)\ttotal: 2.06s\tremaining: 2.25s\n",
      "539:\tlearn: 0.1442260\ttest: 0.4785867\tbest: 0.4637402 (236)\ttotal: 2.06s\tremaining: 2.24s\n",
      "540:\tlearn: 0.1440458\ttest: 0.4785205\tbest: 0.4637402 (236)\ttotal: 2.06s\tremaining: 2.24s\n",
      "541:\tlearn: 0.1438647\ttest: 0.4783595\tbest: 0.4637402 (236)\ttotal: 2.06s\tremaining: 2.23s\n",
      "542:\tlearn: 0.1436301\ttest: 0.4783322\tbest: 0.4637402 (236)\ttotal: 2.07s\tremaining: 2.23s\n",
      "543:\tlearn: 0.1434087\ttest: 0.4784162\tbest: 0.4637402 (236)\ttotal: 2.07s\tremaining: 2.22s\n",
      "544:\tlearn: 0.1431886\ttest: 0.4783280\tbest: 0.4637402 (236)\ttotal: 2.07s\tremaining: 2.22s\n",
      "545:\tlearn: 0.1430415\ttest: 0.4784096\tbest: 0.4637402 (236)\ttotal: 2.08s\tremaining: 2.21s\n",
      "546:\tlearn: 0.1429056\ttest: 0.4784781\tbest: 0.4637402 (236)\ttotal: 2.08s\tremaining: 2.21s\n",
      "547:\tlearn: 0.1426195\ttest: 0.4786700\tbest: 0.4637402 (236)\ttotal: 2.08s\tremaining: 2.21s\n",
      "548:\tlearn: 0.1423657\ttest: 0.4785983\tbest: 0.4637402 (236)\ttotal: 2.09s\tremaining: 2.2s\n",
      "549:\tlearn: 0.1421397\ttest: 0.4789211\tbest: 0.4637402 (236)\ttotal: 2.09s\tremaining: 2.2s\n",
      "550:\tlearn: 0.1419665\ttest: 0.4790780\tbest: 0.4637402 (236)\ttotal: 2.09s\tremaining: 2.19s\n",
      "551:\tlearn: 0.1416828\ttest: 0.4794174\tbest: 0.4637402 (236)\ttotal: 2.1s\tremaining: 2.19s\n",
      "552:\tlearn: 0.1413886\ttest: 0.4791738\tbest: 0.4637402 (236)\ttotal: 2.1s\tremaining: 2.19s\n",
      "553:\tlearn: 0.1408705\ttest: 0.4793037\tbest: 0.4637402 (236)\ttotal: 2.11s\tremaining: 2.18s\n",
      "554:\tlearn: 0.1407176\ttest: 0.4793271\tbest: 0.4637402 (236)\ttotal: 2.11s\tremaining: 2.18s\n",
      "555:\tlearn: 0.1405475\ttest: 0.4796199\tbest: 0.4637402 (236)\ttotal: 2.11s\tremaining: 2.17s\n",
      "556:\tlearn: 0.1403963\ttest: 0.4796524\tbest: 0.4637402 (236)\ttotal: 2.12s\tremaining: 2.17s\n",
      "557:\tlearn: 0.1402831\ttest: 0.4796138\tbest: 0.4637402 (236)\ttotal: 2.12s\tremaining: 2.17s\n",
      "558:\tlearn: 0.1399722\ttest: 0.4797217\tbest: 0.4637402 (236)\ttotal: 2.13s\tremaining: 2.16s\n",
      "559:\tlearn: 0.1396721\ttest: 0.4797493\tbest: 0.4637402 (236)\ttotal: 2.13s\tremaining: 2.16s\n",
      "560:\tlearn: 0.1394353\ttest: 0.4797413\tbest: 0.4637402 (236)\ttotal: 2.13s\tremaining: 2.16s\n",
      "561:\tlearn: 0.1392097\ttest: 0.4796658\tbest: 0.4637402 (236)\ttotal: 2.14s\tremaining: 2.15s\n",
      "562:\tlearn: 0.1389781\ttest: 0.4796429\tbest: 0.4637402 (236)\ttotal: 2.14s\tremaining: 2.15s\n",
      "563:\tlearn: 0.1387994\ttest: 0.4795451\tbest: 0.4637402 (236)\ttotal: 2.14s\tremaining: 2.14s\n",
      "564:\tlearn: 0.1385875\ttest: 0.4794642\tbest: 0.4637402 (236)\ttotal: 2.15s\tremaining: 2.14s\n",
      "565:\tlearn: 0.1384158\ttest: 0.4794163\tbest: 0.4637402 (236)\ttotal: 2.15s\tremaining: 2.14s\n",
      "566:\tlearn: 0.1382514\ttest: 0.4795266\tbest: 0.4637402 (236)\ttotal: 2.15s\tremaining: 2.13s\n",
      "567:\tlearn: 0.1380848\ttest: 0.4794912\tbest: 0.4637402 (236)\ttotal: 2.16s\tremaining: 2.13s\n",
      "568:\tlearn: 0.1378758\ttest: 0.4798298\tbest: 0.4637402 (236)\ttotal: 2.16s\tremaining: 2.12s\n",
      "569:\tlearn: 0.1376863\ttest: 0.4796207\tbest: 0.4637402 (236)\ttotal: 2.17s\tremaining: 2.12s\n",
      "570:\tlearn: 0.1374598\ttest: 0.4794904\tbest: 0.4637402 (236)\ttotal: 2.17s\tremaining: 2.12s\n",
      "571:\tlearn: 0.1371739\ttest: 0.4796525\tbest: 0.4637402 (236)\ttotal: 2.17s\tremaining: 2.11s\n",
      "572:\tlearn: 0.1369489\ttest: 0.4796712\tbest: 0.4637402 (236)\ttotal: 2.18s\tremaining: 2.11s\n",
      "573:\tlearn: 0.1367146\ttest: 0.4795622\tbest: 0.4637402 (236)\ttotal: 2.18s\tremaining: 2.1s\n",
      "574:\tlearn: 0.1364713\ttest: 0.4795211\tbest: 0.4637402 (236)\ttotal: 2.18s\tremaining: 2.1s\n",
      "575:\tlearn: 0.1362179\ttest: 0.4795408\tbest: 0.4637402 (236)\ttotal: 2.19s\tremaining: 2.1s\n",
      "576:\tlearn: 0.1359574\ttest: 0.4797620\tbest: 0.4637402 (236)\ttotal: 2.19s\tremaining: 2.09s\n",
      "577:\tlearn: 0.1357707\ttest: 0.4800090\tbest: 0.4637402 (236)\ttotal: 2.19s\tremaining: 2.09s\n",
      "578:\tlearn: 0.1355423\ttest: 0.4804081\tbest: 0.4637402 (236)\ttotal: 2.2s\tremaining: 2.08s\n",
      "579:\tlearn: 0.1353436\ttest: 0.4804782\tbest: 0.4637402 (236)\ttotal: 2.2s\tremaining: 2.08s\n",
      "580:\tlearn: 0.1351910\ttest: 0.4804803\tbest: 0.4637402 (236)\ttotal: 2.2s\tremaining: 2.08s\n",
      "581:\tlearn: 0.1350441\ttest: 0.4806681\tbest: 0.4637402 (236)\ttotal: 2.21s\tremaining: 2.07s\n",
      "582:\tlearn: 0.1348175\ttest: 0.4808365\tbest: 0.4637402 (236)\ttotal: 2.21s\tremaining: 2.07s\n",
      "583:\tlearn: 0.1346636\ttest: 0.4808850\tbest: 0.4637402 (236)\ttotal: 2.21s\tremaining: 2.06s\n",
      "584:\tlearn: 0.1344476\ttest: 0.4808379\tbest: 0.4637402 (236)\ttotal: 2.22s\tremaining: 2.06s\n",
      "585:\tlearn: 0.1342476\ttest: 0.4810821\tbest: 0.4637402 (236)\ttotal: 2.22s\tremaining: 2.05s\n",
      "586:\tlearn: 0.1340544\ttest: 0.4811859\tbest: 0.4637402 (236)\ttotal: 2.23s\tremaining: 2.05s\n",
      "587:\tlearn: 0.1338592\ttest: 0.4813738\tbest: 0.4637402 (236)\ttotal: 2.23s\tremaining: 2.05s\n",
      "588:\tlearn: 0.1335494\ttest: 0.4813200\tbest: 0.4637402 (236)\ttotal: 2.23s\tremaining: 2.04s\n",
      "589:\tlearn: 0.1334440\ttest: 0.4814734\tbest: 0.4637402 (236)\ttotal: 2.23s\tremaining: 2.04s\n",
      "590:\tlearn: 0.1331846\ttest: 0.4814630\tbest: 0.4637402 (236)\ttotal: 2.24s\tremaining: 2.03s\n",
      "591:\tlearn: 0.1329808\ttest: 0.4815256\tbest: 0.4637402 (236)\ttotal: 2.24s\tremaining: 2.03s\n",
      "592:\tlearn: 0.1327784\ttest: 0.4815636\tbest: 0.4637402 (236)\ttotal: 2.25s\tremaining: 2.02s\n",
      "593:\tlearn: 0.1325880\ttest: 0.4816246\tbest: 0.4637402 (236)\ttotal: 2.25s\tremaining: 2.02s\n",
      "594:\tlearn: 0.1323017\ttest: 0.4817839\tbest: 0.4637402 (236)\ttotal: 2.25s\tremaining: 2.02s\n",
      "595:\tlearn: 0.1320988\ttest: 0.4816761\tbest: 0.4637402 (236)\ttotal: 2.25s\tremaining: 2.01s\n",
      "596:\tlearn: 0.1318939\ttest: 0.4817645\tbest: 0.4637402 (236)\ttotal: 2.26s\tremaining: 2.01s\n",
      "597:\tlearn: 0.1316555\ttest: 0.4818998\tbest: 0.4637402 (236)\ttotal: 2.26s\tremaining: 2s\n",
      "598:\tlearn: 0.1313886\ttest: 0.4820732\tbest: 0.4637402 (236)\ttotal: 2.27s\tremaining: 2s\n",
      "599:\tlearn: 0.1311678\ttest: 0.4821857\tbest: 0.4637402 (236)\ttotal: 2.27s\tremaining: 2s\n",
      "600:\tlearn: 0.1307801\ttest: 0.4824155\tbest: 0.4637402 (236)\ttotal: 2.27s\tremaining: 1.99s\n",
      "601:\tlearn: 0.1306132\ttest: 0.4825634\tbest: 0.4637402 (236)\ttotal: 2.27s\tremaining: 1.99s\n",
      "602:\tlearn: 0.1304161\ttest: 0.4824438\tbest: 0.4637402 (236)\ttotal: 2.28s\tremaining: 1.98s\n",
      "603:\tlearn: 0.1302012\ttest: 0.4824627\tbest: 0.4637402 (236)\ttotal: 2.28s\tremaining: 1.98s\n",
      "604:\tlearn: 0.1299185\ttest: 0.4826898\tbest: 0.4637402 (236)\ttotal: 2.29s\tremaining: 1.98s\n",
      "605:\tlearn: 0.1296354\ttest: 0.4826584\tbest: 0.4637402 (236)\ttotal: 2.29s\tremaining: 1.97s\n",
      "606:\tlearn: 0.1294586\ttest: 0.4826648\tbest: 0.4637402 (236)\ttotal: 2.29s\tremaining: 1.97s\n",
      "607:\tlearn: 0.1292839\ttest: 0.4826220\tbest: 0.4637402 (236)\ttotal: 2.29s\tremaining: 1.96s\n",
      "608:\tlearn: 0.1290846\ttest: 0.4826242\tbest: 0.4637402 (236)\ttotal: 2.3s\tremaining: 1.96s\n",
      "609:\tlearn: 0.1289007\ttest: 0.4827831\tbest: 0.4637402 (236)\ttotal: 2.3s\tremaining: 1.96s\n",
      "610:\tlearn: 0.1287174\ttest: 0.4827057\tbest: 0.4637402 (236)\ttotal: 2.31s\tremaining: 1.95s\n",
      "611:\tlearn: 0.1284872\ttest: 0.4827044\tbest: 0.4637402 (236)\ttotal: 2.31s\tremaining: 1.95s\n",
      "612:\tlearn: 0.1282780\ttest: 0.4828374\tbest: 0.4637402 (236)\ttotal: 2.31s\tremaining: 1.94s\n",
      "613:\tlearn: 0.1280660\ttest: 0.4828055\tbest: 0.4637402 (236)\ttotal: 2.32s\tremaining: 1.94s\n",
      "614:\tlearn: 0.1279073\ttest: 0.4827891\tbest: 0.4637402 (236)\ttotal: 2.32s\tremaining: 1.94s\n",
      "615:\tlearn: 0.1277120\ttest: 0.4827448\tbest: 0.4637402 (236)\ttotal: 2.32s\tremaining: 1.93s\n",
      "616:\tlearn: 0.1274310\ttest: 0.4830166\tbest: 0.4637402 (236)\ttotal: 2.33s\tremaining: 1.93s\n",
      "617:\tlearn: 0.1272510\ttest: 0.4831355\tbest: 0.4637402 (236)\ttotal: 2.33s\tremaining: 1.92s\n",
      "618:\tlearn: 0.1269616\ttest: 0.4830406\tbest: 0.4637402 (236)\ttotal: 2.33s\tremaining: 1.92s\n",
      "619:\tlearn: 0.1268385\ttest: 0.4831681\tbest: 0.4637402 (236)\ttotal: 2.34s\tremaining: 1.92s\n",
      "620:\tlearn: 0.1266729\ttest: 0.4832828\tbest: 0.4637402 (236)\ttotal: 2.34s\tremaining: 1.91s\n",
      "621:\tlearn: 0.1264597\ttest: 0.4832881\tbest: 0.4637402 (236)\ttotal: 2.34s\tremaining: 1.91s\n",
      "622:\tlearn: 0.1261972\ttest: 0.4832082\tbest: 0.4637402 (236)\ttotal: 2.35s\tremaining: 1.9s\n",
      "623:\tlearn: 0.1259859\ttest: 0.4833926\tbest: 0.4637402 (236)\ttotal: 2.35s\tremaining: 1.9s\n",
      "624:\tlearn: 0.1257464\ttest: 0.4834446\tbest: 0.4637402 (236)\ttotal: 2.35s\tremaining: 1.9s\n",
      "625:\tlearn: 0.1256418\ttest: 0.4835123\tbest: 0.4637402 (236)\ttotal: 2.36s\tremaining: 1.89s\n",
      "626:\tlearn: 0.1254833\ttest: 0.4836764\tbest: 0.4637402 (236)\ttotal: 2.36s\tremaining: 1.89s\n",
      "627:\tlearn: 0.1253187\ttest: 0.4835983\tbest: 0.4637402 (236)\ttotal: 2.37s\tremaining: 1.88s\n",
      "628:\tlearn: 0.1251490\ttest: 0.4836550\tbest: 0.4637402 (236)\ttotal: 2.37s\tremaining: 1.88s\n",
      "629:\tlearn: 0.1249947\ttest: 0.4836604\tbest: 0.4637402 (236)\ttotal: 2.37s\tremaining: 1.88s\n",
      "630:\tlearn: 0.1246701\ttest: 0.4838583\tbest: 0.4637402 (236)\ttotal: 2.38s\tremaining: 1.87s\n",
      "631:\tlearn: 0.1244784\ttest: 0.4839057\tbest: 0.4637402 (236)\ttotal: 2.38s\tremaining: 1.87s\n",
      "632:\tlearn: 0.1242436\ttest: 0.4838244\tbest: 0.4637402 (236)\ttotal: 2.38s\tremaining: 1.86s\n",
      "633:\tlearn: 0.1240453\ttest: 0.4837172\tbest: 0.4637402 (236)\ttotal: 2.39s\tremaining: 1.86s\n",
      "634:\tlearn: 0.1238756\ttest: 0.4836570\tbest: 0.4637402 (236)\ttotal: 2.39s\tremaining: 1.85s\n",
      "635:\tlearn: 0.1236927\ttest: 0.4837924\tbest: 0.4637402 (236)\ttotal: 2.39s\tremaining: 1.85s\n",
      "636:\tlearn: 0.1234966\ttest: 0.4839737\tbest: 0.4637402 (236)\ttotal: 2.4s\tremaining: 1.85s\n",
      "637:\tlearn: 0.1233161\ttest: 0.4841218\tbest: 0.4637402 (236)\ttotal: 2.4s\tremaining: 1.84s\n",
      "638:\tlearn: 0.1230752\ttest: 0.4841807\tbest: 0.4637402 (236)\ttotal: 2.4s\tremaining: 1.84s\n",
      "639:\tlearn: 0.1227411\ttest: 0.4843860\tbest: 0.4637402 (236)\ttotal: 2.41s\tremaining: 1.83s\n",
      "640:\tlearn: 0.1226173\ttest: 0.4842622\tbest: 0.4637402 (236)\ttotal: 2.41s\tremaining: 1.83s\n",
      "641:\tlearn: 0.1223962\ttest: 0.4840325\tbest: 0.4637402 (236)\ttotal: 2.41s\tremaining: 1.83s\n",
      "642:\tlearn: 0.1220276\ttest: 0.4843197\tbest: 0.4637402 (236)\ttotal: 2.42s\tremaining: 1.82s\n",
      "643:\tlearn: 0.1217580\ttest: 0.4841039\tbest: 0.4637402 (236)\ttotal: 2.42s\tremaining: 1.82s\n",
      "644:\tlearn: 0.1215224\ttest: 0.4842777\tbest: 0.4637402 (236)\ttotal: 2.42s\tremaining: 1.81s\n",
      "645:\tlearn: 0.1213608\ttest: 0.4842824\tbest: 0.4637402 (236)\ttotal: 2.43s\tremaining: 1.81s\n",
      "646:\tlearn: 0.1212192\ttest: 0.4842270\tbest: 0.4637402 (236)\ttotal: 2.43s\tremaining: 1.81s\n",
      "647:\tlearn: 0.1211228\ttest: 0.4842393\tbest: 0.4637402 (236)\ttotal: 2.43s\tremaining: 1.8s\n",
      "648:\tlearn: 0.1209815\ttest: 0.4844049\tbest: 0.4637402 (236)\ttotal: 2.44s\tremaining: 1.8s\n",
      "649:\tlearn: 0.1207968\ttest: 0.4846282\tbest: 0.4637402 (236)\ttotal: 2.44s\tremaining: 1.79s\n",
      "650:\tlearn: 0.1206531\ttest: 0.4845996\tbest: 0.4637402 (236)\ttotal: 2.44s\tremaining: 1.79s\n",
      "651:\tlearn: 0.1204478\ttest: 0.4847338\tbest: 0.4637402 (236)\ttotal: 2.45s\tremaining: 1.79s\n",
      "652:\tlearn: 0.1202663\ttest: 0.4849560\tbest: 0.4637402 (236)\ttotal: 2.45s\tremaining: 1.78s\n",
      "653:\tlearn: 0.1200344\ttest: 0.4850681\tbest: 0.4637402 (236)\ttotal: 2.45s\tremaining: 1.78s\n",
      "654:\tlearn: 0.1198959\ttest: 0.4850073\tbest: 0.4637402 (236)\ttotal: 2.46s\tremaining: 1.77s\n",
      "655:\tlearn: 0.1196807\ttest: 0.4851839\tbest: 0.4637402 (236)\ttotal: 2.46s\tremaining: 1.77s\n",
      "656:\tlearn: 0.1192404\ttest: 0.4853127\tbest: 0.4637402 (236)\ttotal: 2.46s\tremaining: 1.77s\n",
      "657:\tlearn: 0.1190352\ttest: 0.4852023\tbest: 0.4637402 (236)\ttotal: 2.47s\tremaining: 1.76s\n",
      "658:\tlearn: 0.1188765\ttest: 0.4854688\tbest: 0.4637402 (236)\ttotal: 2.47s\tremaining: 1.76s\n",
      "659:\tlearn: 0.1184105\ttest: 0.4855379\tbest: 0.4637402 (236)\ttotal: 2.48s\tremaining: 1.75s\n",
      "660:\tlearn: 0.1181177\ttest: 0.4856325\tbest: 0.4637402 (236)\ttotal: 2.48s\tremaining: 1.75s\n",
      "661:\tlearn: 0.1178606\ttest: 0.4857721\tbest: 0.4637402 (236)\ttotal: 2.48s\tremaining: 1.75s\n",
      "662:\tlearn: 0.1175699\ttest: 0.4855913\tbest: 0.4637402 (236)\ttotal: 2.48s\tremaining: 1.74s\n",
      "663:\tlearn: 0.1173863\ttest: 0.4857071\tbest: 0.4637402 (236)\ttotal: 2.49s\tremaining: 1.74s\n",
      "664:\tlearn: 0.1171208\ttest: 0.4857090\tbest: 0.4637402 (236)\ttotal: 2.49s\tremaining: 1.74s\n",
      "665:\tlearn: 0.1169785\ttest: 0.4856299\tbest: 0.4637402 (236)\ttotal: 2.5s\tremaining: 1.73s\n",
      "666:\tlearn: 0.1168849\ttest: 0.4857038\tbest: 0.4637402 (236)\ttotal: 2.5s\tremaining: 1.73s\n",
      "667:\tlearn: 0.1167521\ttest: 0.4857450\tbest: 0.4637402 (236)\ttotal: 2.5s\tremaining: 1.72s\n",
      "668:\tlearn: 0.1165504\ttest: 0.4860380\tbest: 0.4637402 (236)\ttotal: 2.5s\tremaining: 1.72s\n",
      "669:\tlearn: 0.1163040\ttest: 0.4862305\tbest: 0.4637402 (236)\ttotal: 2.51s\tremaining: 1.72s\n",
      "670:\tlearn: 0.1161300\ttest: 0.4862364\tbest: 0.4637402 (236)\ttotal: 2.51s\tremaining: 1.71s\n",
      "671:\tlearn: 0.1159372\ttest: 0.4862796\tbest: 0.4637402 (236)\ttotal: 2.52s\tremaining: 1.71s\n",
      "672:\tlearn: 0.1157086\ttest: 0.4863010\tbest: 0.4637402 (236)\ttotal: 2.52s\tremaining: 1.7s\n",
      "673:\tlearn: 0.1154946\ttest: 0.4863401\tbest: 0.4637402 (236)\ttotal: 2.52s\tremaining: 1.7s\n",
      "674:\tlearn: 0.1153167\ttest: 0.4865273\tbest: 0.4637402 (236)\ttotal: 2.53s\tremaining: 1.7s\n",
      "675:\tlearn: 0.1150698\ttest: 0.4867845\tbest: 0.4637402 (236)\ttotal: 2.53s\tremaining: 1.69s\n",
      "676:\tlearn: 0.1149388\ttest: 0.4867676\tbest: 0.4637402 (236)\ttotal: 2.53s\tremaining: 1.69s\n",
      "677:\tlearn: 0.1147628\ttest: 0.4869031\tbest: 0.4637402 (236)\ttotal: 2.54s\tremaining: 1.68s\n",
      "678:\tlearn: 0.1145400\ttest: 0.4870117\tbest: 0.4637402 (236)\ttotal: 2.54s\tremaining: 1.68s\n",
      "679:\tlearn: 0.1142788\ttest: 0.4870259\tbest: 0.4637402 (236)\ttotal: 2.54s\tremaining: 1.68s\n",
      "680:\tlearn: 0.1141454\ttest: 0.4871077\tbest: 0.4637402 (236)\ttotal: 2.55s\tremaining: 1.67s\n",
      "681:\tlearn: 0.1139417\ttest: 0.4872973\tbest: 0.4637402 (236)\ttotal: 2.55s\tremaining: 1.67s\n",
      "682:\tlearn: 0.1137890\ttest: 0.4872077\tbest: 0.4637402 (236)\ttotal: 2.55s\tremaining: 1.66s\n",
      "683:\tlearn: 0.1136332\ttest: 0.4871882\tbest: 0.4637402 (236)\ttotal: 2.56s\tremaining: 1.66s\n",
      "684:\tlearn: 0.1133481\ttest: 0.4870664\tbest: 0.4637402 (236)\ttotal: 2.56s\tremaining: 1.66s\n",
      "685:\tlearn: 0.1130865\ttest: 0.4869699\tbest: 0.4637402 (236)\ttotal: 2.56s\tremaining: 1.65s\n",
      "686:\tlearn: 0.1129502\ttest: 0.4871563\tbest: 0.4637402 (236)\ttotal: 2.57s\tremaining: 1.65s\n",
      "687:\tlearn: 0.1127955\ttest: 0.4873567\tbest: 0.4637402 (236)\ttotal: 2.57s\tremaining: 1.64s\n",
      "688:\tlearn: 0.1126131\ttest: 0.4874403\tbest: 0.4637402 (236)\ttotal: 2.57s\tremaining: 1.64s\n",
      "689:\tlearn: 0.1124711\ttest: 0.4875822\tbest: 0.4637402 (236)\ttotal: 2.58s\tremaining: 1.64s\n",
      "690:\tlearn: 0.1123345\ttest: 0.4875401\tbest: 0.4637402 (236)\ttotal: 2.58s\tremaining: 1.63s\n",
      "691:\tlearn: 0.1121694\ttest: 0.4875962\tbest: 0.4637402 (236)\ttotal: 2.58s\tremaining: 1.63s\n",
      "692:\tlearn: 0.1120577\ttest: 0.4875905\tbest: 0.4637402 (236)\ttotal: 2.59s\tremaining: 1.62s\n",
      "693:\tlearn: 0.1119482\ttest: 0.4877640\tbest: 0.4637402 (236)\ttotal: 2.59s\tremaining: 1.62s\n",
      "694:\tlearn: 0.1117885\ttest: 0.4878398\tbest: 0.4637402 (236)\ttotal: 2.59s\tremaining: 1.62s\n",
      "695:\tlearn: 0.1115418\ttest: 0.4879262\tbest: 0.4637402 (236)\ttotal: 2.6s\tremaining: 1.61s\n",
      "696:\tlearn: 0.1113155\ttest: 0.4878578\tbest: 0.4637402 (236)\ttotal: 2.6s\tremaining: 1.61s\n",
      "697:\tlearn: 0.1111114\ttest: 0.4880940\tbest: 0.4637402 (236)\ttotal: 2.6s\tremaining: 1.6s\n",
      "698:\tlearn: 0.1109467\ttest: 0.4880422\tbest: 0.4637402 (236)\ttotal: 2.61s\tremaining: 1.6s\n",
      "699:\tlearn: 0.1107370\ttest: 0.4880636\tbest: 0.4637402 (236)\ttotal: 2.61s\tremaining: 1.6s\n",
      "700:\tlearn: 0.1104877\ttest: 0.4881098\tbest: 0.4637402 (236)\ttotal: 2.61s\tremaining: 1.59s\n",
      "701:\tlearn: 0.1102736\ttest: 0.4880929\tbest: 0.4637402 (236)\ttotal: 2.62s\tremaining: 1.59s\n",
      "702:\tlearn: 0.1100633\ttest: 0.4880932\tbest: 0.4637402 (236)\ttotal: 2.62s\tremaining: 1.58s\n",
      "703:\tlearn: 0.1098520\ttest: 0.4880592\tbest: 0.4637402 (236)\ttotal: 2.62s\tremaining: 1.58s\n",
      "704:\tlearn: 0.1097227\ttest: 0.4881503\tbest: 0.4637402 (236)\ttotal: 2.63s\tremaining: 1.58s\n",
      "705:\tlearn: 0.1095832\ttest: 0.4882670\tbest: 0.4637402 (236)\ttotal: 2.63s\tremaining: 1.57s\n",
      "706:\tlearn: 0.1094931\ttest: 0.4883913\tbest: 0.4637402 (236)\ttotal: 2.63s\tremaining: 1.57s\n",
      "707:\tlearn: 0.1092956\ttest: 0.4882901\tbest: 0.4637402 (236)\ttotal: 2.64s\tremaining: 1.56s\n",
      "708:\tlearn: 0.1091864\ttest: 0.4882560\tbest: 0.4637402 (236)\ttotal: 2.64s\tremaining: 1.56s\n",
      "709:\tlearn: 0.1090019\ttest: 0.4883850\tbest: 0.4637402 (236)\ttotal: 2.64s\tremaining: 1.56s\n",
      "710:\tlearn: 0.1088072\ttest: 0.4884266\tbest: 0.4637402 (236)\ttotal: 2.65s\tremaining: 1.55s\n",
      "711:\tlearn: 0.1086162\ttest: 0.4884492\tbest: 0.4637402 (236)\ttotal: 2.65s\tremaining: 1.55s\n",
      "712:\tlearn: 0.1083937\ttest: 0.4884610\tbest: 0.4637402 (236)\ttotal: 2.65s\tremaining: 1.54s\n",
      "713:\tlearn: 0.1082270\ttest: 0.4884474\tbest: 0.4637402 (236)\ttotal: 2.66s\tremaining: 1.54s\n",
      "714:\tlearn: 0.1080118\ttest: 0.4887027\tbest: 0.4637402 (236)\ttotal: 2.66s\tremaining: 1.54s\n",
      "715:\tlearn: 0.1077920\ttest: 0.4885614\tbest: 0.4637402 (236)\ttotal: 2.66s\tremaining: 1.53s\n",
      "716:\tlearn: 0.1075883\ttest: 0.4886858\tbest: 0.4637402 (236)\ttotal: 2.67s\tremaining: 1.53s\n",
      "717:\tlearn: 0.1073188\ttest: 0.4886150\tbest: 0.4637402 (236)\ttotal: 2.67s\tremaining: 1.52s\n",
      "718:\tlearn: 0.1071516\ttest: 0.4886608\tbest: 0.4637402 (236)\ttotal: 2.67s\tremaining: 1.52s\n",
      "719:\tlearn: 0.1070025\ttest: 0.4886904\tbest: 0.4637402 (236)\ttotal: 2.68s\tremaining: 1.52s\n",
      "720:\tlearn: 0.1068106\ttest: 0.4889374\tbest: 0.4637402 (236)\ttotal: 2.68s\tremaining: 1.51s\n",
      "721:\tlearn: 0.1066741\ttest: 0.4889520\tbest: 0.4637402 (236)\ttotal: 2.68s\tremaining: 1.51s\n",
      "722:\tlearn: 0.1065219\ttest: 0.4889585\tbest: 0.4637402 (236)\ttotal: 2.69s\tremaining: 1.5s\n",
      "723:\tlearn: 0.1063958\ttest: 0.4889759\tbest: 0.4637402 (236)\ttotal: 2.69s\tremaining: 1.5s\n",
      "724:\tlearn: 0.1061917\ttest: 0.4891765\tbest: 0.4637402 (236)\ttotal: 2.69s\tremaining: 1.5s\n",
      "725:\tlearn: 0.1059942\ttest: 0.4892356\tbest: 0.4637402 (236)\ttotal: 2.7s\tremaining: 1.49s\n",
      "726:\tlearn: 0.1058503\ttest: 0.4895564\tbest: 0.4637402 (236)\ttotal: 2.7s\tremaining: 1.49s\n",
      "727:\tlearn: 0.1057137\ttest: 0.4896312\tbest: 0.4637402 (236)\ttotal: 2.7s\tremaining: 1.49s\n",
      "728:\tlearn: 0.1055535\ttest: 0.4898119\tbest: 0.4637402 (236)\ttotal: 2.71s\tremaining: 1.48s\n",
      "729:\tlearn: 0.1053304\ttest: 0.4900293\tbest: 0.4637402 (236)\ttotal: 2.71s\tremaining: 1.48s\n",
      "730:\tlearn: 0.1051454\ttest: 0.4900636\tbest: 0.4637402 (236)\ttotal: 2.71s\tremaining: 1.47s\n",
      "731:\tlearn: 0.1049264\ttest: 0.4899302\tbest: 0.4637402 (236)\ttotal: 2.72s\tremaining: 1.47s\n",
      "732:\tlearn: 0.1047105\ttest: 0.4899856\tbest: 0.4637402 (236)\ttotal: 2.72s\tremaining: 1.47s\n",
      "733:\tlearn: 0.1045404\ttest: 0.4901203\tbest: 0.4637402 (236)\ttotal: 2.73s\tremaining: 1.46s\n",
      "734:\tlearn: 0.1043604\ttest: 0.4899875\tbest: 0.4637402 (236)\ttotal: 2.73s\tremaining: 1.46s\n",
      "735:\tlearn: 0.1042635\ttest: 0.4899972\tbest: 0.4637402 (236)\ttotal: 2.73s\tremaining: 1.46s\n",
      "736:\tlearn: 0.1040174\ttest: 0.4902010\tbest: 0.4637402 (236)\ttotal: 2.73s\tremaining: 1.45s\n",
      "737:\tlearn: 0.1038627\ttest: 0.4903369\tbest: 0.4637402 (236)\ttotal: 2.74s\tremaining: 1.45s\n",
      "738:\tlearn: 0.1036683\ttest: 0.4903674\tbest: 0.4637402 (236)\ttotal: 2.74s\tremaining: 1.44s\n",
      "739:\tlearn: 0.1034783\ttest: 0.4903077\tbest: 0.4637402 (236)\ttotal: 2.75s\tremaining: 1.44s\n",
      "740:\tlearn: 0.1033228\ttest: 0.4905052\tbest: 0.4637402 (236)\ttotal: 2.75s\tremaining: 1.44s\n",
      "741:\tlearn: 0.1032152\ttest: 0.4906376\tbest: 0.4637402 (236)\ttotal: 2.75s\tremaining: 1.43s\n",
      "742:\tlearn: 0.1030496\ttest: 0.4905597\tbest: 0.4637402 (236)\ttotal: 2.75s\tremaining: 1.43s\n",
      "743:\tlearn: 0.1028295\ttest: 0.4908146\tbest: 0.4637402 (236)\ttotal: 2.76s\tremaining: 1.42s\n",
      "744:\tlearn: 0.1027069\ttest: 0.4909922\tbest: 0.4637402 (236)\ttotal: 2.76s\tremaining: 1.42s\n",
      "745:\tlearn: 0.1026205\ttest: 0.4910427\tbest: 0.4637402 (236)\ttotal: 2.77s\tremaining: 1.42s\n",
      "746:\tlearn: 0.1024985\ttest: 0.4910420\tbest: 0.4637402 (236)\ttotal: 2.77s\tremaining: 1.41s\n",
      "747:\tlearn: 0.1023888\ttest: 0.4909507\tbest: 0.4637402 (236)\ttotal: 2.77s\tremaining: 1.41s\n",
      "748:\tlearn: 0.1022509\ttest: 0.4910337\tbest: 0.4637402 (236)\ttotal: 2.77s\tremaining: 1.4s\n",
      "749:\tlearn: 0.1020853\ttest: 0.4909354\tbest: 0.4637402 (236)\ttotal: 2.78s\tremaining: 1.4s\n",
      "750:\tlearn: 0.1018825\ttest: 0.4908633\tbest: 0.4637402 (236)\ttotal: 2.78s\tremaining: 1.4s\n",
      "751:\tlearn: 0.1017291\ttest: 0.4907926\tbest: 0.4637402 (236)\ttotal: 2.79s\tremaining: 1.39s\n",
      "752:\tlearn: 0.1015552\ttest: 0.4907239\tbest: 0.4637402 (236)\ttotal: 2.79s\tremaining: 1.39s\n",
      "753:\tlearn: 0.1013917\ttest: 0.4907402\tbest: 0.4637402 (236)\ttotal: 2.79s\tremaining: 1.39s\n",
      "754:\tlearn: 0.1012333\ttest: 0.4908070\tbest: 0.4637402 (236)\ttotal: 2.79s\tremaining: 1.38s\n",
      "755:\tlearn: 0.1010788\ttest: 0.4907859\tbest: 0.4637402 (236)\ttotal: 2.8s\tremaining: 1.38s\n",
      "756:\tlearn: 0.1009117\ttest: 0.4907915\tbest: 0.4637402 (236)\ttotal: 2.8s\tremaining: 1.37s\n",
      "757:\tlearn: 0.1008368\ttest: 0.4908411\tbest: 0.4637402 (236)\ttotal: 2.81s\tremaining: 1.37s\n",
      "758:\tlearn: 0.1006838\ttest: 0.4908620\tbest: 0.4637402 (236)\ttotal: 2.81s\tremaining: 1.36s\n",
      "759:\tlearn: 0.1005930\ttest: 0.4908674\tbest: 0.4637402 (236)\ttotal: 2.81s\tremaining: 1.36s\n",
      "760:\tlearn: 0.1004725\ttest: 0.4907495\tbest: 0.4637402 (236)\ttotal: 2.81s\tremaining: 1.36s\n",
      "761:\tlearn: 0.1003032\ttest: 0.4907027\tbest: 0.4637402 (236)\ttotal: 2.82s\tremaining: 1.35s\n",
      "762:\tlearn: 0.1001609\ttest: 0.4908368\tbest: 0.4637402 (236)\ttotal: 2.82s\tremaining: 1.35s\n",
      "763:\tlearn: 0.1000047\ttest: 0.4909824\tbest: 0.4637402 (236)\ttotal: 2.83s\tremaining: 1.35s\n",
      "764:\tlearn: 0.0999062\ttest: 0.4910526\tbest: 0.4637402 (236)\ttotal: 2.83s\tremaining: 1.34s\n",
      "765:\tlearn: 0.0997594\ttest: 0.4910355\tbest: 0.4637402 (236)\ttotal: 2.83s\tremaining: 1.34s\n",
      "766:\tlearn: 0.0995837\ttest: 0.4911561\tbest: 0.4637402 (236)\ttotal: 2.83s\tremaining: 1.33s\n",
      "767:\tlearn: 0.0993949\ttest: 0.4912601\tbest: 0.4637402 (236)\ttotal: 2.84s\tremaining: 1.33s\n",
      "768:\tlearn: 0.0992821\ttest: 0.4913388\tbest: 0.4637402 (236)\ttotal: 2.84s\tremaining: 1.33s\n",
      "769:\tlearn: 0.0990708\ttest: 0.4913602\tbest: 0.4637402 (236)\ttotal: 2.85s\tremaining: 1.32s\n",
      "770:\tlearn: 0.0989424\ttest: 0.4914420\tbest: 0.4637402 (236)\ttotal: 2.85s\tremaining: 1.32s\n",
      "771:\tlearn: 0.0988046\ttest: 0.4915409\tbest: 0.4637402 (236)\ttotal: 2.85s\tremaining: 1.31s\n",
      "772:\tlearn: 0.0986893\ttest: 0.4916893\tbest: 0.4637402 (236)\ttotal: 2.85s\tremaining: 1.31s\n",
      "773:\tlearn: 0.0985866\ttest: 0.4916644\tbest: 0.4637402 (236)\ttotal: 2.86s\tremaining: 1.31s\n",
      "774:\tlearn: 0.0984439\ttest: 0.4917617\tbest: 0.4637402 (236)\ttotal: 2.86s\tremaining: 1.3s\n",
      "775:\tlearn: 0.0982912\ttest: 0.4917700\tbest: 0.4637402 (236)\ttotal: 2.86s\tremaining: 1.3s\n",
      "776:\tlearn: 0.0981108\ttest: 0.4918150\tbest: 0.4637402 (236)\ttotal: 2.87s\tremaining: 1.29s\n",
      "777:\tlearn: 0.0979577\ttest: 0.4919776\tbest: 0.4637402 (236)\ttotal: 2.87s\tremaining: 1.29s\n",
      "778:\tlearn: 0.0976859\ttest: 0.4920445\tbest: 0.4637402 (236)\ttotal: 2.88s\tremaining: 1.29s\n",
      "779:\tlearn: 0.0975098\ttest: 0.4922628\tbest: 0.4637402 (236)\ttotal: 2.88s\tremaining: 1.28s\n",
      "780:\tlearn: 0.0973306\ttest: 0.4920860\tbest: 0.4637402 (236)\ttotal: 2.88s\tremaining: 1.28s\n",
      "781:\tlearn: 0.0972045\ttest: 0.4920359\tbest: 0.4637402 (236)\ttotal: 2.88s\tremaining: 1.28s\n",
      "782:\tlearn: 0.0970779\ttest: 0.4920739\tbest: 0.4637402 (236)\ttotal: 2.89s\tremaining: 1.27s\n",
      "783:\tlearn: 0.0969444\ttest: 0.4919586\tbest: 0.4637402 (236)\ttotal: 2.89s\tremaining: 1.27s\n",
      "784:\tlearn: 0.0967325\ttest: 0.4922676\tbest: 0.4637402 (236)\ttotal: 2.9s\tremaining: 1.26s\n",
      "785:\tlearn: 0.0965846\ttest: 0.4924296\tbest: 0.4637402 (236)\ttotal: 2.9s\tremaining: 1.26s\n",
      "786:\tlearn: 0.0963968\ttest: 0.4926031\tbest: 0.4637402 (236)\ttotal: 2.9s\tremaining: 1.26s\n",
      "787:\tlearn: 0.0962128\ttest: 0.4927154\tbest: 0.4637402 (236)\ttotal: 2.9s\tremaining: 1.25s\n",
      "788:\tlearn: 0.0960039\ttest: 0.4929320\tbest: 0.4637402 (236)\ttotal: 2.91s\tremaining: 1.25s\n",
      "789:\tlearn: 0.0958793\ttest: 0.4928805\tbest: 0.4637402 (236)\ttotal: 2.91s\tremaining: 1.25s\n",
      "790:\tlearn: 0.0957448\ttest: 0.4929019\tbest: 0.4637402 (236)\ttotal: 2.92s\tremaining: 1.24s\n",
      "791:\tlearn: 0.0956674\ttest: 0.4928780\tbest: 0.4637402 (236)\ttotal: 2.92s\tremaining: 1.24s\n",
      "792:\tlearn: 0.0955484\ttest: 0.4929468\tbest: 0.4637402 (236)\ttotal: 2.92s\tremaining: 1.24s\n",
      "793:\tlearn: 0.0954141\ttest: 0.4928182\tbest: 0.4637402 (236)\ttotal: 2.93s\tremaining: 1.23s\n",
      "794:\tlearn: 0.0952561\ttest: 0.4926852\tbest: 0.4637402 (236)\ttotal: 2.93s\tremaining: 1.23s\n",
      "795:\tlearn: 0.0951442\ttest: 0.4928387\tbest: 0.4637402 (236)\ttotal: 2.93s\tremaining: 1.22s\n",
      "796:\tlearn: 0.0950163\ttest: 0.4929398\tbest: 0.4637402 (236)\ttotal: 2.94s\tremaining: 1.22s\n",
      "797:\tlearn: 0.0949197\ttest: 0.4930003\tbest: 0.4637402 (236)\ttotal: 2.94s\tremaining: 1.22s\n",
      "798:\tlearn: 0.0948418\ttest: 0.4930752\tbest: 0.4637402 (236)\ttotal: 2.94s\tremaining: 1.21s\n",
      "799:\tlearn: 0.0946791\ttest: 0.4931446\tbest: 0.4637402 (236)\ttotal: 2.95s\tremaining: 1.21s\n",
      "800:\tlearn: 0.0945508\ttest: 0.4932026\tbest: 0.4637402 (236)\ttotal: 2.95s\tremaining: 1.21s\n",
      "801:\tlearn: 0.0944417\ttest: 0.4931280\tbest: 0.4637402 (236)\ttotal: 2.96s\tremaining: 1.2s\n",
      "802:\tlearn: 0.0942366\ttest: 0.4933130\tbest: 0.4637402 (236)\ttotal: 2.96s\tremaining: 1.2s\n",
      "803:\tlearn: 0.0941263\ttest: 0.4933000\tbest: 0.4637402 (236)\ttotal: 2.96s\tremaining: 1.19s\n",
      "804:\tlearn: 0.0940432\ttest: 0.4934188\tbest: 0.4637402 (236)\ttotal: 2.96s\tremaining: 1.19s\n",
      "805:\tlearn: 0.0939262\ttest: 0.4933735\tbest: 0.4637402 (236)\ttotal: 2.97s\tremaining: 1.19s\n",
      "806:\tlearn: 0.0938141\ttest: 0.4934778\tbest: 0.4637402 (236)\ttotal: 2.97s\tremaining: 1.18s\n",
      "807:\tlearn: 0.0936532\ttest: 0.4934197\tbest: 0.4637402 (236)\ttotal: 2.98s\tremaining: 1.18s\n",
      "808:\tlearn: 0.0935442\ttest: 0.4933863\tbest: 0.4637402 (236)\ttotal: 2.98s\tremaining: 1.17s\n",
      "809:\tlearn: 0.0934029\ttest: 0.4936642\tbest: 0.4637402 (236)\ttotal: 2.98s\tremaining: 1.17s\n",
      "810:\tlearn: 0.0932835\ttest: 0.4937071\tbest: 0.4637402 (236)\ttotal: 2.99s\tremaining: 1.17s\n",
      "811:\tlearn: 0.0931588\ttest: 0.4939857\tbest: 0.4637402 (236)\ttotal: 2.99s\tremaining: 1.16s\n",
      "812:\tlearn: 0.0930207\ttest: 0.4941584\tbest: 0.4637402 (236)\ttotal: 2.99s\tremaining: 1.16s\n",
      "813:\tlearn: 0.0928847\ttest: 0.4943203\tbest: 0.4637402 (236)\ttotal: 3s\tremaining: 1.16s\n",
      "814:\tlearn: 0.0927130\ttest: 0.4942842\tbest: 0.4637402 (236)\ttotal: 3s\tremaining: 1.15s\n",
      "815:\tlearn: 0.0925691\ttest: 0.4945293\tbest: 0.4637402 (236)\ttotal: 3s\tremaining: 1.15s\n",
      "816:\tlearn: 0.0924601\ttest: 0.4947005\tbest: 0.4637402 (236)\ttotal: 3s\tremaining: 1.14s\n",
      "817:\tlearn: 0.0923062\ttest: 0.4949105\tbest: 0.4637402 (236)\ttotal: 3.01s\tremaining: 1.14s\n",
      "818:\tlearn: 0.0921144\ttest: 0.4952230\tbest: 0.4637402 (236)\ttotal: 3.01s\tremaining: 1.14s\n",
      "819:\tlearn: 0.0920101\ttest: 0.4952332\tbest: 0.4637402 (236)\ttotal: 3.02s\tremaining: 1.13s\n",
      "820:\tlearn: 0.0918739\ttest: 0.4953256\tbest: 0.4637402 (236)\ttotal: 3.02s\tremaining: 1.13s\n",
      "821:\tlearn: 0.0917295\ttest: 0.4953490\tbest: 0.4637402 (236)\ttotal: 3.02s\tremaining: 1.13s\n",
      "822:\tlearn: 0.0915948\ttest: 0.4953912\tbest: 0.4637402 (236)\ttotal: 3.02s\tremaining: 1.12s\n",
      "823:\tlearn: 0.0914357\ttest: 0.4953942\tbest: 0.4637402 (236)\ttotal: 3.03s\tremaining: 1.12s\n",
      "824:\tlearn: 0.0913282\ttest: 0.4954363\tbest: 0.4637402 (236)\ttotal: 3.03s\tremaining: 1.11s\n",
      "825:\tlearn: 0.0911883\ttest: 0.4955987\tbest: 0.4637402 (236)\ttotal: 3.04s\tremaining: 1.11s\n",
      "826:\tlearn: 0.0910141\ttest: 0.4954314\tbest: 0.4637402 (236)\ttotal: 3.04s\tremaining: 1.1s\n",
      "827:\tlearn: 0.0909318\ttest: 0.4953730\tbest: 0.4637402 (236)\ttotal: 3.04s\tremaining: 1.1s\n",
      "828:\tlearn: 0.0907288\ttest: 0.4956531\tbest: 0.4637402 (236)\ttotal: 3.04s\tremaining: 1.1s\n",
      "829:\tlearn: 0.0905951\ttest: 0.4956605\tbest: 0.4637402 (236)\ttotal: 3.05s\tremaining: 1.09s\n",
      "830:\tlearn: 0.0904630\ttest: 0.4957764\tbest: 0.4637402 (236)\ttotal: 3.05s\tremaining: 1.09s\n",
      "831:\tlearn: 0.0903405\ttest: 0.4959703\tbest: 0.4637402 (236)\ttotal: 3.05s\tremaining: 1.09s\n",
      "832:\tlearn: 0.0901710\ttest: 0.4962958\tbest: 0.4637402 (236)\ttotal: 3.06s\tremaining: 1.08s\n",
      "833:\tlearn: 0.0900829\ttest: 0.4962991\tbest: 0.4637402 (236)\ttotal: 3.06s\tremaining: 1.08s\n",
      "834:\tlearn: 0.0899658\ttest: 0.4963837\tbest: 0.4637402 (236)\ttotal: 3.06s\tremaining: 1.07s\n",
      "835:\tlearn: 0.0898419\ttest: 0.4963659\tbest: 0.4637402 (236)\ttotal: 3.07s\tremaining: 1.07s\n",
      "836:\tlearn: 0.0896886\ttest: 0.4963502\tbest: 0.4637402 (236)\ttotal: 3.07s\tremaining: 1.07s\n",
      "837:\tlearn: 0.0895508\ttest: 0.4965542\tbest: 0.4637402 (236)\ttotal: 3.07s\tremaining: 1.06s\n",
      "838:\tlearn: 0.0893919\ttest: 0.4964903\tbest: 0.4637402 (236)\ttotal: 3.08s\tremaining: 1.06s\n",
      "839:\tlearn: 0.0891625\ttest: 0.4966157\tbest: 0.4637402 (236)\ttotal: 3.08s\tremaining: 1.06s\n",
      "840:\tlearn: 0.0890569\ttest: 0.4966011\tbest: 0.4637402 (236)\ttotal: 3.08s\tremaining: 1.05s\n",
      "841:\tlearn: 0.0888873\ttest: 0.4968539\tbest: 0.4637402 (236)\ttotal: 3.09s\tremaining: 1.05s\n",
      "842:\tlearn: 0.0886965\ttest: 0.4970467\tbest: 0.4637402 (236)\ttotal: 3.09s\tremaining: 1.04s\n",
      "843:\tlearn: 0.0885945\ttest: 0.4972496\tbest: 0.4637402 (236)\ttotal: 3.09s\tremaining: 1.04s\n",
      "844:\tlearn: 0.0885076\ttest: 0.4972379\tbest: 0.4637402 (236)\ttotal: 3.1s\tremaining: 1.04s\n",
      "845:\tlearn: 0.0883210\ttest: 0.4971022\tbest: 0.4637402 (236)\ttotal: 3.1s\tremaining: 1.03s\n",
      "846:\tlearn: 0.0882358\ttest: 0.4971176\tbest: 0.4637402 (236)\ttotal: 3.1s\tremaining: 1.03s\n",
      "847:\tlearn: 0.0881438\ttest: 0.4972031\tbest: 0.4637402 (236)\ttotal: 3.11s\tremaining: 1.03s\n",
      "848:\tlearn: 0.0879445\ttest: 0.4974827\tbest: 0.4637402 (236)\ttotal: 3.11s\tremaining: 1.02s\n",
      "849:\tlearn: 0.0878233\ttest: 0.4974106\tbest: 0.4637402 (236)\ttotal: 3.12s\tremaining: 1.02s\n",
      "850:\tlearn: 0.0877005\ttest: 0.4975849\tbest: 0.4637402 (236)\ttotal: 3.12s\tremaining: 1.01s\n",
      "851:\tlearn: 0.0875150\ttest: 0.4976170\tbest: 0.4637402 (236)\ttotal: 3.12s\tremaining: 1.01s\n",
      "852:\tlearn: 0.0874079\ttest: 0.4975486\tbest: 0.4637402 (236)\ttotal: 3.13s\tremaining: 1.01s\n",
      "853:\tlearn: 0.0873280\ttest: 0.4975196\tbest: 0.4637402 (236)\ttotal: 3.13s\tremaining: 1s\n",
      "854:\tlearn: 0.0871440\ttest: 0.4977476\tbest: 0.4637402 (236)\ttotal: 3.13s\tremaining: 1s\n",
      "855:\tlearn: 0.0870435\ttest: 0.4977744\tbest: 0.4637402 (236)\ttotal: 3.14s\tremaining: 997ms\n",
      "856:\tlearn: 0.0869261\ttest: 0.4977139\tbest: 0.4637402 (236)\ttotal: 3.14s\tremaining: 993ms\n",
      "857:\tlearn: 0.0867929\ttest: 0.4977120\tbest: 0.4637402 (236)\ttotal: 3.14s\tremaining: 989ms\n",
      "858:\tlearn: 0.0866748\ttest: 0.4978500\tbest: 0.4637402 (236)\ttotal: 3.15s\tremaining: 986ms\n",
      "859:\tlearn: 0.0864947\ttest: 0.4980295\tbest: 0.4637402 (236)\ttotal: 3.15s\tremaining: 982ms\n",
      "860:\tlearn: 0.0863425\ttest: 0.4981417\tbest: 0.4637402 (236)\ttotal: 3.15s\tremaining: 978ms\n",
      "861:\tlearn: 0.0862073\ttest: 0.4981896\tbest: 0.4637402 (236)\ttotal: 3.16s\tremaining: 974ms\n",
      "862:\tlearn: 0.0860778\ttest: 0.4985420\tbest: 0.4637402 (236)\ttotal: 3.16s\tremaining: 970ms\n",
      "863:\tlearn: 0.0859487\ttest: 0.4986706\tbest: 0.4637402 (236)\ttotal: 3.16s\tremaining: 967ms\n",
      "864:\tlearn: 0.0858512\ttest: 0.4987317\tbest: 0.4637402 (236)\ttotal: 3.17s\tremaining: 963ms\n",
      "865:\tlearn: 0.0857131\ttest: 0.4987359\tbest: 0.4637402 (236)\ttotal: 3.17s\tremaining: 959ms\n",
      "866:\tlearn: 0.0856159\ttest: 0.4988615\tbest: 0.4637402 (236)\ttotal: 3.17s\tremaining: 955ms\n",
      "867:\tlearn: 0.0854467\ttest: 0.4990301\tbest: 0.4637402 (236)\ttotal: 3.18s\tremaining: 952ms\n",
      "868:\tlearn: 0.0852254\ttest: 0.4992037\tbest: 0.4637402 (236)\ttotal: 3.18s\tremaining: 948ms\n",
      "869:\tlearn: 0.0850756\ttest: 0.4994174\tbest: 0.4637402 (236)\ttotal: 3.18s\tremaining: 944ms\n",
      "870:\tlearn: 0.0849379\ttest: 0.4993740\tbest: 0.4637402 (236)\ttotal: 3.19s\tremaining: 940ms\n",
      "871:\tlearn: 0.0848587\ttest: 0.4992971\tbest: 0.4637402 (236)\ttotal: 3.19s\tremaining: 936ms\n",
      "872:\tlearn: 0.0847566\ttest: 0.4994938\tbest: 0.4637402 (236)\ttotal: 3.19s\tremaining: 933ms\n",
      "873:\tlearn: 0.0846096\ttest: 0.4997601\tbest: 0.4637402 (236)\ttotal: 3.2s\tremaining: 929ms\n",
      "874:\tlearn: 0.0845212\ttest: 0.4997984\tbest: 0.4637402 (236)\ttotal: 3.2s\tremaining: 925ms\n",
      "875:\tlearn: 0.0844032\ttest: 0.4999492\tbest: 0.4637402 (236)\ttotal: 3.2s\tremaining: 921ms\n",
      "876:\tlearn: 0.0842401\ttest: 0.4999413\tbest: 0.4637402 (236)\ttotal: 3.21s\tremaining: 918ms\n",
      "877:\tlearn: 0.0841235\ttest: 0.5000115\tbest: 0.4637402 (236)\ttotal: 3.21s\tremaining: 914ms\n",
      "878:\tlearn: 0.0839667\ttest: 0.5005108\tbest: 0.4637402 (236)\ttotal: 3.21s\tremaining: 910ms\n",
      "879:\tlearn: 0.0838715\ttest: 0.5006216\tbest: 0.4637402 (236)\ttotal: 3.22s\tremaining: 907ms\n",
      "880:\tlearn: 0.0837370\ttest: 0.5007222\tbest: 0.4637402 (236)\ttotal: 3.22s\tremaining: 903ms\n",
      "881:\tlearn: 0.0836328\ttest: 0.5009003\tbest: 0.4637402 (236)\ttotal: 3.22s\tremaining: 899ms\n",
      "882:\tlearn: 0.0834725\ttest: 0.5008261\tbest: 0.4637402 (236)\ttotal: 3.23s\tremaining: 895ms\n",
      "883:\tlearn: 0.0833340\ttest: 0.5010462\tbest: 0.4637402 (236)\ttotal: 3.23s\tremaining: 891ms\n",
      "884:\tlearn: 0.0831390\ttest: 0.5012971\tbest: 0.4637402 (236)\ttotal: 3.23s\tremaining: 888ms\n",
      "885:\tlearn: 0.0830023\ttest: 0.5013391\tbest: 0.4637402 (236)\ttotal: 3.24s\tremaining: 884ms\n",
      "886:\tlearn: 0.0828833\ttest: 0.5012757\tbest: 0.4637402 (236)\ttotal: 3.24s\tremaining: 880ms\n",
      "887:\tlearn: 0.0827596\ttest: 0.5015233\tbest: 0.4637402 (236)\ttotal: 3.24s\tremaining: 877ms\n",
      "888:\tlearn: 0.0826499\ttest: 0.5016034\tbest: 0.4637402 (236)\ttotal: 3.25s\tremaining: 873ms\n",
      "889:\tlearn: 0.0825389\ttest: 0.5017773\tbest: 0.4637402 (236)\ttotal: 3.25s\tremaining: 869ms\n",
      "890:\tlearn: 0.0823994\ttest: 0.5019229\tbest: 0.4637402 (236)\ttotal: 3.25s\tremaining: 865ms\n",
      "891:\tlearn: 0.0822459\ttest: 0.5020577\tbest: 0.4637402 (236)\ttotal: 3.26s\tremaining: 862ms\n",
      "892:\tlearn: 0.0821417\ttest: 0.5021105\tbest: 0.4637402 (236)\ttotal: 3.26s\tremaining: 858ms\n",
      "893:\tlearn: 0.0820356\ttest: 0.5022214\tbest: 0.4637402 (236)\ttotal: 3.26s\tremaining: 854ms\n",
      "894:\tlearn: 0.0818739\ttest: 0.5022467\tbest: 0.4637402 (236)\ttotal: 3.27s\tremaining: 850ms\n",
      "895:\tlearn: 0.0817230\ttest: 0.5022992\tbest: 0.4637402 (236)\ttotal: 3.27s\tremaining: 847ms\n",
      "896:\tlearn: 0.0815853\ttest: 0.5025393\tbest: 0.4637402 (236)\ttotal: 3.27s\tremaining: 843ms\n",
      "897:\tlearn: 0.0814706\ttest: 0.5025404\tbest: 0.4637402 (236)\ttotal: 3.28s\tremaining: 839ms\n",
      "898:\tlearn: 0.0813375\ttest: 0.5025224\tbest: 0.4637402 (236)\ttotal: 3.28s\tremaining: 835ms\n",
      "899:\tlearn: 0.0811808\ttest: 0.5023641\tbest: 0.4637402 (236)\ttotal: 3.28s\tremaining: 832ms\n",
      "900:\tlearn: 0.0810653\ttest: 0.5025491\tbest: 0.4637402 (236)\ttotal: 3.29s\tremaining: 828ms\n",
      "901:\tlearn: 0.0809859\ttest: 0.5024841\tbest: 0.4637402 (236)\ttotal: 3.29s\tremaining: 824ms\n",
      "902:\tlearn: 0.0807916\ttest: 0.5025949\tbest: 0.4637402 (236)\ttotal: 3.29s\tremaining: 821ms\n",
      "903:\tlearn: 0.0806491\ttest: 0.5026577\tbest: 0.4637402 (236)\ttotal: 3.3s\tremaining: 817ms\n",
      "904:\tlearn: 0.0804850\ttest: 0.5026074\tbest: 0.4637402 (236)\ttotal: 3.3s\tremaining: 813ms\n",
      "905:\tlearn: 0.0803633\ttest: 0.5027116\tbest: 0.4637402 (236)\ttotal: 3.3s\tremaining: 809ms\n",
      "906:\tlearn: 0.0801810\ttest: 0.5029644\tbest: 0.4637402 (236)\ttotal: 3.31s\tremaining: 806ms\n",
      "907:\tlearn: 0.0800531\ttest: 0.5029251\tbest: 0.4637402 (236)\ttotal: 3.31s\tremaining: 802ms\n",
      "908:\tlearn: 0.0799276\ttest: 0.5028804\tbest: 0.4637402 (236)\ttotal: 3.31s\tremaining: 799ms\n",
      "909:\tlearn: 0.0797704\ttest: 0.5033582\tbest: 0.4637402 (236)\ttotal: 3.32s\tremaining: 795ms\n",
      "910:\tlearn: 0.0796857\ttest: 0.5033882\tbest: 0.4637402 (236)\ttotal: 3.32s\tremaining: 791ms\n",
      "911:\tlearn: 0.0795466\ttest: 0.5035703\tbest: 0.4637402 (236)\ttotal: 3.33s\tremaining: 788ms\n",
      "912:\tlearn: 0.0793898\ttest: 0.5035234\tbest: 0.4637402 (236)\ttotal: 3.33s\tremaining: 784ms\n",
      "913:\tlearn: 0.0793106\ttest: 0.5034894\tbest: 0.4637402 (236)\ttotal: 3.33s\tremaining: 780ms\n",
      "914:\tlearn: 0.0792427\ttest: 0.5035140\tbest: 0.4637402 (236)\ttotal: 3.33s\tremaining: 776ms\n",
      "915:\tlearn: 0.0791465\ttest: 0.5034802\tbest: 0.4637402 (236)\ttotal: 3.34s\tremaining: 773ms\n",
      "916:\tlearn: 0.0790524\ttest: 0.5034500\tbest: 0.4637402 (236)\ttotal: 3.34s\tremaining: 769ms\n",
      "917:\tlearn: 0.0788733\ttest: 0.5032142\tbest: 0.4637402 (236)\ttotal: 3.35s\tremaining: 765ms\n",
      "918:\tlearn: 0.0787475\ttest: 0.5033041\tbest: 0.4637402 (236)\ttotal: 3.35s\tremaining: 762ms\n",
      "919:\tlearn: 0.0786322\ttest: 0.5035550\tbest: 0.4637402 (236)\ttotal: 3.35s\tremaining: 758ms\n",
      "920:\tlearn: 0.0785282\ttest: 0.5037897\tbest: 0.4637402 (236)\ttotal: 3.36s\tremaining: 755ms\n",
      "921:\tlearn: 0.0784212\ttest: 0.5038354\tbest: 0.4637402 (236)\ttotal: 3.36s\tremaining: 751ms\n",
      "922:\tlearn: 0.0782254\ttest: 0.5040139\tbest: 0.4637402 (236)\ttotal: 3.36s\tremaining: 747ms\n",
      "923:\tlearn: 0.0781349\ttest: 0.5040097\tbest: 0.4637402 (236)\ttotal: 3.37s\tremaining: 744ms\n",
      "924:\tlearn: 0.0780514\ttest: 0.5040613\tbest: 0.4637402 (236)\ttotal: 3.37s\tremaining: 740ms\n",
      "925:\tlearn: 0.0778607\ttest: 0.5041864\tbest: 0.4637402 (236)\ttotal: 3.37s\tremaining: 736ms\n",
      "926:\tlearn: 0.0777182\ttest: 0.5043583\tbest: 0.4637402 (236)\ttotal: 3.38s\tremaining: 732ms\n",
      "927:\tlearn: 0.0775865\ttest: 0.5044109\tbest: 0.4637402 (236)\ttotal: 3.38s\tremaining: 729ms\n",
      "928:\tlearn: 0.0774827\ttest: 0.5046474\tbest: 0.4637402 (236)\ttotal: 3.38s\tremaining: 725ms\n",
      "929:\tlearn: 0.0773802\ttest: 0.5047488\tbest: 0.4637402 (236)\ttotal: 3.39s\tremaining: 721ms\n",
      "930:\tlearn: 0.0772630\ttest: 0.5048587\tbest: 0.4637402 (236)\ttotal: 3.39s\tremaining: 718ms\n",
      "931:\tlearn: 0.0772017\ttest: 0.5048788\tbest: 0.4637402 (236)\ttotal: 3.39s\tremaining: 714ms\n",
      "932:\tlearn: 0.0771033\ttest: 0.5048240\tbest: 0.4637402 (236)\ttotal: 3.4s\tremaining: 710ms\n",
      "933:\tlearn: 0.0769674\ttest: 0.5051679\tbest: 0.4637402 (236)\ttotal: 3.4s\tremaining: 706ms\n",
      "934:\tlearn: 0.0768426\ttest: 0.5053082\tbest: 0.4637402 (236)\ttotal: 3.4s\tremaining: 703ms\n",
      "935:\tlearn: 0.0767562\ttest: 0.5053045\tbest: 0.4637402 (236)\ttotal: 3.41s\tremaining: 699ms\n",
      "936:\tlearn: 0.0766588\ttest: 0.5054129\tbest: 0.4637402 (236)\ttotal: 3.41s\tremaining: 695ms\n",
      "937:\tlearn: 0.0765746\ttest: 0.5054107\tbest: 0.4637402 (236)\ttotal: 3.42s\tremaining: 692ms\n",
      "938:\tlearn: 0.0764948\ttest: 0.5055481\tbest: 0.4637402 (236)\ttotal: 3.42s\tremaining: 688ms\n",
      "939:\tlearn: 0.0763261\ttest: 0.5055363\tbest: 0.4637402 (236)\ttotal: 3.42s\tremaining: 684ms\n",
      "940:\tlearn: 0.0761730\ttest: 0.5055641\tbest: 0.4637402 (236)\ttotal: 3.42s\tremaining: 681ms\n",
      "941:\tlearn: 0.0760378\ttest: 0.5057372\tbest: 0.4637402 (236)\ttotal: 3.43s\tremaining: 677ms\n",
      "942:\tlearn: 0.0759004\ttest: 0.5058518\tbest: 0.4637402 (236)\ttotal: 3.43s\tremaining: 673ms\n",
      "943:\tlearn: 0.0758007\ttest: 0.5058783\tbest: 0.4637402 (236)\ttotal: 3.44s\tremaining: 670ms\n",
      "944:\tlearn: 0.0756903\ttest: 0.5059106\tbest: 0.4637402 (236)\ttotal: 3.44s\tremaining: 666ms\n",
      "945:\tlearn: 0.0755760\ttest: 0.5060889\tbest: 0.4637402 (236)\ttotal: 3.44s\tremaining: 662ms\n",
      "946:\tlearn: 0.0754428\ttest: 0.5061849\tbest: 0.4637402 (236)\ttotal: 3.44s\tremaining: 658ms\n",
      "947:\tlearn: 0.0753322\ttest: 0.5062965\tbest: 0.4637402 (236)\ttotal: 3.45s\tremaining: 655ms\n",
      "948:\tlearn: 0.0751966\ttest: 0.5067245\tbest: 0.4637402 (236)\ttotal: 3.45s\tremaining: 651ms\n",
      "949:\tlearn: 0.0750851\ttest: 0.5066869\tbest: 0.4637402 (236)\ttotal: 3.46s\tremaining: 647ms\n",
      "950:\tlearn: 0.0749943\ttest: 0.5066313\tbest: 0.4637402 (236)\ttotal: 3.46s\tremaining: 644ms\n",
      "951:\tlearn: 0.0749033\ttest: 0.5064443\tbest: 0.4637402 (236)\ttotal: 3.46s\tremaining: 640ms\n",
      "952:\tlearn: 0.0747679\ttest: 0.5064661\tbest: 0.4637402 (236)\ttotal: 3.46s\tremaining: 636ms\n",
      "953:\tlearn: 0.0746524\ttest: 0.5064307\tbest: 0.4637402 (236)\ttotal: 3.47s\tremaining: 633ms\n",
      "954:\tlearn: 0.0745744\ttest: 0.5063806\tbest: 0.4637402 (236)\ttotal: 3.47s\tremaining: 629ms\n",
      "955:\tlearn: 0.0745120\ttest: 0.5063837\tbest: 0.4637402 (236)\ttotal: 3.48s\tremaining: 625ms\n",
      "956:\tlearn: 0.0743823\ttest: 0.5065602\tbest: 0.4637402 (236)\ttotal: 3.48s\tremaining: 622ms\n",
      "957:\tlearn: 0.0742670\ttest: 0.5068562\tbest: 0.4637402 (236)\ttotal: 3.48s\tremaining: 618ms\n",
      "958:\tlearn: 0.0741825\ttest: 0.5069100\tbest: 0.4637402 (236)\ttotal: 3.48s\tremaining: 614ms\n",
      "959:\tlearn: 0.0741006\ttest: 0.5070397\tbest: 0.4637402 (236)\ttotal: 3.49s\tremaining: 611ms\n",
      "960:\tlearn: 0.0740217\ttest: 0.5070425\tbest: 0.4637402 (236)\ttotal: 3.49s\tremaining: 607ms\n",
      "961:\tlearn: 0.0739299\ttest: 0.5071179\tbest: 0.4637402 (236)\ttotal: 3.5s\tremaining: 603ms\n",
      "962:\tlearn: 0.0737514\ttest: 0.5070456\tbest: 0.4637402 (236)\ttotal: 3.5s\tremaining: 600ms\n",
      "963:\tlearn: 0.0736692\ttest: 0.5071010\tbest: 0.4637402 (236)\ttotal: 3.5s\tremaining: 596ms\n",
      "964:\tlearn: 0.0735154\ttest: 0.5073642\tbest: 0.4637402 (236)\ttotal: 3.51s\tremaining: 592ms\n",
      "965:\tlearn: 0.0734070\ttest: 0.5074141\tbest: 0.4637402 (236)\ttotal: 3.51s\tremaining: 589ms\n",
      "966:\tlearn: 0.0732951\ttest: 0.5075265\tbest: 0.4637402 (236)\ttotal: 3.51s\tremaining: 585ms\n",
      "967:\tlearn: 0.0731830\ttest: 0.5075657\tbest: 0.4637402 (236)\ttotal: 3.52s\tremaining: 581ms\n",
      "968:\tlearn: 0.0730535\ttest: 0.5075880\tbest: 0.4637402 (236)\ttotal: 3.52s\tremaining: 578ms\n",
      "969:\tlearn: 0.0729211\ttest: 0.5076461\tbest: 0.4637402 (236)\ttotal: 3.52s\tremaining: 574ms\n",
      "970:\tlearn: 0.0727926\ttest: 0.5077155\tbest: 0.4637402 (236)\ttotal: 3.53s\tremaining: 570ms\n",
      "971:\tlearn: 0.0726777\ttest: 0.5080408\tbest: 0.4637402 (236)\ttotal: 3.53s\tremaining: 567ms\n",
      "972:\tlearn: 0.0725668\ttest: 0.5081087\tbest: 0.4637402 (236)\ttotal: 3.53s\tremaining: 563ms\n",
      "973:\tlearn: 0.0724676\ttest: 0.5082129\tbest: 0.4637402 (236)\ttotal: 3.54s\tremaining: 559ms\n",
      "974:\tlearn: 0.0723745\ttest: 0.5082624\tbest: 0.4637402 (236)\ttotal: 3.54s\tremaining: 556ms\n",
      "975:\tlearn: 0.0722777\ttest: 0.5083346\tbest: 0.4637402 (236)\ttotal: 3.54s\tremaining: 552ms\n",
      "976:\tlearn: 0.0721892\ttest: 0.5081682\tbest: 0.4637402 (236)\ttotal: 3.55s\tremaining: 548ms\n",
      "977:\tlearn: 0.0720725\ttest: 0.5081996\tbest: 0.4637402 (236)\ttotal: 3.55s\tremaining: 544ms\n",
      "978:\tlearn: 0.0719874\ttest: 0.5080215\tbest: 0.4637402 (236)\ttotal: 3.55s\tremaining: 541ms\n",
      "979:\tlearn: 0.0718517\ttest: 0.5079987\tbest: 0.4637402 (236)\ttotal: 3.56s\tremaining: 537ms\n",
      "980:\tlearn: 0.0717483\ttest: 0.5080533\tbest: 0.4637402 (236)\ttotal: 3.56s\tremaining: 533ms\n",
      "981:\tlearn: 0.0716731\ttest: 0.5080616\tbest: 0.4637402 (236)\ttotal: 3.56s\tremaining: 530ms\n",
      "982:\tlearn: 0.0715600\ttest: 0.5083058\tbest: 0.4637402 (236)\ttotal: 3.57s\tremaining: 526ms\n",
      "983:\tlearn: 0.0714115\ttest: 0.5084406\tbest: 0.4637402 (236)\ttotal: 3.57s\tremaining: 522ms\n",
      "984:\tlearn: 0.0713252\ttest: 0.5085174\tbest: 0.4637402 (236)\ttotal: 3.57s\tremaining: 519ms\n",
      "985:\tlearn: 0.0712519\ttest: 0.5085275\tbest: 0.4637402 (236)\ttotal: 3.58s\tremaining: 515ms\n",
      "986:\tlearn: 0.0711447\ttest: 0.5085460\tbest: 0.4637402 (236)\ttotal: 3.58s\tremaining: 511ms\n",
      "987:\tlearn: 0.0710566\ttest: 0.5086139\tbest: 0.4637402 (236)\ttotal: 3.58s\tremaining: 508ms\n",
      "988:\tlearn: 0.0709670\ttest: 0.5084903\tbest: 0.4637402 (236)\ttotal: 3.59s\tremaining: 504ms\n",
      "989:\tlearn: 0.0708232\ttest: 0.5087542\tbest: 0.4637402 (236)\ttotal: 3.59s\tremaining: 500ms\n",
      "990:\tlearn: 0.0707395\ttest: 0.5086603\tbest: 0.4637402 (236)\ttotal: 3.59s\tremaining: 497ms\n",
      "991:\tlearn: 0.0706388\ttest: 0.5086317\tbest: 0.4637402 (236)\ttotal: 3.6s\tremaining: 493ms\n",
      "992:\tlearn: 0.0705004\ttest: 0.5087893\tbest: 0.4637402 (236)\ttotal: 3.6s\tremaining: 489ms\n",
      "993:\tlearn: 0.0703903\ttest: 0.5089703\tbest: 0.4637402 (236)\ttotal: 3.6s\tremaining: 486ms\n",
      "994:\tlearn: 0.0703153\ttest: 0.5090526\tbest: 0.4637402 (236)\ttotal: 3.61s\tremaining: 482ms\n",
      "995:\tlearn: 0.0702334\ttest: 0.5089672\tbest: 0.4637402 (236)\ttotal: 3.61s\tremaining: 478ms\n",
      "996:\tlearn: 0.0701261\ttest: 0.5090892\tbest: 0.4637402 (236)\ttotal: 3.61s\tremaining: 475ms\n",
      "997:\tlearn: 0.0700333\ttest: 0.5092472\tbest: 0.4637402 (236)\ttotal: 3.62s\tremaining: 471ms\n",
      "998:\tlearn: 0.0699705\ttest: 0.5092733\tbest: 0.4637402 (236)\ttotal: 3.62s\tremaining: 467ms\n",
      "999:\tlearn: 0.0698504\ttest: 0.5093334\tbest: 0.4637402 (236)\ttotal: 3.62s\tremaining: 464ms\n",
      "1000:\tlearn: 0.0697487\ttest: 0.5097014\tbest: 0.4637402 (236)\ttotal: 3.63s\tremaining: 460ms\n",
      "1001:\tlearn: 0.0696721\ttest: 0.5097535\tbest: 0.4637402 (236)\ttotal: 3.63s\tremaining: 456ms\n",
      "1002:\tlearn: 0.0695615\ttest: 0.5098110\tbest: 0.4637402 (236)\ttotal: 3.63s\tremaining: 453ms\n",
      "1003:\tlearn: 0.0694500\ttest: 0.5098795\tbest: 0.4637402 (236)\ttotal: 3.64s\tremaining: 449ms\n",
      "1004:\tlearn: 0.0693163\ttest: 0.5099385\tbest: 0.4637402 (236)\ttotal: 3.64s\tremaining: 446ms\n",
      "1005:\tlearn: 0.0692524\ttest: 0.5101729\tbest: 0.4637402 (236)\ttotal: 3.64s\tremaining: 442ms\n",
      "1006:\tlearn: 0.0691337\ttest: 0.5103704\tbest: 0.4637402 (236)\ttotal: 3.65s\tremaining: 438ms\n",
      "1007:\tlearn: 0.0689991\ttest: 0.5104910\tbest: 0.4637402 (236)\ttotal: 3.65s\tremaining: 434ms\n",
      "1008:\tlearn: 0.0689304\ttest: 0.5105031\tbest: 0.4637402 (236)\ttotal: 3.65s\tremaining: 431ms\n",
      "1009:\tlearn: 0.0688344\ttest: 0.5106175\tbest: 0.4637402 (236)\ttotal: 3.66s\tremaining: 427ms\n",
      "1010:\tlearn: 0.0687544\ttest: 0.5106001\tbest: 0.4637402 (236)\ttotal: 3.66s\tremaining: 424ms\n",
      "1011:\tlearn: 0.0686666\ttest: 0.5108626\tbest: 0.4637402 (236)\ttotal: 3.66s\tremaining: 420ms\n",
      "1012:\tlearn: 0.0686026\ttest: 0.5109438\tbest: 0.4637402 (236)\ttotal: 3.67s\tremaining: 416ms\n",
      "1013:\tlearn: 0.0685432\ttest: 0.5109729\tbest: 0.4637402 (236)\ttotal: 3.67s\tremaining: 413ms\n",
      "1014:\tlearn: 0.0684302\ttest: 0.5110475\tbest: 0.4637402 (236)\ttotal: 3.67s\tremaining: 409ms\n",
      "1015:\tlearn: 0.0683481\ttest: 0.5111655\tbest: 0.4637402 (236)\ttotal: 3.68s\tremaining: 405ms\n",
      "1016:\tlearn: 0.0682401\ttest: 0.5112361\tbest: 0.4637402 (236)\ttotal: 3.68s\tremaining: 402ms\n",
      "1017:\tlearn: 0.0681726\ttest: 0.5112513\tbest: 0.4637402 (236)\ttotal: 3.68s\tremaining: 398ms\n",
      "1018:\tlearn: 0.0681132\ttest: 0.5113358\tbest: 0.4637402 (236)\ttotal: 3.69s\tremaining: 394ms\n",
      "1019:\tlearn: 0.0679989\ttest: 0.5115384\tbest: 0.4637402 (236)\ttotal: 3.69s\tremaining: 391ms\n",
      "1020:\tlearn: 0.0678861\ttest: 0.5116290\tbest: 0.4637402 (236)\ttotal: 3.69s\tremaining: 387ms\n",
      "1021:\tlearn: 0.0678001\ttest: 0.5118039\tbest: 0.4637402 (236)\ttotal: 3.7s\tremaining: 383ms\n",
      "1022:\tlearn: 0.0677308\ttest: 0.5118078\tbest: 0.4637402 (236)\ttotal: 3.7s\tremaining: 380ms\n",
      "1023:\tlearn: 0.0676582\ttest: 0.5119572\tbest: 0.4637402 (236)\ttotal: 3.7s\tremaining: 376ms\n",
      "1024:\tlearn: 0.0675483\ttest: 0.5118416\tbest: 0.4637402 (236)\ttotal: 3.71s\tremaining: 373ms\n",
      "1025:\tlearn: 0.0674313\ttest: 0.5119738\tbest: 0.4637402 (236)\ttotal: 3.71s\tremaining: 369ms\n",
      "1026:\tlearn: 0.0673478\ttest: 0.5120573\tbest: 0.4637402 (236)\ttotal: 3.71s\tremaining: 365ms\n",
      "1027:\tlearn: 0.0672457\ttest: 0.5120723\tbest: 0.4637402 (236)\ttotal: 3.72s\tremaining: 362ms\n",
      "1028:\tlearn: 0.0671774\ttest: 0.5121223\tbest: 0.4637402 (236)\ttotal: 3.72s\tremaining: 358ms\n",
      "1029:\tlearn: 0.0670578\ttest: 0.5121819\tbest: 0.4637402 (236)\ttotal: 3.73s\tremaining: 354ms\n",
      "1030:\tlearn: 0.0669818\ttest: 0.5121018\tbest: 0.4637402 (236)\ttotal: 3.73s\tremaining: 351ms\n",
      "1031:\tlearn: 0.0668723\ttest: 0.5121683\tbest: 0.4637402 (236)\ttotal: 3.73s\tremaining: 347ms\n",
      "1032:\tlearn: 0.0667742\ttest: 0.5123060\tbest: 0.4637402 (236)\ttotal: 3.74s\tremaining: 344ms\n",
      "1033:\tlearn: 0.0666494\ttest: 0.5125931\tbest: 0.4637402 (236)\ttotal: 3.74s\tremaining: 340ms\n",
      "1034:\tlearn: 0.0665084\ttest: 0.5126613\tbest: 0.4637402 (236)\ttotal: 3.74s\tremaining: 336ms\n",
      "1035:\tlearn: 0.0663730\ttest: 0.5129277\tbest: 0.4637402 (236)\ttotal: 3.75s\tremaining: 333ms\n",
      "1036:\tlearn: 0.0663191\ttest: 0.5128721\tbest: 0.4637402 (236)\ttotal: 3.75s\tremaining: 329ms\n",
      "1037:\tlearn: 0.0661953\ttest: 0.5128944\tbest: 0.4637402 (236)\ttotal: 3.75s\tremaining: 325ms\n",
      "1038:\tlearn: 0.0661287\ttest: 0.5129005\tbest: 0.4637402 (236)\ttotal: 3.76s\tremaining: 322ms\n",
      "1039:\tlearn: 0.0660499\ttest: 0.5131890\tbest: 0.4637402 (236)\ttotal: 3.76s\tremaining: 318ms\n",
      "1040:\tlearn: 0.0659540\ttest: 0.5132677\tbest: 0.4637402 (236)\ttotal: 3.76s\tremaining: 315ms\n",
      "1041:\tlearn: 0.0658968\ttest: 0.5132948\tbest: 0.4637402 (236)\ttotal: 3.77s\tremaining: 311ms\n",
      "1042:\tlearn: 0.0658235\ttest: 0.5132193\tbest: 0.4637402 (236)\ttotal: 3.77s\tremaining: 307ms\n",
      "1043:\tlearn: 0.0657435\ttest: 0.5131057\tbest: 0.4637402 (236)\ttotal: 3.77s\tremaining: 304ms\n",
      "1044:\tlearn: 0.0656751\ttest: 0.5129606\tbest: 0.4637402 (236)\ttotal: 3.77s\tremaining: 300ms\n",
      "1045:\tlearn: 0.0655954\ttest: 0.5130446\tbest: 0.4637402 (236)\ttotal: 3.78s\tremaining: 296ms\n",
      "1046:\tlearn: 0.0655377\ttest: 0.5131655\tbest: 0.4637402 (236)\ttotal: 3.78s\tremaining: 293ms\n",
      "1047:\tlearn: 0.0654158\ttest: 0.5132931\tbest: 0.4637402 (236)\ttotal: 3.79s\tremaining: 289ms\n",
      "1048:\tlearn: 0.0653277\ttest: 0.5132746\tbest: 0.4637402 (236)\ttotal: 3.79s\tremaining: 285ms\n",
      "1049:\tlearn: 0.0652534\ttest: 0.5136374\tbest: 0.4637402 (236)\ttotal: 3.79s\tremaining: 282ms\n",
      "1050:\tlearn: 0.0651887\ttest: 0.5137998\tbest: 0.4637402 (236)\ttotal: 3.8s\tremaining: 278ms\n",
      "1051:\tlearn: 0.0650856\ttest: 0.5136885\tbest: 0.4637402 (236)\ttotal: 3.8s\tremaining: 274ms\n",
      "1052:\tlearn: 0.0649785\ttest: 0.5138866\tbest: 0.4637402 (236)\ttotal: 3.8s\tremaining: 271ms\n",
      "1053:\tlearn: 0.0648693\ttest: 0.5140245\tbest: 0.4637402 (236)\ttotal: 3.81s\tremaining: 267ms\n",
      "1054:\tlearn: 0.0647882\ttest: 0.5139966\tbest: 0.4637402 (236)\ttotal: 3.81s\tremaining: 264ms\n",
      "1055:\tlearn: 0.0647087\ttest: 0.5142574\tbest: 0.4637402 (236)\ttotal: 3.81s\tremaining: 260ms\n",
      "1056:\tlearn: 0.0646225\ttest: 0.5143235\tbest: 0.4637402 (236)\ttotal: 3.81s\tremaining: 256ms\n",
      "1057:\tlearn: 0.0645414\ttest: 0.5144813\tbest: 0.4637402 (236)\ttotal: 3.82s\tremaining: 253ms\n",
      "1058:\tlearn: 0.0644483\ttest: 0.5145849\tbest: 0.4637402 (236)\ttotal: 3.82s\tremaining: 249ms\n",
      "1059:\tlearn: 0.0643579\ttest: 0.5144709\tbest: 0.4637402 (236)\ttotal: 3.83s\tremaining: 245ms\n",
      "1060:\tlearn: 0.0642953\ttest: 0.5145243\tbest: 0.4637402 (236)\ttotal: 3.83s\tremaining: 242ms\n",
      "1061:\tlearn: 0.0642191\ttest: 0.5146102\tbest: 0.4637402 (236)\ttotal: 3.83s\tremaining: 238ms\n",
      "1062:\tlearn: 0.0641322\ttest: 0.5149524\tbest: 0.4637402 (236)\ttotal: 3.83s\tremaining: 235ms\n",
      "1063:\tlearn: 0.0640751\ttest: 0.5150267\tbest: 0.4637402 (236)\ttotal: 3.84s\tremaining: 231ms\n",
      "1064:\tlearn: 0.0639758\ttest: 0.5152272\tbest: 0.4637402 (236)\ttotal: 3.84s\tremaining: 227ms\n",
      "1065:\tlearn: 0.0638711\ttest: 0.5152931\tbest: 0.4637402 (236)\ttotal: 3.85s\tremaining: 224ms\n",
      "1066:\tlearn: 0.0637719\ttest: 0.5152338\tbest: 0.4637402 (236)\ttotal: 3.85s\tremaining: 220ms\n",
      "1067:\tlearn: 0.0636523\ttest: 0.5153897\tbest: 0.4637402 (236)\ttotal: 3.85s\tremaining: 216ms\n",
      "1068:\tlearn: 0.0635574\ttest: 0.5154638\tbest: 0.4637402 (236)\ttotal: 3.85s\tremaining: 213ms\n",
      "1069:\tlearn: 0.0634952\ttest: 0.5154753\tbest: 0.4637402 (236)\ttotal: 3.86s\tremaining: 209ms\n",
      "1070:\tlearn: 0.0634131\ttest: 0.5157530\tbest: 0.4637402 (236)\ttotal: 3.86s\tremaining: 206ms\n",
      "1071:\tlearn: 0.0633756\ttest: 0.5158234\tbest: 0.4637402 (236)\ttotal: 3.87s\tremaining: 202ms\n",
      "1072:\tlearn: 0.0633369\ttest: 0.5158572\tbest: 0.4637402 (236)\ttotal: 3.87s\tremaining: 198ms\n",
      "1073:\tlearn: 0.0632117\ttest: 0.5161240\tbest: 0.4637402 (236)\ttotal: 3.87s\tremaining: 195ms\n",
      "1074:\tlearn: 0.0631038\ttest: 0.5162812\tbest: 0.4637402 (236)\ttotal: 3.88s\tremaining: 191ms\n",
      "1075:\tlearn: 0.0629816\ttest: 0.5165397\tbest: 0.4637402 (236)\ttotal: 3.88s\tremaining: 187ms\n",
      "1076:\tlearn: 0.0629175\ttest: 0.5166447\tbest: 0.4637402 (236)\ttotal: 3.88s\tremaining: 184ms\n",
      "1077:\tlearn: 0.0628595\ttest: 0.5166669\tbest: 0.4637402 (236)\ttotal: 3.89s\tremaining: 180ms\n",
      "1078:\tlearn: 0.0627648\ttest: 0.5167853\tbest: 0.4637402 (236)\ttotal: 3.89s\tremaining: 177ms\n",
      "1079:\tlearn: 0.0626716\ttest: 0.5169595\tbest: 0.4637402 (236)\ttotal: 3.89s\tremaining: 173ms\n",
      "1080:\tlearn: 0.0626121\ttest: 0.5169721\tbest: 0.4637402 (236)\ttotal: 3.9s\tremaining: 170ms\n",
      "1081:\tlearn: 0.0625248\ttest: 0.5172653\tbest: 0.4637402 (236)\ttotal: 3.9s\tremaining: 166ms\n",
      "1082:\tlearn: 0.0624214\ttest: 0.5173908\tbest: 0.4637402 (236)\ttotal: 3.91s\tremaining: 162ms\n",
      "1083:\tlearn: 0.0623238\ttest: 0.5173995\tbest: 0.4637402 (236)\ttotal: 3.91s\tremaining: 159ms\n",
      "1084:\tlearn: 0.0622521\ttest: 0.5174839\tbest: 0.4637402 (236)\ttotal: 3.91s\tremaining: 155ms\n",
      "1085:\tlearn: 0.0621515\ttest: 0.5178141\tbest: 0.4637402 (236)\ttotal: 3.92s\tremaining: 151ms\n",
      "1086:\tlearn: 0.0620953\ttest: 0.5178646\tbest: 0.4637402 (236)\ttotal: 3.92s\tremaining: 148ms\n",
      "1087:\tlearn: 0.0620029\ttest: 0.5178571\tbest: 0.4637402 (236)\ttotal: 3.92s\tremaining: 144ms\n",
      "1088:\tlearn: 0.0618888\ttest: 0.5178532\tbest: 0.4637402 (236)\ttotal: 3.93s\tremaining: 141ms\n",
      "1089:\tlearn: 0.0618019\ttest: 0.5180654\tbest: 0.4637402 (236)\ttotal: 3.93s\tremaining: 137ms\n",
      "1090:\tlearn: 0.0616829\ttest: 0.5183294\tbest: 0.4637402 (236)\ttotal: 3.93s\tremaining: 133ms\n",
      "1091:\tlearn: 0.0616288\ttest: 0.5181771\tbest: 0.4637402 (236)\ttotal: 3.94s\tremaining: 130ms\n",
      "1092:\tlearn: 0.0615673\ttest: 0.5182251\tbest: 0.4637402 (236)\ttotal: 3.94s\tremaining: 126ms\n",
      "1093:\tlearn: 0.0614652\ttest: 0.5183784\tbest: 0.4637402 (236)\ttotal: 3.94s\tremaining: 123ms\n",
      "1094:\tlearn: 0.0614141\ttest: 0.5184151\tbest: 0.4637402 (236)\ttotal: 3.95s\tremaining: 119ms\n",
      "1095:\tlearn: 0.0613599\ttest: 0.5184649\tbest: 0.4637402 (236)\ttotal: 3.95s\tremaining: 115ms\n",
      "1096:\tlearn: 0.0612792\ttest: 0.5188021\tbest: 0.4637402 (236)\ttotal: 3.95s\tremaining: 112ms\n",
      "1097:\tlearn: 0.0612142\ttest: 0.5187348\tbest: 0.4637402 (236)\ttotal: 3.96s\tremaining: 108ms\n",
      "1098:\tlearn: 0.0611005\ttest: 0.5187748\tbest: 0.4637402 (236)\ttotal: 3.96s\tremaining: 105ms\n",
      "1099:\tlearn: 0.0610116\ttest: 0.5187713\tbest: 0.4637402 (236)\ttotal: 3.96s\tremaining: 101ms\n",
      "1100:\tlearn: 0.0608964\ttest: 0.5190340\tbest: 0.4637402 (236)\ttotal: 3.97s\tremaining: 97.3ms\n",
      "1101:\tlearn: 0.0608094\ttest: 0.5192637\tbest: 0.4637402 (236)\ttotal: 3.97s\tremaining: 93.7ms\n",
      "1102:\tlearn: 0.0607076\ttest: 0.5193456\tbest: 0.4637402 (236)\ttotal: 3.97s\tremaining: 90.1ms\n",
      "1103:\tlearn: 0.0606613\ttest: 0.5193825\tbest: 0.4637402 (236)\ttotal: 3.98s\tremaining: 86.5ms\n",
      "1104:\tlearn: 0.0605853\ttest: 0.5194926\tbest: 0.4637402 (236)\ttotal: 3.98s\tremaining: 82.9ms\n",
      "1105:\tlearn: 0.0605167\ttest: 0.5196592\tbest: 0.4637402 (236)\ttotal: 3.98s\tremaining: 79.3ms\n",
      "1106:\tlearn: 0.0604574\ttest: 0.5197091\tbest: 0.4637402 (236)\ttotal: 3.99s\tremaining: 75.6ms\n",
      "1107:\tlearn: 0.0603784\ttest: 0.5198352\tbest: 0.4637402 (236)\ttotal: 3.99s\tremaining: 72ms\n",
      "1108:\tlearn: 0.0602965\ttest: 0.5199266\tbest: 0.4637402 (236)\ttotal: 3.99s\tremaining: 68.4ms\n",
      "1109:\tlearn: 0.0601850\ttest: 0.5197531\tbest: 0.4637402 (236)\ttotal: 4s\tremaining: 64.8ms\n",
      "1110:\tlearn: 0.0600875\ttest: 0.5199086\tbest: 0.4637402 (236)\ttotal: 4s\tremaining: 61.2ms\n",
      "1111:\tlearn: 0.0600390\ttest: 0.5199478\tbest: 0.4637402 (236)\ttotal: 4s\tremaining: 57.6ms\n",
      "1112:\tlearn: 0.0599902\ttest: 0.5198896\tbest: 0.4637402 (236)\ttotal: 4.01s\tremaining: 54ms\n",
      "1113:\tlearn: 0.0598984\ttest: 0.5199193\tbest: 0.4637402 (236)\ttotal: 4.01s\tremaining: 50.4ms\n",
      "1114:\tlearn: 0.0598286\ttest: 0.5200203\tbest: 0.4637402 (236)\ttotal: 4.01s\tremaining: 46.8ms\n",
      "1115:\tlearn: 0.0597446\ttest: 0.5203693\tbest: 0.4637402 (236)\ttotal: 4.02s\tremaining: 43.2ms\n",
      "1116:\tlearn: 0.0596974\ttest: 0.5204097\tbest: 0.4637402 (236)\ttotal: 4.02s\tremaining: 39.6ms\n",
      "1117:\tlearn: 0.0596066\ttest: 0.5204198\tbest: 0.4637402 (236)\ttotal: 4.02s\tremaining: 36ms\n",
      "1118:\tlearn: 0.0595568\ttest: 0.5205440\tbest: 0.4637402 (236)\ttotal: 4.03s\tremaining: 32.4ms\n",
      "1119:\tlearn: 0.0594673\ttest: 0.5205751\tbest: 0.4637402 (236)\ttotal: 4.03s\tremaining: 28.8ms\n",
      "1120:\tlearn: 0.0594119\ttest: 0.5205598\tbest: 0.4637402 (236)\ttotal: 4.03s\tremaining: 25.2ms\n",
      "1121:\tlearn: 0.0593112\ttest: 0.5205095\tbest: 0.4637402 (236)\ttotal: 4.04s\tremaining: 21.6ms\n",
      "1122:\tlearn: 0.0592283\ttest: 0.5204803\tbest: 0.4637402 (236)\ttotal: 4.04s\tremaining: 18ms\n",
      "1123:\tlearn: 0.0591414\ttest: 0.5209345\tbest: 0.4637402 (236)\ttotal: 4.04s\tremaining: 14.4ms\n",
      "1124:\tlearn: 0.0590610\ttest: 0.5210184\tbest: 0.4637402 (236)\ttotal: 4.05s\tremaining: 10.8ms\n",
      "1125:\tlearn: 0.0589956\ttest: 0.5211838\tbest: 0.4637402 (236)\ttotal: 4.05s\tremaining: 7.2ms\n",
      "1126:\tlearn: 0.0589482\ttest: 0.5212225\tbest: 0.4637402 (236)\ttotal: 4.05s\tremaining: 3.6ms\n",
      "1127:\tlearn: 0.0588875\ttest: 0.5212078\tbest: 0.4637402 (236)\ttotal: 4.06s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4637401836\n",
      "bestIteration = 236\n",
      "\n",
      "Shrink model to first 237 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x21aedaee6f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_cb: dict = study_cb.best_params.copy()\n",
    "BASE_CB_MODEL: CatBoostClassifier = CatBoostClassifier(\n",
    "    **best_params_cb,\n",
    "    verbose = 1,\n",
    "    auto_class_weights = \"Balanced\",\n",
    "    random_state = 13,\n",
    "    task_type = \"CPU\",\n",
    "    boosting_type = 'Plain'\n",
    "    )\n",
    "BASE_CB_MODEL.fit(\n",
    "    X_ROOT_TRAIN,\n",
    "    Y_ROOT_TRAIN,\n",
    "    eval_set = [(X_ROOT_TEST , Y_ROOT_TEST)],\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8109c135",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm_meta_pred: np.ndarray = BASE_MODEL_XGBM.predict_proba(X_ROOT_TEST)\n",
    "lgbm_meta_pred: np.ndarray = BASE_MODEL_LGBM.predict_proba(X_ROOT_TEST)\n",
    "cb_meta_pred: np.ndarray   = BASE_CB_MODEL.predict_proba(X_ROOT_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "881c4fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "XGBM_PREDICTION",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "LGBM_PREDICTION",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CB_PREDICTION",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ACTUAL_VALUE",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "953ceb39-a0f6-42e6-ba59-167605599dd6",
       "rows": [
        [
         "127",
         "0.8532894",
         "0.9470219170010701",
         "0.8789050306350783",
         "1"
        ],
        [
         "2504",
         "0.013197343",
         "0.005113086186298822",
         "0.06116754835162261",
         "0"
        ],
        [
         "634",
         "0.044218425",
         "0.03603790953801924",
         "0.1198153279644213",
         "0"
        ],
        [
         "1797",
         "0.7606771",
         "0.7970024919348099",
         "0.5295473422677646",
         "1"
        ],
        [
         "2153",
         "0.049029887",
         "0.033177430565959516",
         "0.17630893905353",
         "0"
        ],
        [
         "753",
         "0.04180444",
         "0.013850104414746312",
         "0.23588813765013164",
         "0"
        ],
        [
         "81",
         "0.8803313",
         "0.9321764398281484",
         "0.7794991435573667",
         "1"
        ],
        [
         "481",
         "0.9629581",
         "0.9701780042376423",
         "0.9119520437052661",
         "1"
        ],
        [
         "196",
         "0.06287413",
         "0.032225904084501655",
         "0.18183495154517046",
         "0"
        ],
        [
         "2189",
         "0.28854552",
         "0.24335122589519242",
         "0.551026350583852",
         "0"
        ],
        [
         "1879",
         "0.00843356",
         "0.003600171492974844",
         "0.08185392645586725",
         "0"
        ],
        [
         "136",
         "0.93687725",
         "0.9724902110861875",
         "0.8910175942010301",
         "0"
        ],
        [
         "848",
         "0.9650105",
         "0.9771047319053938",
         "0.8830379954077643",
         "0"
        ],
        [
         "2260",
         "0.9644564",
         "0.968148225189062",
         "0.8059956910102425",
         "1"
        ],
        [
         "850",
         "0.040699895",
         "0.1286842713268502",
         "0.18821458613031924",
         "0"
        ],
        [
         "2076",
         "0.9935242",
         "0.9965552257553815",
         "0.9613852519890668",
         "1"
        ],
        [
         "1459",
         "0.43317425",
         "0.19929780945145362",
         "0.3971736476744083",
         "1"
        ],
        [
         "1260",
         "0.010657241",
         "0.004057655845421547",
         "0.08319708967002684",
         "0"
        ],
        [
         "94",
         "0.19880566",
         "0.2034297715997701",
         "0.4910370305761097",
         "0"
        ],
        [
         "1832",
         "0.058485355",
         "0.06433914072229224",
         "0.1746458734585618",
         "0"
        ],
        [
         "663",
         "0.5416417",
         "0.49703618204568933",
         "0.641323889388805",
         "1"
        ],
        [
         "1163",
         "0.02814126",
         "0.02261118979870161",
         "0.09810636775815935",
         "0"
        ],
        [
         "1924",
         "0.45621312",
         "0.7007197153958525",
         "0.5026047250895542",
         "0"
        ],
        [
         "447",
         "0.019140113",
         "0.004896640522893405",
         "0.08402052400298307",
         "0"
        ],
        [
         "1829",
         "0.99151176",
         "0.997512048978702",
         "0.9376704671644222",
         "1"
        ],
        [
         "2511",
         "0.220628",
         "0.1329988039236658",
         "0.5644777996275891",
         "0"
        ],
        [
         "27",
         "0.9905489",
         "0.9980103434732542",
         "0.9549142642234136",
         "1"
        ],
        [
         "2361",
         "0.0041295947",
         "0.0003983351881541612",
         "0.04260544519032933",
         "0"
        ],
        [
         "1447",
         "0.035241686",
         "0.01712449322454425",
         "0.16004452673040503",
         "0"
        ],
        [
         "867",
         "0.019251848",
         "0.005362459491011438",
         "0.04183279385931458",
         "0"
        ],
        [
         "225",
         "0.0143714985",
         "0.012827487110339496",
         "0.07296936618780472",
         "0"
        ],
        [
         "936",
         "0.0141605055",
         "0.006096541579369484",
         "0.10738261742026986",
         "0"
        ],
        [
         "2275",
         "0.029410359",
         "0.019721356201663383",
         "0.12258611238651294",
         "0"
        ],
        [
         "1960",
         "0.002693631",
         "0.001852401031310174",
         "0.03619139067423087",
         "0"
        ],
        [
         "285",
         "0.2875027",
         "0.3852145892048232",
         "0.39085967324956966",
         "1"
        ],
        [
         "1029",
         "0.7324334",
         "0.8788547758317808",
         "0.7670960345626099",
         "0"
        ],
        [
         "1828",
         "0.76248896",
         "0.8187884951545835",
         "0.6640946506750304",
         "1"
        ],
        [
         "2480",
         "0.40029132",
         "0.6638574453448847",
         "0.4064656311881606",
         "1"
        ],
        [
         "748",
         "0.30058226",
         "0.3433880680510581",
         "0.47743931082819585",
         "0"
        ],
        [
         "298",
         "0.027294638",
         "0.011468312214945956",
         "0.09907373428366206",
         "0"
        ],
        [
         "2564",
         "0.031088993",
         "0.011286383654417571",
         "0.14187971080700368",
         "1"
        ],
        [
         "1476",
         "0.41317093",
         "0.5925690896883503",
         "0.451214831705856",
         "0"
        ],
        [
         "201",
         "0.075067654",
         "0.07555410207724154",
         "0.2601735454770287",
         "1"
        ],
        [
         "1424",
         "0.2577082",
         "0.19975823242603913",
         "0.4062284095124534",
         "1"
        ],
        [
         "110",
         "0.14158452",
         "0.12457161928792472",
         "0.26711000534296364",
         "0"
        ],
        [
         "579",
         "0.016639",
         "0.007917115479256796",
         "0.06358985855365866",
         "0"
        ],
        [
         "1498",
         "0.034287598",
         "0.012721334150929079",
         "0.19163957705971674",
         "0"
        ],
        [
         "1953",
         "0.003949361",
         "0.00021003900268459045",
         "0.027040910763282952",
         "0"
        ],
        [
         "289",
         "0.091695726",
         "0.01821894377576405",
         "0.3107207047389014",
         "1"
        ],
        [
         "576",
         "0.0066118403",
         "0.004059583198836001",
         "0.05708487336610646",
         "0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 524
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBM_PREDICTION</th>\n",
       "      <th>LGBM_PREDICTION</th>\n",
       "      <th>CB_PREDICTION</th>\n",
       "      <th>ACTUAL_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.853289</td>\n",
       "      <td>0.947022</td>\n",
       "      <td>0.878905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>0.013197</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.061168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.044218</td>\n",
       "      <td>0.036038</td>\n",
       "      <td>0.119815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>0.760677</td>\n",
       "      <td>0.797002</td>\n",
       "      <td>0.529547</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>0.049030</td>\n",
       "      <td>0.033177</td>\n",
       "      <td>0.176309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>0.857422</td>\n",
       "      <td>0.854587</td>\n",
       "      <td>0.854766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.041366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>0.143663</td>\n",
       "      <td>0.046718</td>\n",
       "      <td>0.195612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>0.007739</td>\n",
       "      <td>0.006773</td>\n",
       "      <td>0.052485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.763902</td>\n",
       "      <td>0.766957</td>\n",
       "      <td>0.721575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>524 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      XGBM_PREDICTION  LGBM_PREDICTION  CB_PREDICTION  ACTUAL_VALUE\n",
       "127          0.853289         0.947022       0.878905             1\n",
       "2504         0.013197         0.005113       0.061168             0\n",
       "634          0.044218         0.036038       0.119815             0\n",
       "1797         0.760677         0.797002       0.529547             1\n",
       "2153         0.049030         0.033177       0.176309             0\n",
       "...               ...              ...            ...           ...\n",
       "880          0.857422         0.854587       0.854766             0\n",
       "2031         0.002385         0.000824       0.041366             0\n",
       "1600         0.143663         0.046718       0.195612             0\n",
       "1581         0.007739         0.006773       0.052485             0\n",
       "975          0.763902         0.766957       0.721575             1\n",
       "\n",
       "[524 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta: pd.DataFrame = pd.DataFrame({\n",
    "    'XGBM_PREDICTION' : xgbm_meta_pred[:, 1],\n",
    "    'LGBM_PREDICTION' : lgbm_meta_pred[:, 1],\n",
    "    'CB_PREDICTION'   : cb_meta_pred[:, 1],\n",
    "    'ACTUAL_VALUE'    : Y_ROOT_TEST\n",
    "})\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca6b94bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:37,461] A new study created in RDB with name: gbm_study_6\n",
      "  0%|          | 0/50 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:39,122] Trial 5 finished with value: 0.8054131054131053 and parameters: {'learning_rate': 0.12672104404074147, 'n_estimators': 86, 'subsample': 0.948955737656499, 'max_depth': 6}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:39,220] Trial 2 finished with value: 0.8132478632478632 and parameters: {'learning_rate': 0.12950188114972344, 'n_estimators': 31, 'subsample': 0.893717678431399, 'max_depth': 4}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:39,223] Trial 4 finished with value: 0.7977207977207976 and parameters: {'learning_rate': 0.11066430336549668, 'n_estimators': 41, 'subsample': 0.8935031399806452, 'max_depth': 5}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:   8%|▊         | 4/50 [00:02<00:19,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:39,533] Trial 0 finished with value: 0.8017094017094017 and parameters: {'learning_rate': 0.11784439106160452, 'n_estimators': 77, 'subsample': 0.8387938920076922, 'max_depth': 5}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:39,588] Trial 1 finished with value: 0.7864672364672364 and parameters: {'learning_rate': 0.14616165370537598, 'n_estimators': 87, 'subsample': 0.9725549897451385, 'max_depth': 7}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  10%|█         | 5/50 [00:03<00:19,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:40,346] Trial 7 finished with value: 0.8055555555555556 and parameters: {'learning_rate': 0.13405454983947973, 'n_estimators': 45, 'subsample': 0.8020837438976065, 'max_depth': 7}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:40,486] Trial 6 finished with value: 0.8055555555555556 and parameters: {'learning_rate': 0.12494994193167347, 'n_estimators': 54, 'subsample': 0.8242808647002585, 'max_depth': 5}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:40,523] Trial 3 finished with value: 0.7827635327635327 and parameters: {'learning_rate': 0.10493184215193804, 'n_estimators': 99, 'subsample': 0.9685971939467918, 'max_depth': 7}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:40,534] Trial 10 finished with value: 0.798005698005698 and parameters: {'learning_rate': 0.14070436431642483, 'n_estimators': 83, 'subsample': 0.9360639734091274, 'max_depth': 3}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  20%|██        | 10/50 [00:03<00:09,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:40,828] Trial 11 finished with value: 0.7941595441595442 and parameters: {'learning_rate': 0.10739469438378586, 'n_estimators': 87, 'subsample': 0.8791045902884956, 'max_depth': 6}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  22%|██▏       | 11/50 [00:04<00:11,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:41,281] Trial 8 finished with value: 0.813105413105413 and parameters: {'learning_rate': 0.14356130038760184, 'n_estimators': 100, 'subsample': 0.8025274618444924, 'max_depth': 6}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:41,457] Trial 9 finished with value: 0.7978632478632479 and parameters: {'learning_rate': 0.14855511282705117, 'n_estimators': 89, 'subsample': 0.8794971145297967, 'max_depth': 7}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  28%|██▊       | 14/50 [00:04<00:09,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:41,797] Trial 12 finished with value: 0.8055555555555556 and parameters: {'learning_rate': 0.14693540907805874, 'n_estimators': 73, 'subsample': 0.8703574592801867, 'max_depth': 6}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:41,881] Trial 13 finished with value: 0.8094017094017094 and parameters: {'learning_rate': 0.1417631466710317, 'n_estimators': 57, 'subsample': 0.8779604772744728, 'max_depth': 6}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:41,939] Trial 14 finished with value: 0.7941595441595442 and parameters: {'learning_rate': 0.1356233793822921, 'n_estimators': 33, 'subsample': 0.8648324472136698, 'max_depth': 3}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  34%|███▍      | 17/50 [00:04<00:06,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:42,152] Trial 19 finished with value: 0.8018518518518517 and parameters: {'learning_rate': 0.14868823914029716, 'n_estimators': 64, 'subsample': 0.8603277957786637, 'max_depth': 3}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:42,154] Trial 15 finished with value: 0.8055555555555556 and parameters: {'learning_rate': 0.1179151671802693, 'n_estimators': 68, 'subsample': 0.85940544610984, 'max_depth': 7}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:42,265] Trial 16 finished with value: 0.8095441595441596 and parameters: {'learning_rate': 0.13361219232625704, 'n_estimators': 30, 'subsample': 0.8624740737799301, 'max_depth': 3}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:42,279] Trial 17 finished with value: 0.8018518518518519 and parameters: {'learning_rate': 0.13484831082739462, 'n_estimators': 32, 'subsample': 0.8503669961209696, 'max_depth': 3}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  44%|████▍     | 22/50 [00:05<00:03,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:42,445] Trial 18 finished with value: 0.7941595441595442 and parameters: {'learning_rate': 0.1346821410912803, 'n_estimators': 31, 'subsample': 0.8408755050921748, 'max_depth': 3}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:42,499] Trial 21 finished with value: 0.7940170940170941 and parameters: {'learning_rate': 0.12879273795487675, 'n_estimators': 65, 'subsample': 0.9208950256454509, 'max_depth': 4}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:42,601] Trial 20 finished with value: 0.8055555555555556 and parameters: {'learning_rate': 0.12859162750552575, 'n_estimators': 67, 'subsample': 0.9145868488279516, 'max_depth': 4}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  44%|████▍     | 22/50 [00:05<00:03,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:43,089] Trial 22 finished with value: 0.8017094017094017 and parameters: {'learning_rate': 0.14126731578787607, 'n_estimators': 42, 'subsample': 0.9092936310140541, 'max_depth': 4}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  48%|████▊     | 24/50 [00:06<00:04,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:43,416] Trial 25 finished with value: 0.7977207977207976 and parameters: {'learning_rate': 0.14170117454368383, 'n_estimators': 40, 'subsample': 0.8168185285298426, 'max_depth': 4}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:43,539] Trial 23 finished with value: 0.7903133903133902 and parameters: {'learning_rate': 0.14060537286492225, 'n_estimators': 43, 'subsample': 0.8053640046129754, 'max_depth': 4}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  50%|█████     | 25/50 [00:06<00:05,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:43,819] Trial 26 finished with value: 0.8132478632478632 and parameters: {'learning_rate': 0.14094049208533418, 'n_estimators': 41, 'subsample': 0.8040193478321773, 'max_depth': 4}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:43,915] Trial 24 finished with value: 0.7904558404558404 and parameters: {'learning_rate': 0.1405449517938042, 'n_estimators': 42, 'subsample': 0.8051099608426104, 'max_depth': 4}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  50%|█████     | 25/50 [00:06<00:05,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:44,009] Trial 27 finished with value: 0.8092592592592591 and parameters: {'learning_rate': 0.1397492489397894, 'n_estimators': 40, 'subsample': 0.8200021784490554, 'max_depth': 4}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  56%|█████▌    | 28/50 [00:07<00:05,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:44,541] Trial 29 finished with value: 0.7901709401709403 and parameters: {'learning_rate': 0.11905714396799047, 'n_estimators': 49, 'subsample': 0.8013715621061998, 'max_depth': 8}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:44,637] Trial 31 finished with value: 0.8018518518518519 and parameters: {'learning_rate': 0.12120324446005032, 'n_estimators': 100, 'subsample': 0.8011886890902196, 'max_depth': 4}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  60%|██████    | 30/50 [00:07<00:03,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:45,172] Trial 28 finished with value: 0.7713675213675214 and parameters: {'learning_rate': 0.12099432872655508, 'n_estimators': 49, 'subsample': 0.9992779881892387, 'max_depth': 8}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  62%|██████▏   | 31/50 [00:07<00:04,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:45,428] Trial 33 finished with value: 0.7790598290598291 and parameters: {'learning_rate': 0.1185372700976115, 'n_estimators': 50, 'subsample': 0.9895303344878802, 'max_depth': 8}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  64%|██████▍   | 32/50 [00:08<00:04,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:45,677] Trial 30 finished with value: 0.8055555555555556 and parameters: {'learning_rate': 0.12097906579415206, 'n_estimators': 100, 'subsample': 0.803766448886761, 'max_depth': 8}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  66%|██████▌   | 33/50 [00:08<00:04,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:45,913] Trial 34 finished with value: 0.8094017094017094 and parameters: {'learning_rate': 0.12185533487296593, 'n_estimators': 50, 'subsample': 0.8335544426927528, 'max_depth': 8}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  68%|██████▊   | 34/50 [00:09<00:03,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:46,428] Trial 35 finished with value: 0.813105413105413 and parameters: {'learning_rate': 0.11341223136011047, 'n_estimators': 58, 'subsample': 0.8324502568014707, 'max_depth': 5}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:46,527] Trial 32 finished with value: 0.8018518518518519 and parameters: {'learning_rate': 0.12151972928846064, 'n_estimators': 100, 'subsample': 0.8206011499331601, 'max_depth': 8}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:46,553] Trial 36 finished with value: 0.8094017094017094 and parameters: {'learning_rate': 0.11293324229742031, 'n_estimators': 57, 'subsample': 0.8414103925439611, 'max_depth': 5}. Best is trial 2 with value: 0.8132478632478632.\n",
      "[I 2025-12-25 16:30:46,584] Trial 38 finished with value: 0.7978632478632479 and parameters: {'learning_rate': 0.1332245112295603, 'n_estimators': 35, 'subsample': 0.8308130906048234, 'max_depth': 5}. Best is trial 2 with value: 0.8132478632478632.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.813248:  76%|███████▌  | 38/50 [00:09<00:03,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:46,681] Trial 37 finished with value: 0.8246438746438747 and parameters: {'learning_rate': 0.13193520403664774, 'n_estimators': 37, 'subsample': 0.8353273958308829, 'max_depth': 5}. Best is trial 37 with value: 0.8246438746438747.\n",
      "[I 2025-12-25 16:30:46,818] Trial 40 finished with value: 0.8286324786324786 and parameters: {'learning_rate': 0.13121904389117106, 'n_estimators': 36, 'subsample': 0.8930689961627997, 'max_depth': 5}. Best is trial 40 with value: 0.8286324786324786.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.828632:  82%|████████▏ | 41/50 [00:09<00:01,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:46,976] Trial 39 finished with value: 0.8094017094017094 and parameters: {'learning_rate': 0.1309766181799045, 'n_estimators': 36, 'subsample': 0.8949913322625958, 'max_depth': 5}. Best is trial 40 with value: 0.8286324786324786.\n",
      "[I 2025-12-25 16:30:46,997] Trial 41 finished with value: 0.8055555555555556 and parameters: {'learning_rate': 0.13167620660575294, 'n_estimators': 36, 'subsample': 0.8981035203338386, 'max_depth': 5}. Best is trial 40 with value: 0.8286324786324786.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.828632:  84%|████████▍ | 42/50 [00:09<00:01,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:47,296] Trial 45 finished with value: 0.8094017094017094 and parameters: {'learning_rate': 0.10073430095152339, 'n_estimators': 36, 'subsample': 0.8167377435448172, 'max_depth': 5}. Best is trial 40 with value: 0.8286324786324786.\n",
      "[I 2025-12-25 16:30:47,323] Trial 42 finished with value: 0.8094017094017094 and parameters: {'learning_rate': 0.14523863032303197, 'n_estimators': 37, 'subsample': 0.8946533532965923, 'max_depth': 5}. Best is trial 40 with value: 0.8286324786324786.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.828632:  86%|████████▌ | 43/50 [00:10<00:01,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:47,555] Trial 44 finished with value: 0.8247863247863247 and parameters: {'learning_rate': 0.13762492978677549, 'n_estimators': 36, 'subsample': 0.8988166872034666, 'max_depth': 5}. Best is trial 40 with value: 0.8286324786324786.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.828632:  94%|█████████▍| 47/50 [00:10<00:00,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:47,867] Trial 43 finished with value: 0.7978632478632479 and parameters: {'learning_rate': 0.11463374046299167, 'n_estimators': 93, 'subsample': 0.894340745963955, 'max_depth': 5}. Best is trial 40 with value: 0.8286324786324786.\n",
      "[I 2025-12-25 16:30:48,001] Trial 46 finished with value: 0.813105413105413 and parameters: {'learning_rate': 0.13790290491794507, 'n_estimators': 79, 'subsample': 0.957637627974519, 'max_depth': 6}. Best is trial 40 with value: 0.8286324786324786.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.828632:  98%|█████████▊| 49/50 [00:10<00:00,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:48,322] Trial 49 finished with value: 0.798005698005698 and parameters: {'learning_rate': 0.1378332343803066, 'n_estimators': 94, 'subsample': 0.9389870262033242, 'max_depth': 6}. Best is trial 40 with value: 0.8286324786324786.\n",
      "[I 2025-12-25 16:30:48,432] Trial 47 finished with value: 0.8055555555555556 and parameters: {'learning_rate': 0.13756728028518345, 'n_estimators': 45, 'subsample': 0.938839233440881, 'max_depth': 6}. Best is trial 40 with value: 0.8286324786324786.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.828632: 100%|██████████| 50/50 [00:11<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-25 16:30:48,575] Trial 48 finished with value: 0.7941595441595442 and parameters: {'learning_rate': 0.13697373042847938, 'n_estimators': 91, 'subsample': 0.9495763018804174, 'max_depth': 6}. Best is trial 40 with value: 0.8286324786324786.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "META_X = df_meta.drop('ACTUAL_VALUE' , axis = 1).copy()\n",
    "META_Y = df_meta['ACTUAL_VALUE']\n",
    "\n",
    "META_X_TRAIN , META_X_TEST, META_Y_TRAIN , META_Y_TEST = train_test_split(\n",
    "    META_X,\n",
    "    META_Y,\n",
    "    train_size = 0.5,\n",
    "    test_size  = 0.5,\n",
    "    stratify = META_Y,\n",
    "    shuffle = True,\n",
    "    random_state = 13\n",
    ")\n",
    "weight_pos: float = (META_Y_TRAIN == 0).sum()/(META_Y_TRAIN == 1).sum()\n",
    "weight_neg: float = 1.0\n",
    "weights: np.ndarray = np.where(META_Y_TRAIN == 1, weight_pos , weight_neg)\n",
    "\n",
    "def obj_for_meta(trial: optuna.Trial) -> float:\n",
    "\n",
    "    gbm_params: dict = {\n",
    "        'loss' : 'log_loss',\n",
    "        'learning_rate' : trial.suggest_float('learning_rate', 0.1 , 0.15),\n",
    "        'n_estimators'  : trial.suggest_int('n_estimators', 30, 100),\n",
    "        'subsample'     : trial.suggest_float('subsample', 0.8 , 1),\n",
    "        'min_samples_split': int(2),\n",
    "        'min_samples_leaf' : int(1),\n",
    "        'max_depth'      : trial.suggest_int('max_depth', 3, 8),\n",
    "        'random_state' : int(13)\n",
    "    }\n",
    "\n",
    "    __model: GradientBoostingClassifier = GradientBoostingClassifier(\n",
    "        **gbm_params\n",
    "    )\n",
    "    \n",
    "    __model.fit(META_X_TRAIN , META_Y_TRAIN, sample_weight = weights)\n",
    "    validator: StratifiedKFold = StratifiedKFold(\n",
    "        n_splits= 10 ,\n",
    "        shuffle= True, \n",
    "        random_state= 13\n",
    "        )\n",
    "    accuracy: float = cross_val_score(\n",
    "        __model,\n",
    "        META_X_TEST,\n",
    "        META_Y_TEST,\n",
    "        cv = validator,\n",
    "        scoring = \"accuracy\",\n",
    "        n_jobs = -1,\n",
    "    ).mean()\n",
    "    return accuracy\n",
    "\n",
    "storage_path_gbm: str = \"sqlite:///gbm_study.db\"\n",
    "study_gbm = optuna.create_study(\n",
    "    study_name = \"gbm_study_6\",\n",
    "    storage  = storage_path_gbm,\n",
    "    direction= 'maximize',\n",
    "    load_if_exists = True\n",
    ")\n",
    "study_gbm.optimize(\n",
    "    func = obj_for_meta,\n",
    "    n_trials = 50,\n",
    "    n_jobs = -1,\n",
    "    show_progress_bar = True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c3b873f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.13121904389117106, max_depth=5,\n",
       "                           n_estimators=36, random_state=13,\n",
       "                           subsample=0.8930689961627997)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('loss',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">loss&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;log_loss&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.13121904389117106</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">36</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.8930689961627997</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;friedman_mse&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('init',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">init&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">13</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validation_fraction',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validation_fraction&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter_no_change',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_iter_no_change&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.13121904389117106, max_depth=5,\n",
       "                           n_estimators=36, random_state=13,\n",
       "                           subsample=0.8930689961627997)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_meta: dict = study_gbm.best_params.copy()\n",
    "META_MODEL: GradientBoostingClassifier = GradientBoostingClassifier(\n",
    "    **best_params_meta ,\n",
    "    min_samples_split = int(2),\n",
    "    min_samples_leaf = int(1), \n",
    "    random_state = int(13))\n",
    "\n",
    "#\n",
    "#w1: float = (META_Y == 0).sum()/(META_Y == 1).sum()\n",
    "#w0: float = 1.0\n",
    "#weights_2: np.ndarray = np.where(META_Y == 1 , w1 , w0)\n",
    "#\n",
    "META_MODEL.fit(\n",
    "    META_X_TRAIN, \n",
    "    META_Y_TRAIN, \n",
    "    sample_weight = weights\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13ea5bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df: pd.DataFrame = pd.read_csv('test.csv')\n",
    "test_df.columns = [\n",
    "    'date',\n",
    "    'temp_9am',\n",
    "    'temp_3pm',\n",
    "    'min_temp',\n",
    "    'max_temp',\n",
    "    'rain_fall',\n",
    "    'evaporation',\n",
    "    'sunshine',\n",
    "    'wind_gust_dir',\n",
    "    'wind_gust_speed',\n",
    "    'wind_dir_9am',\n",
    "    'wind_dir_3pm',\n",
    "    'wind_speed_9am',\n",
    "    'wind_speed_3pm',\n",
    "    'humidity_9am',\n",
    "    'humidity3pm',\n",
    "    'pressure_9am',\n",
    "    'pressure_3pm',\n",
    "    'cloud_9am',\n",
    "    'cloud_3pm',\n",
    "    'id'\n",
    "]\n",
    "ids = test_df['id']\n",
    "test_df = test_df.drop('id' , axis = 1)\n",
    "test_df['date'] = test_df['date'].map(date_to_days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3d5c4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wind_gust_dir', 'wind_dir_9am', 'wind_dir_3pm']\n",
      "16\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "cat_columns: list = []\n",
    "for item in test_df.columns:\n",
    "    if test_df[item].dtype == object:\n",
    "        cat_columns.append(item)\n",
    "print(cat_columns)\n",
    "for item in cat_columns: print(len(test_df[item].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "794be67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output = False , \n",
    "                        categories = 'auto', \n",
    "                        handle_unknown= 'error',\n",
    "                        max_categories = 32)\n",
    "\n",
    "encoder.fit(test_df[cat_columns])\n",
    "cat_ohed = pd.DataFrame(encoder.transform(test_df[cat_columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faea070d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "temp_9am",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temp_3pm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "min_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max_temp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rain_fall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "evaporation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sunshine",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wind_gust_speed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wind_speed_9am",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wind_speed_3pm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "humidity_9am",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "humidity3pm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pressure_9am",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pressure_3pm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cloud_9am",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cloud_3pm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "11",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "13",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "14",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "15",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "16",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "17",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "18",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "19",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "21",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "22",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "23",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "25",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "26",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "27",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "28",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "29",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "30",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "31",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "32",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "33",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "34",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "35",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "36",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "37",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "38",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "39",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "40",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "41",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "42",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "43",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "44",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "45",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "46",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "47",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b92c62fe-6dcb-4b6e-9ad5-d9550f95db6a",
       "rows": [
        [
         "0",
         "7396",
         "12.7",
         "17.0",
         "9.0",
         "19.7",
         "0.0",
         "3.2",
         "10.8",
         "31",
         "17",
         "13",
         "50",
         "39",
         "1015.8",
         "1013.3",
         "1",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "7397",
         "11.9",
         "18.6",
         "8.0",
         "18.8",
         "0.0",
         "4.0",
         "10.4",
         "31",
         "11",
         "19",
         "61",
         "46",
         "1018.0",
         "1012.0",
         "5",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "7398",
         "14.4",
         "20.6",
         "11.2",
         "20.8",
         "2.8",
         "5.6",
         "8.0",
         "52",
         "20",
         "24",
         "69",
         "28",
         "1006.0",
         "1005.6",
         "3",
         "6",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "3",
         "7399",
         "13.7",
         "18.3",
         "12.5",
         "19.5",
         "20.4",
         "4.0",
         "5.7",
         "48",
         "19",
         "20",
         "92",
         "54",
         "1021.5",
         "1020.5",
         "7",
         "2",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "7400",
         "15.2",
         "18.7",
         "11.5",
         "21.7",
         "0.0",
         "2.8",
         "9.3",
         "37",
         "17",
         "24",
         "68",
         "53",
         "1022.3",
         "1019.6",
         "1",
         "5",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "5",
         "7401",
         "14.6",
         "16.0",
         "12.7",
         "17.5",
         "0.4",
         "5.4",
         "1.0",
         "24",
         "11",
         "6",
         "84",
         "68",
         "1024.9",
         "1021.9",
         "7",
         "7",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "6",
         "7402",
         "17.4",
         "22.7",
         "11.1",
         "24.9",
         "0.2",
         "0.6",
         "9.3",
         "54",
         "9",
         "15",
         "62",
         "32",
         "1018.3",
         "1013.3",
         "2",
         "4",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0"
        ],
        [
         "7",
         "7403",
         "13.3",
         "19.7",
         "10.0",
         "20.0",
         "0.0",
         "6.8",
         "11.0",
         "52",
         "30",
         "24",
         "42",
         "32",
         "1018.8",
         "1015.7",
         "1",
         "2",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0"
        ],
        [
         "8",
         "7404",
         "15.4",
         "18.9",
         "9.8",
         "20.2",
         "0.0",
         "5.0",
         "10.9",
         "41",
         "20",
         "17",
         "48",
         "39",
         "1023.1",
         "1022.0",
         "1",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "9",
         "7405",
         "15.5",
         "18.9",
         "11.3",
         "19.6",
         "0.0",
         "4.8",
         "6.5",
         "37",
         "13",
         "15",
         "59",
         "41",
         "1030.9",
         "1029.8",
         "1",
         "7",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "10",
         "7406",
         "17.6",
         "20.5",
         "14.0",
         "21.3",
         "0.0",
         "4.0",
         "9.1",
         "39",
         "11",
         "24",
         "56",
         "44",
         "1032.1",
         "1027.6",
         "1",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "11",
         "7407",
         "17.2",
         "21.3",
         "10.9",
         "25.4",
         "0.0",
         "7.4",
         "10.4",
         "24",
         "11",
         "19",
         "61",
         "51",
         "1028.5",
         "1024.7",
         "1",
         "5",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "12",
         "7408",
         "18.3",
         "21.4",
         "12.4",
         "22.3",
         "0.0",
         "3.8",
         "10.6",
         "30",
         "11",
         "20",
         "61",
         "60",
         "1028.5",
         "1025.0",
         "1",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "13",
         "7409",
         "20.7",
         "21.4",
         "15.3",
         "23.6",
         "0.0",
         "5.0",
         "10.7",
         "43",
         "17",
         "24",
         "58",
         "59",
         "1025.9",
         "1020.5",
         "1",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "14",
         "7410",
         "23.5",
         "29.2",
         "15.8",
         "29.8",
         "0.0",
         "6.4",
         "11.0",
         "41",
         "9",
         "35",
         "33",
         "25",
         "1015.4",
         "1009.0",
         "1",
         "3",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "15",
         "7411",
         "17.2",
         "19.3",
         "12.4",
         "21.1",
         "0.0",
         "10.2",
         "10.2",
         "37",
         "19",
         "26",
         "42",
         "60",
         "1017.7",
         "1015.0",
         "2",
         "3",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "16",
         "7412",
         "18.0",
         "17.7",
         "12.2",
         "19.9",
         "0.0",
         "4.2",
         "8.2",
         "43",
         "9",
         "28",
         "53",
         "57",
         "1018.4",
         "1018.3",
         "3",
         "7",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "17",
         "7413",
         "15.8",
         "18.9",
         "13.6",
         "20.0",
         "2.2",
         "6.4",
         "7.7",
         "52",
         "20",
         "26",
         "65",
         "44",
         "1026.2",
         "1025.5",
         "5",
         "2",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "18",
         "7414",
         "14.7",
         "18.1",
         "12.5",
         "19.5",
         "10.8",
         "5.4",
         "7.3",
         "33",
         "17",
         "24",
         "88",
         "54",
         "1026.5",
         "1023.9",
         "7",
         "6",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "19",
         "7415",
         "16.6",
         "17.4",
         "12.5",
         "18.6",
         "0.4",
         "4.0",
         "3.4",
         "37",
         "11",
         "13",
         "62",
         "72",
         "1024.5",
         "1021.7",
         "5",
         "7",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "20",
         "7416",
         "16.3",
         "21.3",
         "12.4",
         "22.5",
         "0.2",
         "1.6",
         "10.4",
         "35",
         "15",
         "15",
         "74",
         "60",
         "1019.9",
         "1015.2",
         "1",
         "2",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "21",
         "7417",
         "18.7",
         "17.8",
         "14.6",
         "19.5",
         "0.2",
         "6.2",
         "9.2",
         "59",
         "24",
         "37",
         "36",
         "47",
         "1016.8",
         "1017.5",
         "3",
         "2",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "22",
         "7418",
         "13.3",
         "11.7",
         "10.0",
         "16.2",
         "0.2",
         "8.8",
         "6.5",
         "69",
         "31",
         "35",
         "55",
         "74",
         "1025.5",
         "1025.4",
         "3",
         "7",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "23",
         "7419",
         "13.0",
         "13.6",
         "8.3",
         "16.3",
         "3.2",
         "4.0",
         "6.1",
         "65",
         "22",
         "28",
         "63",
         "62",
         "1025.6",
         "1024.6",
         "7",
         "7",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "24",
         "7420",
         "13.4",
         "15.9",
         "10.1",
         "16.4",
         "31.8",
         "2.8",
         "4.3",
         "54",
         "13",
         "26",
         "91",
         "63",
         "1029.3",
         "1027.8",
         "7",
         "7",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "25",
         "7421",
         "14.4",
         "18.4",
         "11.1",
         "20.1",
         "3.4",
         "4.4",
         "7.7",
         "43",
         "22",
         "24",
         "86",
         "48",
         "1028.5",
         "1025.4",
         "6",
         "3",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "26",
         "7422",
         "15.3",
         "18.3",
         "12.3",
         "19.2",
         "3.6",
         "3.8",
         "6.2",
         "46",
         "20",
         "20",
         "70",
         "51",
         "1023.7",
         "1021.1",
         "7",
         "7",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "27",
         "7423",
         "17.3",
         "19.1",
         "10.9",
         "20.8",
         "0.2",
         "4.2",
         "11.0",
         "28",
         "15",
         "17",
         "56",
         "49",
         "1021.1",
         "1017.8",
         "1",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "28",
         "7424",
         "19.1",
         "21.7",
         "11.9",
         "23.4",
         "0.0",
         "5.8",
         "3.4",
         "50",
         "15",
         "17",
         "58",
         "55",
         "1019.5",
         "1015.8",
         "0",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "29",
         "7425",
         "21.0",
         "18.7",
         "16.7",
         "21.4",
         "0.0",
         "5.6",
         "6.4",
         "33",
         "17",
         "20",
         "57",
         "62",
         "1022.1",
         "1021.4",
         "7",
         "7",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "30",
         "7426",
         "19.9",
         "21.7",
         "16.8",
         "22.9",
         "0.0",
         "5.6",
         "9.6",
         "33",
         "6",
         "24",
         "68",
         "65",
         "1026.4",
         "1022.8",
         "4",
         "1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "31",
         "7427",
         "21.3",
         "21.1",
         "16.5",
         "23.0",
         "0.0",
         "4.8",
         "10.5",
         "33",
         "4",
         "24",
         "57",
         "57",
         "1033.4",
         "1031.8",
         "1",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "32",
         "7428",
         "21.5",
         "27.3",
         "14.2",
         "27.5",
         "0.0",
         "7.2",
         "11.1",
         "22",
         "13",
         "11",
         "62",
         "47",
         "1030.6",
         "1024.7",
         "0",
         "1",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "33",
         "7429",
         "26.4",
         "32.6",
         "19.8",
         "33.8",
         "0.0",
         "8.0",
         "8.2",
         "46",
         "4",
         "28",
         "28",
         "13",
         "1023.4",
         "1021.8",
         "7",
         "7",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0"
        ],
        [
         "34",
         "7430",
         "21.1",
         "35.6",
         "16.1",
         "37.0",
         "0.0",
         "11.0",
         "11.4",
         "20",
         "11",
         "11",
         "42",
         "16",
         "1024.0",
         "1021.1",
         "1",
         "7",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "35",
         "7431",
         "23.8",
         "30.6",
         "20.3",
         "32.3",
         "0.0",
         "8.6",
         "11.4",
         "43",
         "15",
         "17",
         "37",
         "26",
         "1023.2",
         "1019.7",
         "1",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "36",
         "7432",
         "20.3",
         "19.0",
         "19.7",
         "21.5",
         "0.0",
         "13.2",
         "1.3",
         "67",
         "39",
         "26",
         "61",
         "56",
         "1029.6",
         "1033.6",
         "5",
         "7",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "37",
         "7433",
         "18.5",
         "19.9",
         "17.0",
         "21.1",
         "0.0",
         "6.6",
         "2.2",
         "35",
         "13",
         "20",
         "53",
         "57",
         "1038.8",
         "1036.0",
         "7",
         "7",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "38",
         "7434",
         "20.1",
         "22.0",
         "16.8",
         "22.7",
         "0.0",
         "5.4",
         "8.7",
         "43",
         "15",
         "24",
         "51",
         "51",
         "1034.4",
         "1029.7",
         "7",
         "5",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "39",
         "7435",
         "21.2",
         "22.3",
         "15.7",
         "24.3",
         "0.0",
         "6.8",
         "9.5",
         "24",
         "2",
         "17",
         "62",
         "60",
         "1028.9",
         "1025.8",
         "1",
         "4",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "40",
         "7436",
         "18.7",
         "21.4",
         "15.0",
         "24.3",
         "0.0",
         "5.6",
         "6.4",
         "41",
         "9",
         "11",
         "77",
         "65",
         "1022.7",
         "1018.6",
         "6",
         "7",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "41",
         "7437",
         "22.7",
         "23.4",
         "16.5",
         "29.5",
         "3.6",
         "5.0",
         "9.6",
         "43",
         "11",
         "19",
         "50",
         "55",
         "1016.7",
         "1012.4",
         "1",
         "6",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "42",
         "7438",
         "18.3",
         "19.8",
         "17.5",
         "20.4",
         "1.6",
         "7.8",
         "0.8",
         "37",
         "20",
         "20",
         "82",
         "77",
         "1022.3",
         "1022.3",
         "4",
         "8",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "43",
         "7439",
         "20.1",
         "22.7",
         "16.9",
         "23.3",
         "3.4",
         "1.4",
         "8.3",
         "37",
         "6",
         "20",
         "75",
         "60",
         "1026.8",
         "1025.2",
         "7",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "44",
         "7440",
         "21.6",
         "23.1",
         "16.3",
         "24.0",
         "0.0",
         "7.0",
         "12.0",
         "44",
         "13",
         "30",
         "65",
         "63",
         "1026.2",
         "1022.0",
         "1",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "45",
         "7441",
         "23.3",
         "27.3",
         "17.3",
         "27.5",
         "0.0",
         "6.8",
         "11.9",
         "43",
         "6",
         "20",
         "60",
         "52",
         "1021.7",
         "1018.7",
         "0",
         "1",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "46",
         "7442",
         "21.5",
         "23.0",
         "19.1",
         "26.0",
         "0.0",
         "9.8",
         "9.7",
         "31",
         "17",
         "15",
         "66",
         "64",
         "1023.1",
         "1021.4",
         "1",
         "4",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "47",
         "7443",
         "19.5",
         "22.1",
         "18.8",
         "23.2",
         "1.4",
         "7.2",
         "3.8",
         "35",
         "17",
         "15",
         "69",
         "56",
         "1029.2",
         "1027.9",
         "8",
         "7",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "48",
         "7444",
         "21.8",
         "24.4",
         "19.4",
         "24.6",
         "0.2",
         "4.2",
         "8.2",
         "39",
         "11",
         "24",
         "81",
         "54",
         "1026.6",
         "1022.4",
         "7",
         "4",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "49",
         "7445",
         "23.7",
         "26.0",
         "18.7",
         "26.8",
         "0.4",
         "6.8",
         "7.7",
         "35",
         "6",
         "15",
         "60",
         "55",
         "1020.6",
         "1016.3",
         "2",
         "2",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 65,
        "rows": 655
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp_9am</th>\n",
       "      <th>temp_3pm</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>rain_fall</th>\n",
       "      <th>evaporation</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>wind_gust_speed</th>\n",
       "      <th>wind_speed_9am</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7396</td>\n",
       "      <td>12.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10.8</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7397</td>\n",
       "      <td>11.9</td>\n",
       "      <td>18.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7398</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7399</td>\n",
       "      <td>13.7</td>\n",
       "      <td>18.3</td>\n",
       "      <td>12.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>20.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7400</td>\n",
       "      <td>15.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>11.5</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>8046</td>\n",
       "      <td>10.5</td>\n",
       "      <td>17.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>8047</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>9.3</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>8048</td>\n",
       "      <td>10.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>8049</td>\n",
       "      <td>12.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>9.3</td>\n",
       "      <td>43</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>8050</td>\n",
       "      <td>9.4</td>\n",
       "      <td>18.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>655 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     date  temp_9am  temp_3pm  min_temp  max_temp  rain_fall  evaporation  \\\n",
       "0    7396      12.7      17.0       9.0      19.7        0.0          3.2   \n",
       "1    7397      11.9      18.6       8.0      18.8        0.0          4.0   \n",
       "2    7398      14.4      20.6      11.2      20.8        2.8          5.6   \n",
       "3    7399      13.7      18.3      12.5      19.5       20.4          4.0   \n",
       "4    7400      15.2      18.7      11.5      21.7        0.0          2.8   \n",
       "..    ...       ...       ...       ...       ...        ...          ...   \n",
       "650  8046      10.5      17.9       8.6      19.6        0.0          2.0   \n",
       "651  8047      11.0      18.7       9.3      19.2        0.0          2.0   \n",
       "652  8048      10.2      17.3       9.4      17.7        0.0          2.4   \n",
       "653  8049      12.4      19.0      10.1      19.3        0.0          1.4   \n",
       "654  8050       9.4      18.8       7.6      19.3        0.0          3.4   \n",
       "\n",
       "     sunshine  wind_gust_speed  wind_speed_9am  ...   38   39   40   41   42  \\\n",
       "0        10.8               31              17  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "1        10.4               31              11  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "2         8.0               52              20  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "3         5.7               48              19  ...  0.0  0.0  1.0  0.0  0.0   \n",
       "4         9.3               37              17  ...  0.0  0.0  0.0  1.0  0.0   \n",
       "..        ...              ...             ...  ...  ...  ...  ...  ...  ...   \n",
       "650       7.8               37              22  ...  0.0  0.0  0.0  0.0  1.0   \n",
       "651       9.2               30              20  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "652       2.7               24              15  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "653       9.3               43              17  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "654       9.4               35              13  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      43   44   45   46   47  \n",
       "0    0.0  0.0  0.0  0.0  0.0  \n",
       "1    0.0  0.0  0.0  0.0  0.0  \n",
       "2    0.0  0.0  0.0  0.0  1.0  \n",
       "3    0.0  0.0  0.0  0.0  0.0  \n",
       "4    0.0  0.0  0.0  0.0  0.0  \n",
       "..   ...  ...  ...  ...  ...  \n",
       "650  0.0  0.0  0.0  0.0  0.0  \n",
       "651  0.0  0.0  0.0  0.0  0.0  \n",
       "652  0.0  0.0  0.0  0.0  0.0  \n",
       "653  0.0  0.0  1.0  0.0  0.0  \n",
       "654  0.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[655 rows x 65 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df.drop(cat_columns, axis = 1)\n",
    "test_df = pd.concat([test_df , cat_ohed], axis = 1)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acba90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_xgbm_test_pred: np.ndarray = BASE_MODEL_XGBM.predict_proba(test_df)\n",
    "base_lgbm_test_pred: np.ndarray = BASE_MODEL_LGBM.predict_proba(test_df)\n",
    "base_cb_test_pred  : np.ndarray = BASE_CB_MODEL.predict_proba(test_df)\n",
    "\n",
    "meta_test_df: pd.DataFrame =  pd.DataFrame({\n",
    "    \"XGBM_PREDICTION\" : base_xgbm_test_pred[:, 1],\n",
    "    \"LGBM_PREDICTION\" : base_lgbm_test_pred[:, 1],\n",
    "    \"CB_PREDICTION\"   : base_cb_test_pred[:, 1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "569220fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result: np.ndarray = META_MODEL.predict(meta_test_df)\n",
    "resultDataFrame: pd.DataFrame = pd.DataFrame({\n",
    "    'ID' : ids,\n",
    "    'Predicted' : pd.Series(final_result).map({1 : \"yes\" , 0 : \"no\"})\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDataFrame.to_csv(\"result.csv\" , index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
